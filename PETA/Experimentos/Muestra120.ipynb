{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZK41MNgZDEE9pw_LuWBGh9zFE2lC1Nc9","timestamp":1674164707852},{"file_id":"1pM4FyjV72HeYXVll7Q9TokiVunh0UijY","timestamp":1674152895718}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"xhN8vz1PQ8Wv","executionInfo":{"status":"error","timestamp":1674574711075,"user_tz":180,"elapsed":10,"user":{"displayName":"Emmanuel Iarussi","userId":"10801541093148836004"}},"outputId":"8b36c7fd-289f-424d-ed89-85e618e5173f"},"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_109564/1050275017.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}]},{"cell_type":"code","source":["%matplotlib inline"],"metadata":{"id":"vpyelL4yXvC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRvvbIrxP5Hd","executionInfo":{"status":"ok","timestamp":1674328682281,"user_tz":180,"elapsed":3555,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"533bf7ff-7a1a-425f-ed14-e6464b8982d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch Version:  1.13.1+cu116\n","Torchvision Version:  0.14.1+cu116\n"]}],"source":["from __future__ import print_function, division\n","import os\n","import time\n","import copy\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchvision import transforms, utils, models, datasets\n","# import dicom2nifti.   # no disponible en collab\n","import torch.nn as nn\n","import torch.optim as optim\n","import nibabel as nib \n","# import nilearn as nil # no disponible en collab\n","import scipy.ndimage as ndi\n","from pathlib import Path\n","from PIL import Image\n","import io\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"]},{"cell_type":"code","source":["#imagesFolder = '/content/gdrive/MyDrive/Tesis/Imagenes/ADNI-MUESTRA-40'\n","#trainDatasetCSV = imagesFolder + '/ADNI-MUESTRA-40-UniformResolution_train.csv'\n","#valDatasetCSV = imagesFolder + '/ADNI-MUESTRA-40-UniformResolution_val.csv'\n","\n","# muestra10 solo tiene train\n","imagesFolder = '/content/gdrive/MyDrive/Tesis/Imagenes/ADNI-MUESTRA-120'\n","trainDatasetCSV = imagesFolder + '/MUESTRA_train.csv'\n","valDatasetCSV =   imagesFolder + '/MUESTRA_val.csv'\n","\n","crossEntrophyWeigths = torch.tensor([1.0,1.0,1.0])"],"metadata":{"id":"HErqZ9GNCDq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n","model_name = \"inception\"\n","\n","# Number of classes in the dataset\n","num_classes = 3\n","\n","# Batch size for training (change depending on how much memory you have)\n","batch_size = 10\n","\n","# Number of epochs to train for\n","num_epochs = 10\n","\n","# Flag for feature extracting. When False, we finetune the whole model,\n","#   when True we only update the reshaped layer params\n","feature_extract = False\n"],"metadata":{"id":"VYNyT00wpzwU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://stackoverflow.com/questions/8598673/how-to-save-a-pylab-figure-into-in-memory-file-which-can-be-read-into-pil-image\n","def fig2img(fig):\n","    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n","    buf = io.BytesIO()\n","    fig.savefig(buf, facecolor='black', dpi = 64, transparent=False) # dpi Requerido para que la imagen sea 512x512\n","    buf.seek(0)\n","    img = Image.open(buf)\n","    return img"],"metadata":{"id":"VDba_NBLQOou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def transformGridImage(sample):\n","    brain_vol_data = sample.get_fdata()\n","    fig_rows = 4\n","    fig_cols = 4\n","    n_subplots = fig_rows * fig_cols\n","    n_slice = brain_vol_data.shape[2]\n","    step_size = n_slice // n_subplots\n","    plot_range = n_subplots * step_size\n","    start_stop = int((n_slice - plot_range) / 2)\n","\n","    fig, axs = plt.subplots(fig_rows, fig_cols, figsize=[10, 10], facecolor='none', dpi=64)\n","    fig.set_size_inches(8, 8)\n","    fig.set_dpi(64)\n","    \n","    for idx, img in enumerate(range(start_stop, plot_range, step_size)):\n","        rotatedImg = ndi.rotate(brain_vol_data[:, :, img], 90)\n","        axs.flat[idx].imshow(np.squeeze(rotatedImg), cmap='gray') # np.squeeze es necesario para remover la dimension 1 al final\n","        axs.flat[idx].axis('off')\n","        \n","    plt.tight_layout()\n","\n","    image = fig2img(fig)\n","\n","    plt.close(fig) # Para que no muestre la imÃ¡gen\n","    \n","    return image"],"metadata":{"id":"K-Z1h8wrQaiB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CreateGrid transform\n","class CreateGrid(object):\n","    \"\"\"Creates a grid from the image\n","    \"\"\"\n","    def __init__(self):\n","        True\n","\n","    def __call__(self, sample):\n","        return transformGridImage(sample)"],"metadata":{"id":"vODiu92PQdIL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RemoveTransparency(object):\n","    def __call__(self, sample):\n","      # La imagen se guarda con transparencia, removemos la dimension de indice 3\n","      return sample[0:3, : :]"],"metadata":{"id":"TX-5K8GGG-zT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ToLabelOutput(object):\n","    def __call__(self, label):\n","        if label == \"CN\":\n","            return 0\n","        elif label == \"AD\":\n","            return 1\n","        else:\n","            return 2 # MCI, LMCI, EMCI"],"metadata":{"id":"UmM3wjZ0Qfa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ADNIDataset(Dataset):\n","    \"\"\"ADNI dataset.\"\"\"\n","\n","    def __init__(self, csv_file, root_dir, transform=None, target_transform = None):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file with annotations.\n","            root_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.csv = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","      return int(len(self.csv))\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","            \n","        studyID = self.csv.iloc[idx, 0]\n","        subjectID = self.csv.iloc[idx, 1]\n","        processFormat = self.csv.iloc[idx, 7]\n","        date = self.csv.iloc[idx, 9]\n","        diagnosis = self.csv.iloc[idx, 2]\n","        \n","        filename = None\n","        \n","        rglob = '*' + str(studyID)+'.nii'\n","        #print(rglob)\n","        samples = 0\n","        # for path in Path('ADNI-Full-PostProc').rglob(rglob):\n","        for path in Path(self.root_dir).rglob(rglob):\n","            filename = str(path)\n","            samples =+ 1\n","            \n","        if samples > 1:\n","            raise \"Mas de un sample. Error\"\n","\n","        if not filename:\n","            raise Exception(\"Not found filename for index \" + str(idx) + \" y studyID \" + studyID)\n","\n","        # print(\"Leyendo: \" + filename)\n","            \n","        brain_vol = nib.load(filename)\n","\n","        image = brain_vol\n","        label = diagnosis\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","            \n","        if self.target_transform:\n","            label = self.target_transform(label)\n","\n","        return image, label"],"metadata":{"id":"wxq4R1JOQgyU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modelo"],"metadata":{"id":"zW1D_vQnpzDk"}},{"cell_type":"code","source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=True):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        # No usamos el aux\n","                        #outputs, aux_outputs = model(inputs)\n","                        #loss1 = criterion(outputs, labels)\n","                        #loss2 = criterion(aux_outputs, labels)\n","                        #loss = loss1 + 0.4*loss2\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"],"metadata":{"id":"m44_ZbqJvsQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"],"metadata":{"id":"Vl-UuMFJv0_S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Initialize and reshape inception"],"metadata":{"id":"DuMUC0zqwFLw"}},{"cell_type":"code","source":["def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"inception\":\n","        \"\"\" Inception v3\n","        Be careful, expects (299,299) sized images and has auxiliary output\n","        \"\"\"\n","        model_ft = models.inception_v3(pretrained=use_pretrained, \n","                                       aux_logits = False)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        # Handle the auxilary net\n","        # num_ftrs = model_ft.AuxLogits.fc.in_features\n","        # model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n","        # Handle the primary net\n","        num_ftrs = model_ft.fc.in_features\n","        print(\"num featurs\" + str(num_ftrs))\n","        # Fuente: https://github.com/bdrad/petdementiapub/blob/master/petdementia_source.py\n","        model_ft.fc = nn.Sequential(\n","          nn.Linear(num_ftrs,1024),\n","          nn.ReLU(),\n","          nn.Linear(1024,num_classes),\n","          # nn.Softmax() # innecesario, cross entrophy acepta logits\n","        )\n","          \n","        input_size = 512 \n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft, input_size\n","\n","# Initialize the model for this run\n","model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n","\n","# Print the model we just instantiated\n","print(model_ft)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqZfuwYwwLw2","executionInfo":{"status":"ok","timestamp":1674328683334,"user_tz":180,"elapsed":6,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}},"outputId":"ae371046-1007-4f38-88dc-7d4507ec4392"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num featurs2048\n","Inception3(\n","  (Conv2d_1a_3x3): BasicConv2d(\n","    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2a_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2b_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (Conv2d_3b_1x1): BasicConv2d(\n","    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_4a_3x3): BasicConv2d(\n","    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (Mixed_5b): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5c): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5d): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6a): InceptionB(\n","    (branch3x3): BasicConv2d(\n","      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6b): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6c): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6d): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6e): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7a): InceptionD(\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7b): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7c): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Sequential(\n","    (0): Linear(in_features=2048, out_features=1024, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=1024, out_features=3, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms = {\n","    'train': transforms.Compose([\n","        #transforms.RandomResizedCrop(input_size),\n","        #transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        #transforms.Resize(input_size),\n","        #transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create training and validation datasets\n","# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']} #todo: separar datasets\n","\n","image_datasets = {\n","    'train': ADNIDataset(trainDatasetCSV, imagesFolder, transform = transforms.Compose([CreateGrid(), transforms.ToTensor(), RemoveTransparency()]), target_transform =ToLabelOutput() ),\n","    'val': ADNIDataset(valDatasetCSV, imagesFolder, transform = transforms.Compose([CreateGrid(), transforms.ToTensor(), RemoveTransparency()]), target_transform =ToLabelOutput() )\n","}\n","\n","# Create training and validation dataloaders\n","dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pfACeWNcwYqY","executionInfo":{"status":"ok","timestamp":1674328686917,"user_tz":180,"elapsed":3586,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}},"outputId":"4a8fb4f4-d99f-42a3-8c49-a970d67fc910"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Datasets and Dataloaders...\n"]}]},{"cell_type":"code","source":["# Send the model to GPU\n","model_ft = model_ft.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_ft.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.Adam(params_to_update, lr=0.0001)\n"],"metadata":{"id":"XciJ190PwerB","executionInfo":{"status":"ok","timestamp":1674328691378,"user_tz":180,"elapsed":4476,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f40d8f36-bb64-467d-8efc-850469653ff5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Params to learn:\n","\t Conv2d_1a_3x3.conv.weight\n","\t Conv2d_1a_3x3.bn.weight\n","\t Conv2d_1a_3x3.bn.bias\n","\t Conv2d_2a_3x3.conv.weight\n","\t Conv2d_2a_3x3.bn.weight\n","\t Conv2d_2a_3x3.bn.bias\n","\t Conv2d_2b_3x3.conv.weight\n","\t Conv2d_2b_3x3.bn.weight\n","\t Conv2d_2b_3x3.bn.bias\n","\t Conv2d_3b_1x1.conv.weight\n","\t Conv2d_3b_1x1.bn.weight\n","\t Conv2d_3b_1x1.bn.bias\n","\t Conv2d_4a_3x3.conv.weight\n","\t Conv2d_4a_3x3.bn.weight\n","\t Conv2d_4a_3x3.bn.bias\n","\t Mixed_5b.branch1x1.conv.weight\n","\t Mixed_5b.branch1x1.bn.weight\n","\t Mixed_5b.branch1x1.bn.bias\n","\t Mixed_5b.branch5x5_1.conv.weight\n","\t Mixed_5b.branch5x5_1.bn.weight\n","\t Mixed_5b.branch5x5_1.bn.bias\n","\t Mixed_5b.branch5x5_2.conv.weight\n","\t Mixed_5b.branch5x5_2.bn.weight\n","\t Mixed_5b.branch5x5_2.bn.bias\n","\t Mixed_5b.branch3x3dbl_1.conv.weight\n","\t Mixed_5b.branch3x3dbl_1.bn.weight\n","\t Mixed_5b.branch3x3dbl_1.bn.bias\n","\t Mixed_5b.branch3x3dbl_2.conv.weight\n","\t Mixed_5b.branch3x3dbl_2.bn.weight\n","\t Mixed_5b.branch3x3dbl_2.bn.bias\n","\t Mixed_5b.branch3x3dbl_3.conv.weight\n","\t Mixed_5b.branch3x3dbl_3.bn.weight\n","\t Mixed_5b.branch3x3dbl_3.bn.bias\n","\t Mixed_5b.branch_pool.conv.weight\n","\t Mixed_5b.branch_pool.bn.weight\n","\t Mixed_5b.branch_pool.bn.bias\n","\t Mixed_5c.branch1x1.conv.weight\n","\t Mixed_5c.branch1x1.bn.weight\n","\t Mixed_5c.branch1x1.bn.bias\n","\t Mixed_5c.branch5x5_1.conv.weight\n","\t Mixed_5c.branch5x5_1.bn.weight\n","\t Mixed_5c.branch5x5_1.bn.bias\n","\t Mixed_5c.branch5x5_2.conv.weight\n","\t Mixed_5c.branch5x5_2.bn.weight\n","\t Mixed_5c.branch5x5_2.bn.bias\n","\t Mixed_5c.branch3x3dbl_1.conv.weight\n","\t Mixed_5c.branch3x3dbl_1.bn.weight\n","\t Mixed_5c.branch3x3dbl_1.bn.bias\n","\t Mixed_5c.branch3x3dbl_2.conv.weight\n","\t Mixed_5c.branch3x3dbl_2.bn.weight\n","\t Mixed_5c.branch3x3dbl_2.bn.bias\n","\t Mixed_5c.branch3x3dbl_3.conv.weight\n","\t Mixed_5c.branch3x3dbl_3.bn.weight\n","\t Mixed_5c.branch3x3dbl_3.bn.bias\n","\t Mixed_5c.branch_pool.conv.weight\n","\t Mixed_5c.branch_pool.bn.weight\n","\t Mixed_5c.branch_pool.bn.bias\n","\t Mixed_5d.branch1x1.conv.weight\n","\t Mixed_5d.branch1x1.bn.weight\n","\t Mixed_5d.branch1x1.bn.bias\n","\t Mixed_5d.branch5x5_1.conv.weight\n","\t Mixed_5d.branch5x5_1.bn.weight\n","\t Mixed_5d.branch5x5_1.bn.bias\n","\t Mixed_5d.branch5x5_2.conv.weight\n","\t Mixed_5d.branch5x5_2.bn.weight\n","\t Mixed_5d.branch5x5_2.bn.bias\n","\t Mixed_5d.branch3x3dbl_1.conv.weight\n","\t Mixed_5d.branch3x3dbl_1.bn.weight\n","\t Mixed_5d.branch3x3dbl_1.bn.bias\n","\t Mixed_5d.branch3x3dbl_2.conv.weight\n","\t Mixed_5d.branch3x3dbl_2.bn.weight\n","\t Mixed_5d.branch3x3dbl_2.bn.bias\n","\t Mixed_5d.branch3x3dbl_3.conv.weight\n","\t Mixed_5d.branch3x3dbl_3.bn.weight\n","\t Mixed_5d.branch3x3dbl_3.bn.bias\n","\t Mixed_5d.branch_pool.conv.weight\n","\t Mixed_5d.branch_pool.bn.weight\n","\t Mixed_5d.branch_pool.bn.bias\n","\t Mixed_6a.branch3x3.conv.weight\n","\t Mixed_6a.branch3x3.bn.weight\n","\t Mixed_6a.branch3x3.bn.bias\n","\t Mixed_6a.branch3x3dbl_1.conv.weight\n","\t Mixed_6a.branch3x3dbl_1.bn.weight\n","\t Mixed_6a.branch3x3dbl_1.bn.bias\n","\t Mixed_6a.branch3x3dbl_2.conv.weight\n","\t Mixed_6a.branch3x3dbl_2.bn.weight\n","\t Mixed_6a.branch3x3dbl_2.bn.bias\n","\t Mixed_6a.branch3x3dbl_3.conv.weight\n","\t Mixed_6a.branch3x3dbl_3.bn.weight\n","\t Mixed_6a.branch3x3dbl_3.bn.bias\n","\t Mixed_6b.branch1x1.conv.weight\n","\t Mixed_6b.branch1x1.bn.weight\n","\t Mixed_6b.branch1x1.bn.bias\n","\t Mixed_6b.branch7x7_1.conv.weight\n","\t Mixed_6b.branch7x7_1.bn.weight\n","\t Mixed_6b.branch7x7_1.bn.bias\n","\t Mixed_6b.branch7x7_2.conv.weight\n","\t Mixed_6b.branch7x7_2.bn.weight\n","\t Mixed_6b.branch7x7_2.bn.bias\n","\t Mixed_6b.branch7x7_3.conv.weight\n","\t Mixed_6b.branch7x7_3.bn.weight\n","\t Mixed_6b.branch7x7_3.bn.bias\n","\t Mixed_6b.branch7x7dbl_1.conv.weight\n","\t Mixed_6b.branch7x7dbl_1.bn.weight\n","\t Mixed_6b.branch7x7dbl_1.bn.bias\n","\t Mixed_6b.branch7x7dbl_2.conv.weight\n","\t Mixed_6b.branch7x7dbl_2.bn.weight\n","\t Mixed_6b.branch7x7dbl_2.bn.bias\n","\t Mixed_6b.branch7x7dbl_3.conv.weight\n","\t Mixed_6b.branch7x7dbl_3.bn.weight\n","\t Mixed_6b.branch7x7dbl_3.bn.bias\n","\t Mixed_6b.branch7x7dbl_4.conv.weight\n","\t Mixed_6b.branch7x7dbl_4.bn.weight\n","\t Mixed_6b.branch7x7dbl_4.bn.bias\n","\t Mixed_6b.branch7x7dbl_5.conv.weight\n","\t Mixed_6b.branch7x7dbl_5.bn.weight\n","\t Mixed_6b.branch7x7dbl_5.bn.bias\n","\t Mixed_6b.branch_pool.conv.weight\n","\t Mixed_6b.branch_pool.bn.weight\n","\t Mixed_6b.branch_pool.bn.bias\n","\t Mixed_6c.branch1x1.conv.weight\n","\t Mixed_6c.branch1x1.bn.weight\n","\t Mixed_6c.branch1x1.bn.bias\n","\t Mixed_6c.branch7x7_1.conv.weight\n","\t Mixed_6c.branch7x7_1.bn.weight\n","\t Mixed_6c.branch7x7_1.bn.bias\n","\t Mixed_6c.branch7x7_2.conv.weight\n","\t Mixed_6c.branch7x7_2.bn.weight\n","\t Mixed_6c.branch7x7_2.bn.bias\n","\t Mixed_6c.branch7x7_3.conv.weight\n","\t Mixed_6c.branch7x7_3.bn.weight\n","\t Mixed_6c.branch7x7_3.bn.bias\n","\t Mixed_6c.branch7x7dbl_1.conv.weight\n","\t Mixed_6c.branch7x7dbl_1.bn.weight\n","\t Mixed_6c.branch7x7dbl_1.bn.bias\n","\t Mixed_6c.branch7x7dbl_2.conv.weight\n","\t Mixed_6c.branch7x7dbl_2.bn.weight\n","\t Mixed_6c.branch7x7dbl_2.bn.bias\n","\t Mixed_6c.branch7x7dbl_3.conv.weight\n","\t Mixed_6c.branch7x7dbl_3.bn.weight\n","\t Mixed_6c.branch7x7dbl_3.bn.bias\n","\t Mixed_6c.branch7x7dbl_4.conv.weight\n","\t Mixed_6c.branch7x7dbl_4.bn.weight\n","\t Mixed_6c.branch7x7dbl_4.bn.bias\n","\t Mixed_6c.branch7x7dbl_5.conv.weight\n","\t Mixed_6c.branch7x7dbl_5.bn.weight\n","\t Mixed_6c.branch7x7dbl_5.bn.bias\n","\t Mixed_6c.branch_pool.conv.weight\n","\t Mixed_6c.branch_pool.bn.weight\n","\t Mixed_6c.branch_pool.bn.bias\n","\t Mixed_6d.branch1x1.conv.weight\n","\t Mixed_6d.branch1x1.bn.weight\n","\t Mixed_6d.branch1x1.bn.bias\n","\t Mixed_6d.branch7x7_1.conv.weight\n","\t Mixed_6d.branch7x7_1.bn.weight\n","\t Mixed_6d.branch7x7_1.bn.bias\n","\t Mixed_6d.branch7x7_2.conv.weight\n","\t Mixed_6d.branch7x7_2.bn.weight\n","\t Mixed_6d.branch7x7_2.bn.bias\n","\t Mixed_6d.branch7x7_3.conv.weight\n","\t Mixed_6d.branch7x7_3.bn.weight\n","\t Mixed_6d.branch7x7_3.bn.bias\n","\t Mixed_6d.branch7x7dbl_1.conv.weight\n","\t Mixed_6d.branch7x7dbl_1.bn.weight\n","\t Mixed_6d.branch7x7dbl_1.bn.bias\n","\t Mixed_6d.branch7x7dbl_2.conv.weight\n","\t Mixed_6d.branch7x7dbl_2.bn.weight\n","\t Mixed_6d.branch7x7dbl_2.bn.bias\n","\t Mixed_6d.branch7x7dbl_3.conv.weight\n","\t Mixed_6d.branch7x7dbl_3.bn.weight\n","\t Mixed_6d.branch7x7dbl_3.bn.bias\n","\t Mixed_6d.branch7x7dbl_4.conv.weight\n","\t Mixed_6d.branch7x7dbl_4.bn.weight\n","\t Mixed_6d.branch7x7dbl_4.bn.bias\n","\t Mixed_6d.branch7x7dbl_5.conv.weight\n","\t Mixed_6d.branch7x7dbl_5.bn.weight\n","\t Mixed_6d.branch7x7dbl_5.bn.bias\n","\t Mixed_6d.branch_pool.conv.weight\n","\t Mixed_6d.branch_pool.bn.weight\n","\t Mixed_6d.branch_pool.bn.bias\n","\t Mixed_6e.branch1x1.conv.weight\n","\t Mixed_6e.branch1x1.bn.weight\n","\t Mixed_6e.branch1x1.bn.bias\n","\t Mixed_6e.branch7x7_1.conv.weight\n","\t Mixed_6e.branch7x7_1.bn.weight\n","\t Mixed_6e.branch7x7_1.bn.bias\n","\t Mixed_6e.branch7x7_2.conv.weight\n","\t Mixed_6e.branch7x7_2.bn.weight\n","\t Mixed_6e.branch7x7_2.bn.bias\n","\t Mixed_6e.branch7x7_3.conv.weight\n","\t Mixed_6e.branch7x7_3.bn.weight\n","\t Mixed_6e.branch7x7_3.bn.bias\n","\t Mixed_6e.branch7x7dbl_1.conv.weight\n","\t Mixed_6e.branch7x7dbl_1.bn.weight\n","\t Mixed_6e.branch7x7dbl_1.bn.bias\n","\t Mixed_6e.branch7x7dbl_2.conv.weight\n","\t Mixed_6e.branch7x7dbl_2.bn.weight\n","\t Mixed_6e.branch7x7dbl_2.bn.bias\n","\t Mixed_6e.branch7x7dbl_3.conv.weight\n","\t Mixed_6e.branch7x7dbl_3.bn.weight\n","\t Mixed_6e.branch7x7dbl_3.bn.bias\n","\t Mixed_6e.branch7x7dbl_4.conv.weight\n","\t Mixed_6e.branch7x7dbl_4.bn.weight\n","\t Mixed_6e.branch7x7dbl_4.bn.bias\n","\t Mixed_6e.branch7x7dbl_5.conv.weight\n","\t Mixed_6e.branch7x7dbl_5.bn.weight\n","\t Mixed_6e.branch7x7dbl_5.bn.bias\n","\t Mixed_6e.branch_pool.conv.weight\n","\t Mixed_6e.branch_pool.bn.weight\n","\t Mixed_6e.branch_pool.bn.bias\n","\t Mixed_7a.branch3x3_1.conv.weight\n","\t Mixed_7a.branch3x3_1.bn.weight\n","\t Mixed_7a.branch3x3_1.bn.bias\n","\t Mixed_7a.branch3x3_2.conv.weight\n","\t Mixed_7a.branch3x3_2.bn.weight\n","\t Mixed_7a.branch3x3_2.bn.bias\n","\t Mixed_7a.branch7x7x3_1.conv.weight\n","\t Mixed_7a.branch7x7x3_1.bn.weight\n","\t Mixed_7a.branch7x7x3_1.bn.bias\n","\t Mixed_7a.branch7x7x3_2.conv.weight\n","\t Mixed_7a.branch7x7x3_2.bn.weight\n","\t Mixed_7a.branch7x7x3_2.bn.bias\n","\t Mixed_7a.branch7x7x3_3.conv.weight\n","\t Mixed_7a.branch7x7x3_3.bn.weight\n","\t Mixed_7a.branch7x7x3_3.bn.bias\n","\t Mixed_7a.branch7x7x3_4.conv.weight\n","\t Mixed_7a.branch7x7x3_4.bn.weight\n","\t Mixed_7a.branch7x7x3_4.bn.bias\n","\t Mixed_7b.branch1x1.conv.weight\n","\t Mixed_7b.branch1x1.bn.weight\n","\t Mixed_7b.branch1x1.bn.bias\n","\t Mixed_7b.branch3x3_1.conv.weight\n","\t Mixed_7b.branch3x3_1.bn.weight\n","\t Mixed_7b.branch3x3_1.bn.bias\n","\t Mixed_7b.branch3x3_2a.conv.weight\n","\t Mixed_7b.branch3x3_2a.bn.weight\n","\t Mixed_7b.branch3x3_2a.bn.bias\n","\t Mixed_7b.branch3x3_2b.conv.weight\n","\t Mixed_7b.branch3x3_2b.bn.weight\n","\t Mixed_7b.branch3x3_2b.bn.bias\n","\t Mixed_7b.branch3x3dbl_1.conv.weight\n","\t Mixed_7b.branch3x3dbl_1.bn.weight\n","\t Mixed_7b.branch3x3dbl_1.bn.bias\n","\t Mixed_7b.branch3x3dbl_2.conv.weight\n","\t Mixed_7b.branch3x3dbl_2.bn.weight\n","\t Mixed_7b.branch3x3dbl_2.bn.bias\n","\t Mixed_7b.branch3x3dbl_3a.conv.weight\n","\t Mixed_7b.branch3x3dbl_3a.bn.weight\n","\t Mixed_7b.branch3x3dbl_3a.bn.bias\n","\t Mixed_7b.branch3x3dbl_3b.conv.weight\n","\t Mixed_7b.branch3x3dbl_3b.bn.weight\n","\t Mixed_7b.branch3x3dbl_3b.bn.bias\n","\t Mixed_7b.branch_pool.conv.weight\n","\t Mixed_7b.branch_pool.bn.weight\n","\t Mixed_7b.branch_pool.bn.bias\n","\t Mixed_7c.branch1x1.conv.weight\n","\t Mixed_7c.branch1x1.bn.weight\n","\t Mixed_7c.branch1x1.bn.bias\n","\t Mixed_7c.branch3x3_1.conv.weight\n","\t Mixed_7c.branch3x3_1.bn.weight\n","\t Mixed_7c.branch3x3_1.bn.bias\n","\t Mixed_7c.branch3x3_2a.conv.weight\n","\t Mixed_7c.branch3x3_2a.bn.weight\n","\t Mixed_7c.branch3x3_2a.bn.bias\n","\t Mixed_7c.branch3x3_2b.conv.weight\n","\t Mixed_7c.branch3x3_2b.bn.weight\n","\t Mixed_7c.branch3x3_2b.bn.bias\n","\t Mixed_7c.branch3x3dbl_1.conv.weight\n","\t Mixed_7c.branch3x3dbl_1.bn.weight\n","\t Mixed_7c.branch3x3dbl_1.bn.bias\n","\t Mixed_7c.branch3x3dbl_2.conv.weight\n","\t Mixed_7c.branch3x3dbl_2.bn.weight\n","\t Mixed_7c.branch3x3dbl_2.bn.bias\n","\t Mixed_7c.branch3x3dbl_3a.conv.weight\n","\t Mixed_7c.branch3x3dbl_3a.bn.weight\n","\t Mixed_7c.branch3x3dbl_3a.bn.bias\n","\t Mixed_7c.branch3x3dbl_3b.conv.weight\n","\t Mixed_7c.branch3x3dbl_3b.bn.weight\n","\t Mixed_7c.branch3x3dbl_3b.bn.bias\n","\t Mixed_7c.branch_pool.conv.weight\n","\t Mixed_7c.branch_pool.bn.weight\n","\t Mixed_7c.branch_pool.bn.bias\n","\t fc.0.weight\n","\t fc.0.bias\n","\t fc.2.weight\n","\t fc.2.bias\n"]}]},{"cell_type":"code","source":["# Setup the loss fxn\n","crossEntrophyWeigths = crossEntrophyWeigths.to(device)\n","criterion = nn.CrossEntropyLoss(crossEntrophyWeigths)\n","\n","# Train and evaluate\n","model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"],"metadata":{"id":"D84am68jwlX6","executionInfo":{"status":"ok","timestamp":1674329238177,"user_tz":180,"elapsed":546817,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"11290746-f3bb-4342-fb9a-7f55a4411462"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/9\n","----------\n","train Loss: 1.1466 Acc: 0.3000\n","val Loss: 42.5540 Acc: 0.3333\n","Epoch 1/9\n","----------\n","train Loss: 1.1203 Acc: 0.3889\n","val Loss: 3.0919 Acc: 0.3333\n","Epoch 2/9\n","----------\n","train Loss: 1.0375 Acc: 0.4667\n","val Loss: 1.8416 Acc: 0.3333\n","Epoch 3/9\n","----------\n","train Loss: 0.9832 Acc: 0.5333\n","val Loss: 1.0974 Acc: 0.2667\n","Epoch 4/9\n","----------\n","train Loss: 0.9183 Acc: 0.5444\n","val Loss: 1.1863 Acc: 0.3333\n","Epoch 5/9\n","----------\n","train Loss: 0.8450 Acc: 0.5556\n","val Loss: 1.5212 Acc: 0.3333\n","Epoch 6/9\n","----------\n","train Loss: 0.8003 Acc: 0.6444\n","val Loss: 1.6623 Acc: 0.3333\n","Epoch 7/9\n","----------\n","train Loss: 0.7257 Acc: 0.6556\n","val Loss: 1.3509 Acc: 0.3333\n","Epoch 8/9\n","----------\n","train Loss: 0.6205 Acc: 0.7111\n","val Loss: 1.1020 Acc: 0.4000\n","Epoch 9/9\n","----------\n","train Loss: 0.5664 Acc: 0.7889\n","val Loss: 1.3879 Acc: 0.3667\n","Training complete in 9m 7s\n","Best val Acc: 0.400000\n"]}]},{"cell_type":"markdown","source":["# Prueba manual para ver quÃ© devuelve"],"metadata":{"id":"CW0oQaDWlWgo"}},{"cell_type":"code","source":["dataset = ADNIDataset(valDatasetCSV, imagesFolder, transform = transforms.Compose([CreateGrid(), transforms.ToTensor(), RemoveTransparency()]), target_transform =ToLabelOutput() )\n","\n","# Create training and validation dataloaders\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)\n","\n","i = 0\n","max = 10\n","for inputs, labels in dataloader:\n","  inputs = inputs.to(device)\n","  labels = labels.to(device)\n","  print(\"Index: \" + str(i))\n","  print(labels)\n","  print(\"Result: \")\n","  print(model_ft(inputs))\n","  i += 1\n","  if i > max:\n","    break"],"metadata":{"id":"rLgQSBF1XPps","executionInfo":{"status":"ok","timestamp":1674329244172,"user_tz":180,"elapsed":5998,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"40d2c1e9-e516-4171-f2f2-53611f81b171"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index: 0\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.9655, -0.6448,  0.4522]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 1\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.2458,  0.8202, -0.6318]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 2\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.2123,  0.9360, -0.7435]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 3\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.3634,  0.3129, -0.0820]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 4\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.3196,  0.3949, -0.1729]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 5\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.1364,  0.7761, -0.4552]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 6\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.3397,  0.3579, -0.1572]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 7\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.3209,  0.3474, -0.0803]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 8\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.4287,  0.2490, -0.1649]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 9\n","tensor([0], device='cuda:0')\n","Result: \n","tensor([[ 0.1481,  0.6507, -0.2918]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n","Index: 10\n","tensor([2], device='cuda:0')\n","Result: \n","tensor([[-0.9467,  2.3456, -1.0583]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)\n"]}]}]}