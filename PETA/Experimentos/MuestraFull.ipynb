{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhN8vz1PQ8Wv",
        "outputId": "2de87346-bd15-486b-d3e2-702b3b316b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "if 'google' in locals():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpyelL4yXvC0"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChL61Twesn0o"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRvvbIrxP5Hd",
        "outputId": "d98295d0-0e87-4b51-a0ae-5b3e56790a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.13.1+cu116\n",
            "Torchvision Version:  0.14.1+cu116\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, utils, models, datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nibabel as nib\n",
        "import scipy.ndimage as ndi\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import io\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuraci칩n"
      ],
      "metadata": {
        "id": "NA6iXVFtLjxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HErqZ9GNCDq6"
      },
      "outputs": [],
      "source": [
        "imagesFolder = '/content/gdrive/MyDrive/Tesis/Imagenes/ADNI-MUESTRA-FULL'\n",
        "trainDatasetCSV = imagesFolder + '/MUESTRA_train.csv'\n",
        "valDatasetCSV =   imagesFolder + '/MUESTRA_val.csv'\n",
        "experimentName = 'MuestraFull_test'\n",
        "experimentOutputFolder = '/content/gdrive/MyDrive/Tesis/Experimentos/muestraFull'\n",
        "experimentDescription = 'Muestra con todas las im치genes de ADNI, test (2 epochs)'\n",
        "executions = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYNyT00wpzwU"
      },
      "outputs": [],
      "source": [
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 3\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 10\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 2\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "usePretrained = True\n",
        "\n",
        "learningRate = 0.0001\n",
        "\n",
        "crossEntrophyWeigths = torch.tensor([485.0,283.0,1167.0])\n",
        "\n",
        "slicesToCut = 0\n",
        "\n",
        "# Data augmentation\n",
        "dataAugmentation = {\n",
        "    \"angle\": 13.0,\n",
        "    \"zoom\": 0.15,\n",
        "    \"shiftX\": 10.0,\n",
        "    \"shiftY\": 10.0,\n",
        "    \"angleTransformChance\": 0.1,\n",
        "    \"zoomTransformChance\": 0.1,\n",
        "    \"shiftTransformChance\": 0.0\n",
        "}\n",
        "dataAugmentation = {}\n",
        "\n",
        "validationCacheSize = 2000\n",
        "trainCacheSize = 300"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejecuci칩n"
      ],
      "metadata": {
        "id": "FtIIG97yLfMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(os.path.join(experimentOutputFolder, experimentName + \"_params.txt\"), \"w\")\n",
        "f.write(\"batch_size: \" + str(batch_size) + \"\\n\")\n",
        "f.write(\"epochs: \" + str(num_epochs) + \"\\n\")\n",
        "f.write(\"feature_extract: \" + str(feature_extract) + \"\\n\")\n",
        "f.write(\"usePretrained: \" + str(usePretrained) + \"\\n\")\n",
        "f.write(\"learningRate: \" + str(learningRate) + \"\\n\")\n",
        "f.write(\"cross entrophy weights: \" + str(crossEntrophyWeigths) + \"\\n\")\n",
        "f.write(\"slicesToCut: \" + str(slicesToCut) + \"\\n\")\n",
        "f.write(\"dataAugmentation: \" + str(json.dumps(dataAugmentation)) + \"\\n\")\n",
        "f.write(\"executions: \" + str(executions) + \"\\n\")\n",
        "f.write(\"validationCacheSize: \" + str(validationCacheSize) + \"\\n\")\n",
        "f.write(\"trainCacheSize: \" + str(trainCacheSize) + \"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "a2ZFcEXjwezm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(os.path.join(experimentOutputFolder, experimentName + \"_descripcion.txt\"), \"w\")\n",
        "f.write(experimentDescription)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "zJYNgYD9AC4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDba_NBLQOou"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/8598673/how-to-save-a-pylab-figure-into-in-memory-file-which-can-be-read-into-pil-image\n",
        "def fig2img(fig):\n",
        "    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, facecolor='black', dpi = 64, transparent=False) # dpi Requerido para que la imagen sea 512x512\n",
        "    buf.seek(0)\n",
        "    img = Image.open(buf)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Z1h8wrQaiB"
      },
      "outputs": [],
      "source": [
        "def clipped_zoom(img, zoom_factor, **kwargs):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
        "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
        "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
        "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
        "\n",
        "    # Zooming out\n",
        "    if zoom_factor < 1:\n",
        "\n",
        "        # Bounding box of the zoomed-out image within the output array\n",
        "        zh = int(np.round(h * zoom_factor))\n",
        "        zw = int(np.round(w * zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        # Zero-padding\n",
        "        out = np.zeros_like(img)\n",
        "        out[top:top+zh, left:left+zw] = ndi.zoom(img, zoom_tuple, **kwargs)\n",
        "\n",
        "    # Zooming in\n",
        "    elif zoom_factor > 1:\n",
        "\n",
        "        # Bounding box of the zoomed-in region within the input array\n",
        "        zh = int(np.round(h / zoom_factor))\n",
        "        zw = int(np.round(w / zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        out = ndi.zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
        "\n",
        "        # `out` might still be slightly larger than `img` due to rounding, so\n",
        "        # trim off any extra pixels at the edges\n",
        "        trim_top = ((out.shape[0] - h) // 2)\n",
        "        trim_left = ((out.shape[1] - w) // 2)\n",
        "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
        "\n",
        "    # If zoom_factor == 1, just return the input array\n",
        "    else:\n",
        "        out = img\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformGridImage(sample, angle = None, zoom = None, shiftX = None, shiftY = None, \n",
        "                        angleTransformChance = 0.1, zoomTransformChance = 0.1, shiftTransformChance = 0.1):\n",
        "    brain_vol_data = sample.get_fdata()\n",
        "    fig_rows = 4\n",
        "    fig_cols = 4\n",
        "    n_subplots = fig_rows * fig_cols\n",
        "    n_slice = brain_vol_data.shape[2]\n",
        "\n",
        "    slices_to_eliminate = slicesToCut\n",
        "\n",
        "    n_slice_padding = slices_to_eliminate // 2 # quitamos los primeros y ultimos n slices\n",
        "    n_slice = n_slice - slices_to_eliminate\n",
        "\n",
        "    step_size = n_slice / n_subplots\n",
        "\n",
        "    slice_indices = np.arange(n_slice_padding, n_slice_padding + n_slice, step = step_size)\n",
        "\n",
        "    fig, axs = plt.subplots(fig_rows, fig_cols, figsize=[10, 10], facecolor='black')\n",
        "    \n",
        "    if angle == None or angleTransformChance < random.uniform(0.0, 1.0):\n",
        "        angle = 0.0 # Disable random angle\n",
        "        \n",
        "    if zoom != None and random.uniform(0.0, 1.0) > zoomTransformChance:\n",
        "        zoom = None\n",
        "        \n",
        "    if shiftX != None and random.uniform(0.0, 1.0) > shiftTransformChance:\n",
        "        shiftX = None\n",
        "        \n",
        "    if shiftY != None and random.uniform(0.0, 1.0) > shiftTransformChance:\n",
        "        shiftY = None\n",
        "\n",
        "    idx = 0\n",
        "    for img in slice_indices:\n",
        "        processedImage = ndi.rotate(brain_vol_data[:, :, round(img)], 90.0 + angle)\n",
        "        if zoom != None:\n",
        "            processedImage = clipped_zoom(processedImage, zoom)\n",
        "        if shiftX != None:\n",
        "            processedImage = ndi.shift(processedImage, [0.0, shiftX, 0.0])\n",
        "        if shiftY != None:\n",
        "            processedImage = ndi.shift(processedImage, [shiftY, 0.0, 0.0])\n",
        "        axs.flat[idx].imshow(np.squeeze(processedImage), cmap='gray')\n",
        "        axs.flat[idx].axis('off')\n",
        "        idx += 1\n",
        "        \n",
        "    plt.tight_layout()\n",
        "\n",
        "    image = fig2img(fig)\n",
        "\n",
        "    plt.close(fig) # Para que no muestre la im치gen\n",
        "    \n",
        "    return image"
      ],
      "metadata": {
        "id": "2w0W-yXe-GRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vODiu92PQdIL"
      },
      "outputs": [],
      "source": [
        "# CreateGrid transform\n",
        "class CreateGrid(object):\n",
        "    \"\"\"Creates a grid from the image\n",
        "    \"\"\"\n",
        "    def __init__(self, transformArgs = {}):\n",
        "        self.transformArgs = transformArgs\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        return transformGridImage(sample, **self.transformArgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX-5K8GGG-zT"
      },
      "outputs": [],
      "source": [
        "class RemoveTransparency(object):\n",
        "    def __call__(self, sample):\n",
        "      # La imagen se guarda con transparencia, removemos la dimension de indice 3\n",
        "      return sample[0:3, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmM3wjZ0Qfa4"
      },
      "outputs": [],
      "source": [
        "class ToLabelOutput(object):\n",
        "    def __call__(self, label):\n",
        "        if label == \"CN\":\n",
        "            return 0\n",
        "        elif label == \"AD\":\n",
        "            return 1\n",
        "        else:\n",
        "            return 2 # MCI, LMCI, EMCI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxq4R1JOQgyU"
      },
      "outputs": [],
      "source": [
        "class ADNIDataset(Dataset):\n",
        "    \"\"\"ADNI dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None, target_transform = None, cacheSize = 200):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.csv = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        # file cache almacena las rutas a cada item\n",
        "        self.filename_cache = [None] * len(self)\n",
        "        # item_cache directamente almacena los items procesados\n",
        "        self.cacheSize = cacheSize\n",
        "        self.item_cache = [None] * cacheSize\n",
        "\n",
        "    def __len__(self):\n",
        "      return int(len(self.csv))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        if self.cacheSize > 0 and self.item_cache[idx % self.cacheSize] != None:\n",
        "            item = self.item_cache[idx % self.cacheSize]\n",
        "            if item[\"id\"] == idx:\n",
        "                # item in cache\n",
        "                return item[\"image\"], item[\"label\"]\n",
        "            \n",
        "        studyID = self.csv.iloc[idx, 0]\n",
        "        subjectID = self.csv.iloc[idx, 1]\n",
        "        processFormat = self.csv.iloc[idx, 7]\n",
        "        date = self.csv.iloc[idx, 9]\n",
        "        diagnosis = self.csv.iloc[idx, 2]\n",
        "        \n",
        "        filename = self.filename_cache[idx]\n",
        "        \n",
        "        if filename == None:\n",
        "            rglob = '*'+str(studyID)+'*.nii'\n",
        "            samples = 0\n",
        "\n",
        "            for path in Path(self.root_dir).rglob(rglob):\n",
        "                filename = str(path)\n",
        "                samples =+ 1\n",
        "            \n",
        "            if samples > 1:\n",
        "                raise \"Mas de un sample. Error\"\n",
        "\n",
        "            self.filename_cache[idx] = filename\n",
        "\n",
        "        if not filename:\n",
        "            raise Exception(\"Not found filename for index \" + str(idx) + \" y studyID \" + studyID)\n",
        "            \n",
        "        brain_vol = nib.load(filename)\n",
        "\n",
        "        image = brain_vol\n",
        "        label = diagnosis\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        if self.cacheSize > 0 and self.item_cache[idx % self.cacheSize] == None:\n",
        "            # Storing item in cache\n",
        "            self.item_cache[idx % self.cacheSize] = {\n",
        "                \"id\": idx,\n",
        "                \"label\": label,\n",
        "                \"image\": image\n",
        "            }\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def printFile(text, file):\n",
        "  print(text)\n",
        "  if file != None:\n",
        "      file.write(text + \"\\n\")"
      ],
      "metadata": {
        "id": "tMPKNDmqyALS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW1D_vQnpzDk"
      },
      "source": [
        "# Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m44_ZbqJvsQ9"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=True, logFile = None):\n",
        "    f = None\n",
        "    if logFile != None:\n",
        "        f = open(logFile, \"w\")\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        printFile('Epoch {}/{}'.format(epoch, num_epochs - 1), f)\n",
        "        printFile('-' * 10, f)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        # No usamos el aux\n",
        "                        #outputs, aux_outputs = model(inputs)\n",
        "                        #loss1 = criterion(outputs, labels)\n",
        "                        #loss2 = criterion(aux_outputs, labels)\n",
        "                        #loss = loss1 + 0.4*loss2\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            printFile('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), f)\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                val_loss_history.append(epoch_loss)\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                train_loss_history.append(epoch_loss)\n",
        "            \n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    printFile('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60), f)\n",
        "    printFile('Best val Acc: {:4f}'.format(best_acc), f)\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    if logFile != None:\n",
        "        f.close()\n",
        "    return model, val_acc_history, val_loss_history, train_acc_history, train_loss_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl-UuMFJv0_S"
      },
      "outputs": [],
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuMUC0zqwFLw"
      },
      "source": [
        "# Initialize and reshape inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "e58701268e414ee494812df35b750951",
            "6259ea78745743d0a45ca7229584d68c",
            "539a7687bdd04c20af58658a4ffa8033",
            "180a408371204175a1cedc7102425283",
            "349e6d4f4f3243b1aabc569383bb96b5",
            "00ac5b6fc6f540c8b882bdcb85827b67",
            "249a799f1e0442ea9828c6b96ea9ac12",
            "3d2b03fed95c4480ab44db4571d684ed",
            "9005236086394b57ac7be7480bd6106d",
            "4e7e3926a4814c9b9e93afb967fe28c6",
            "aae9c7b1a5984bbd994229c617c19693"
          ]
        },
        "id": "GqZfuwYwwLw2",
        "outputId": "c6116d48-31e9-41c7-9429-6ab010fcbc80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/104M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e58701268e414ee494812df35b750951"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num featurs2048\n"
          ]
        }
      ],
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained, \n",
        "                                       aux_logits = True)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        # num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        # model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        print(\"num featurs\" + str(num_ftrs))\n",
        "        # Fuente: https://github.com/bdrad/petdementiapub/blob/master/petdementia_source.py\n",
        "        model_ft.fc = nn.Sequential(\n",
        "          nn.Linear(num_ftrs,1024),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(1024,num_classes),\n",
        "        )\n",
        "          \n",
        "        input_size = 512 \n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=usePretrained)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "# print(model_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfACeWNcwYqY",
        "outputId": "10a1584f-685b-4f4e-e342-6306b720c75a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ]
        }
      ],
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        CreateGrid(dataAugmentation),\n",
        "        transforms.ToTensor(),\n",
        "        RemoveTransparency(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        CreateGrid(),\n",
        "        transforms.ToTensor(),\n",
        "        RemoveTransparency(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "\n",
        "image_datasets = {\n",
        "    'train': ADNIDataset(trainDatasetCSV, imagesFolder, transform = data_transforms['train'], target_transform =ToLabelOutput(), cacheSize = trainCacheSize ),\n",
        "    'val': ADNIDataset(valDatasetCSV, imagesFolder, transform = data_transforms['val'], target_transform =ToLabelOutput(), cacheSize = validationCacheSize )\n",
        "}\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XciJ190PwerB",
        "outputId": "0c07aafd-a47f-49ba-c1d0-6f8be2d29d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.0.weight\n",
            "\t fc.0.bias\n",
            "\t fc.2.weight\n",
            "\t fc.2.bias\n"
          ]
        }
      ],
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(params_to_update, lr=learningRate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVJl5AvUqK13"
      },
      "outputs": [],
      "source": [
        "def test_model(model,dataloaders,device):\n",
        "    classStats = [{\n",
        "        'fn': 0,\n",
        "        'tn': 0,\n",
        "        'tp': 0,\n",
        "        'fp': 0,\n",
        "        'n': 0,\n",
        "    } for i in range(num_classes)]\n",
        "    correctlyPredicted = 0\n",
        "    n = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            # Iteramos para chequear estadisticas\n",
        "            for i, correctClass in enumerate(labels.data):\n",
        "              n += 1\n",
        "              predictedClass = int(preds[i].item())\n",
        "              correctClass = int(correctClass.item())\n",
        "              classStats[correctClass]['n'] += 1\n",
        "              if correctClass == predictedClass:\n",
        "                  correctlyPredicted += 1\n",
        "                  classStats[correctClass]['tp'] += 1\n",
        "                  for i in range(num_classes):\n",
        "                      if i != correctClass:\n",
        "                          classStats[correctClass]['tn'] += 1\n",
        "              else:\n",
        "                  classStats[correctClass]['fn'] += 1\n",
        "                  classStats[predictedClass]['fp'] += 1\n",
        "                  for i in range(num_classes):\n",
        "                      if i != correctClass and i != predictedClass:\n",
        "                          classStats[correctClass]['tn'] += 1\n",
        "    accuracy = correctlyPredicted * 1.0 / n\n",
        "    return classStats, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def printClassStats(stats):\n",
        "  recall = sensitivity = stats['tp'] / (stats['tp'] + stats['fn']) # prob positive test result\n",
        "  specificity = stats['tn'] / (stats['tn'] + stats['fp'])          # prob negative test result\n",
        "  if stats['tp'] + stats['fp'] > 0:\n",
        "    precision = stats['tp'] / (stats['tp'] + stats['fp'])          # prob of recognized positive actually correct\n",
        "  else:\n",
        "    precision = 1\n",
        "    printFile(\"Setting precision as 1 but no positive value has been reported, so this is placeholder\", f)\n",
        "  if precision + recall == 0:\n",
        "    printFile(\"Setting f1 as 0 because precision + recall is ZERO\", f)\n",
        "    f1 = 0.0\n",
        "  else:\n",
        "    f1 = 2 * (precision * recall) / ( precision + recall )\n",
        "  printFile(\"Sensitivity (%): \" + str(round(sensitivity * 100)), f)\n",
        "  printFile(\"Specificity (%): \" + str(round(specificity * 100)), f)\n",
        "  printFile(\"Precision  (%): \" + str(round(precision * 100)), f)\n",
        "  printFile(\"F1 Score  (%): \" + str(round(f1 * 100)), f)\n",
        "  printFile(\"Number of images: \" + str(stats['n']), f)\n",
        "  return recall, specificity, precision, f1"
      ],
      "metadata": {
        "id": "aK3auwSS05Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "D84am68jwlX6",
        "outputId": "cc22de5e-cbba-441e-c43b-68bc7d3b29dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Execution 0 begin ---\n",
            "Epoch 0/1\n",
            "----------\n",
            "train Loss: 0.6378 Acc: 0.6016\n",
            "val Loss: 0.6225 Acc: 0.6019\n",
            "Epoch 1/1\n",
            "----------\n",
            "train Loss: 0.5616 Acc: 0.6036\n",
            "val Loss: 0.8363 Acc: 0.6019\n",
            "Training complete in 210m 43s\n",
            "Best val Acc: 0.601852\n",
            "accuracy: 0.6018518518518519\n",
            "CN stats: \n",
            "Setting precision as 1 but no positive value has been reported, so this is placeholder\n",
            "Sensitivity (%): 0\n",
            "Specificity (%): 100\n",
            "Precision  (%): 100\n",
            "F1 Score  (%): 0\n",
            "Number of images: 54\n",
            "\n",
            "AD stats: \n",
            "Setting precision as 1 but no positive value has been reported, so this is placeholder\n",
            "Sensitivity (%): 0\n",
            "Specificity (%): 100\n",
            "Precision  (%): 100\n",
            "F1 Score  (%): 0\n",
            "Number of images: 32\n",
            "\n",
            "MCI stats: \n",
            "Sensitivity (%): 100\n",
            "Specificity (%): 75\n",
            "Precision  (%): 60\n",
            "F1 Score  (%): 75\n",
            "Number of images: 130\n",
            "--- Execution End ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "accuracyValues = []\n",
        "adStatValues = []\n",
        "cnStatValues = []\n",
        "mciStatValues = []\n",
        "for i in range(0, executions):\n",
        "    experimentExecutionName = experimentName + '_' + str(i)\n",
        "    print(\"--- Execution \" + str(i) + \" begin ---\")\n",
        "    # Setup the loss fxn\n",
        "    crossEntrophyWeigths = crossEntrophyWeigths.to(device)\n",
        "    criterion = nn.CrossEntropyLoss(crossEntrophyWeigths)\n",
        "\n",
        "    logFile = os.path.join(experimentOutputFolder, experimentExecutionName + '_train.log')\n",
        "\n",
        "    # Train and evaluate\n",
        "    model_ft, val_acc_hist, val_loss_hist, train_acc_hist, train_loss_hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"), logFile = logFile)\n",
        "\n",
        "    torch.save(model_ft.state_dict(), os.path.join(experimentOutputFolder, experimentExecutionName + '.pth'))\n",
        "\n",
        "    # validation accuracy\n",
        "    fig = plt.figure()\n",
        "    lst = [ x.cpu().item() for x in val_acc_hist ]\n",
        "    plt.plot(lst)\n",
        "    ax = plt.gca()\n",
        "    plt.text(0.05, 0.9, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.8, 'LR = ' + str(learningRate), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.7, 'batch = ' + str(batch_size), transform=ax.transAxes)\n",
        "    plt.suptitle(experimentExecutionName + ' (acc set de validacion)')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_val_acc.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # validation loss\n",
        "    fig = plt.figure()\n",
        "    plt.plot(val_loss_hist)\n",
        "    ax = plt.gca()\n",
        "    plt.text(0.05, 0.3, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.2, 'LR = ' + str(learningRate), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.1, 'batch = ' + str(batch_size), transform=ax.transAxes)\n",
        "    plt.suptitle(experimentExecutionName + ' (loss set de validacion)')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_val_loss.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # train accuracy\n",
        "    fig = plt.figure()\n",
        "    lst = [ x.cpu().item() for x in train_acc_hist ]\n",
        "    ax = plt.gca()\n",
        "    plt.text(0.05, 0.9, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.8, 'LR = ' + str(learningRate), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.7, 'batch = ' + str(batch_size), transform=ax.transAxes)\n",
        "    plt.plot(lst)\n",
        "    plt.suptitle(experimentExecutionName + ' (accuracy set de train)')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_train_acc.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # train loss\n",
        "    fig = plt.figure()\n",
        "    ax = plt.gca()\n",
        "    plt.text(0.05, 0.3, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.2, 'LR = ' + str(learningRate), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.1, 'batch = ' + str(batch_size), transform=ax.transAxes)\n",
        "    plt.plot(train_loss_hist)\n",
        "    plt.suptitle(experimentExecutionName + ' (Loss set de train)')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_train_loss.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    stats, accuracy = test_model(model_ft, dataloaders_dict, device)\n",
        "\n",
        "    print(\"accuracy: \" + str(accuracy))\n",
        "    accuracyValues.append(accuracy)\n",
        "\n",
        "    f = open(os.path.join(experimentOutputFolder, experimentExecutionName + \"_stats.txt\"), \"w\")\n",
        "    printFile(\"CN stats: \", f)\n",
        "    recall, specificity, precision, f1 = printClassStats(stats[0])\n",
        "    cnStatValues.append({\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"precision\": precision,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "    # AD\n",
        "    printFile(\"\\nAD stats: \", f)\n",
        "    recall, specificity, precision, f1 = printClassStats(stats[1])\n",
        "    adStatValues.append({\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"precision\": precision,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "    # MCI\n",
        "    printFile(\"\\nMCI stats: \", f)\n",
        "    recall, specificity, precision, f1 = printClassStats(stats[2])\n",
        "    mciStatValues.append({\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"precision\": precision,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "    f.close()\n",
        "\n",
        "    print(\"--- Execution End ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracyValues = torch.tensor(accuracyValues)\n",
        "std, mean = torch.std_mean(accuracyValues)\n",
        "f = open(os.path.join(\n",
        "    os.path.join(experimentOutputFolder, experimentName + '_results.txt')), \"w\")\n",
        "printFile(\"Final stats: \", f)\n",
        "printFile(\"Executions: \" + str(executions), f)\n",
        "printFile(\"Accuracy mean: \" + str(mean.item()), f)\n",
        "printFile(\"Accuracy std: \" + str(std.item()), f)\n",
        "printFile(\"Best accuracy: \" + str(accuracyValues.max().item()), f)\n",
        "printFile(\"Worst accuracy: \" + str(accuracyValues.min().item()), f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "WuiTfuCMd8j4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70661545-cb8b-4666-a150-90e4d9e1213f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final stats: \n",
            "Executions: 1\n",
            "Accuracy mean: 0.6018518805503845\n",
            "Accuracy std: nan\n",
            "Best accuracy: 0.6018518805503845\n",
            "Worst accuracy: 0.6018518805503845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC - AUC"
      ],
      "metadata": {
        "id": "xA-ShjPRUYxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sortByX(point):\n",
        "  return point[0]\n",
        "\n",
        "# Se necesita ordenar los puntos para llamar a torch.trapezoid con los puntos ordenados por la coordenada X\n",
        "def sortListsByX(x, y):\n",
        "    points = zip(x, y)\n",
        "    points = list(points)\n",
        "    points.sort(key=sortByX)\n",
        "    x, y = ([ a for a,b in points ], [ b for a,b in points ])\n",
        "    return x, y\n",
        "\n",
        "fig = plt.figure()\n",
        "ad_y = ad_tpr = [ x[\"recall\"] for x in adStatValues ]\n",
        "ad_x = ad_fpr = [ 1.0 - x[\"specificity\"] for x in adStatValues ]\n",
        "ad_x, ad_y = sortListsByX(ad_x, ad_y)\n",
        "\n",
        "cn_y = cn_tpr = [ x[\"recall\"] for x in cnStatValues ]\n",
        "cn_x = cn_fpr = [ 1.0 - x[\"specificity\"] for x in cnStatValues ]\n",
        "cn_x, cn_y = sortListsByX(cn_x, cn_y)\n",
        "\n",
        "mci_y = mci_tpr = [ x[\"recall\"] for x in mciStatValues ]\n",
        "mci_x = mci_fpr = [ 1.0 - x[\"specificity\"] for x in mciStatValues ]\n",
        "mci_x, mci_y = sortListsByX(mci_x, mci_y)\n",
        "\n",
        "decimals = 3\n",
        "ad_auc = round(torch.trapezoid(torch.tensor(ad_y), torch.tensor(ad_x)).item(), decimals)\n",
        "cn_auc = round(torch.trapezoid(torch.tensor(cn_y), torch.tensor(cn_x)).item(), decimals)\n",
        "mci_auc = round(torch.trapezoid(torch.tensor(mci_y), torch.tensor(mci_x)).item(), decimals)\n",
        "\n",
        "plt.title(experimentName + \" ROC\")\n",
        "\n",
        "plt.plot(ad_fpr, ad_tpr)\n",
        "plt.plot(cn_fpr, cn_tpr)\n",
        "plt.plot(mci_fpr, mci_tpr)\n",
        "\n",
        "plt.legend([\"AD (\"+str(ad_auc)+\")\", \"CN (\"+str(cn_auc)+\")\", \"MCI (\"+str(mci_auc)+\")\"], loc =\"lower right\")\n",
        "plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_auc_roc.png'))\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mmKtfcWNUOIR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "68c3bcc5-c89b-476a-f55c-f612d9c756b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbiElEQVR4nO3de5hV1Z3m8e8bRDEJ3qC8UUZupdzEAAXSk6TjBBmBJxbjaAykReO1Y4fgTCQTEibGSyYR40TTaU2aTmwhmZQx9oik1XhpMCY+ohaiiKgIWITCwpACb4moyG/+OLvKU0VdTlWdoorF+3me83j23muvvdY5Pm9t1t5nbUUEZma27/tQdzfAzMyKw4FuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZ5JJ0qqSZvuVrSad3ZJrNCOdCtWVmQvSupf5P1qySFpIFdeOxGodqJekLSXyS9lb1eK0b7mjnOVZJ+UaS6QtLQVrZ/UdL7WX/ekPSMpM82KXOQpO9J+qOktyW9JOlrktSk3OmSHpH0pqRtkn4nqaIY/bDu4UC31rwMzKxfkHQS8OHua84HJB1QYNGTI+Kj2euwLm3U3vNYRHwUOAy4BbhdUn7ffg1MAqYBfYFZwKXAD+sLSDo7K7cYKAWOAq4EztgbHbCu4UC31vwcOC9v+XxyAdBA0sOSLs5b/qKkP+QtD5P0oKTtkl6UdE7etmmS1mZniFskzZX0EeA+4Ni8M+tjs7PgOyX9QtIbwBclTZD0mKTXJNVK+idJB7bVqaZnwZJuk/SdjnxAkqYA3wQ+n7X1mWz9oZJ+lrVri6TvSOqVbRuanQ2/LunPkn6VrX8kq/aZrK7Pt3bsiNhN7jv6CFCW1TEJ+C/AWRGxJiJ2RcQK4Fzgy9mxBfwAuDYifhoRr0fE7oj4XURc0pHPwXoGB7q1ZgVwiKThWRjNAAoeWsjC+UHgl8CR2f63SBqRFfkZ8PcR0RcYBSyLiL8AU4FX8s6sX8nKTwfuJHdm+n+B94H/AfQH/obcWek/dKbD7RURvwW+C/wqa+vJ2abbgF3AUGAMuZCt/8N3LfAAcDi5s+MfZXX9bba9/l8Vv2rt2Nl3cgHwHrApWz0ZeDwiNjdp5+NADbnP6ETgOHKfpSXEgW5tqT9Lnww8D2xpx76fBaoj4l+zM8VVwL8Bn8u2vweMkHRIROyIiKfaqO+xiFiSnU2+HRErI2JFVnc18M/Ap5vs81R2Bv+apH9sR9s7TNJR5IY7/ntE/CUi/gTcSO4PGuT6fTxwbETsjIg/tFBVSyZm1wN2AjcA52bHgNwft9oW9qvNtvfLW7aEONCtLT8HvgB8kSbDLQU4HjglL1BfA/4OODrbfha54NuUDUH8TRv1NTrrlHSCpH+XtDUbhvkuucDKNzYiDstec9rZ/o46HugN1Ob1+5/J/SsF4H8CAp6Q9JykC9tZ/4rsesDhwFLgU3nb/gwc08J+x2Tb6/KWLSEOdGtVRGwid3F0GvD/minyFxpfKD067/1m4Hd5gXpYNpRwWVb3kxExnVzQLQHuqD9sS81psvxj4AWgLCIOITeWrT322tNfW2lzRzRt12bgHaB/Xr8PiYiRABGxNSIuiYhjgb8nNwzV4p0tLR404i3gMmCWpDHZ6ofI/RE9Lr+spFPIDbMsA17M2nhWe49pPZsD3QpxEfCZbHy7qaeB/ybpw1koXZS37d+BEyTNktQ7e43PxuQPlPR3kg6NiPeAN4Dd2X6vAv0kHdpGu/pm+70laRi5cCvE08AXJPXKLmo2HaZpr1eBgZI+BBARteTGyP+PpEMkfUjSEEmfBpD0OUml2b47yP1ByO/74EIPHBHbgZ+Su0OFiHgI+A/g3ySNzPo4kdy1jx9HxEuRewjCV4FvSbogr42flLSwcx+FdScHurUpIjZERFULm28E3iUXRIvIXays3+9NchcDZwCvAFuBBcBBWZFZQHU2XPIlcsMxRMQLQCWwMRuyOLaFY88lNxz0JvAvQKsXEfNcTu72vPohoCUF7teSX2f/rZNUfx3gPOBAYC250L6TD4Y4xgOPS3qL3JDJ5RGxMdt2FbAo63fDHUFtuAmYJml0tnwWsBz4LfAWuTD/GfCV+h0i4k7g88CF5L6bV4HvAHcXeEzrgeQnFpmZpcFn6GZmiXCgmxVA0n15P3TKf32zu9tmVs9DLmZmiSh0Poyi69+/fwwcOLC7Dm9mtk9auXLlnyOipLlt3RboAwcOpKqqpRsnzMysOZI2tbTNY+hmZolwoJuZJcKBbmaWCAe6mVkiHOhmZoloM9Al3SrpT5LWtLBdkv5R0npJqyWNLX4zzcysLYWcod8GTGll+1Ryj78qI/fcwh93vllmZtZebQZ6RDwCbG+lyHRgceSsAA6T5Inzzcz2smKMoQ+g8ZNkarJ1e5B0qaQqSVXbtm0rwqHNzKzeXr0oGhELI6I8IspLSpr95aqZmXVQMQJ9C7lHW9UrpX0PEjYzsyIoRqAvBc7L7naZCLyePYLLzMz2ojYn55JUCZwK9JdUA3yb3BPNiYifAPeSe4DwenIP372gqxprZmYtazPQI2JmG9sD+HLRWmRmZh3iX4qamSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIgoKdElTJL0oab2kec1s/5ik5ZJWSVotaVrxm2pmZq1pM9Al9QJuBqYCI4CZkkY0Kfa/gDsiYgwwA7il2A01M7PWFXKGPgFYHxEbI+Jd4HZgepMyARySvT8UeKV4TTQzs0IUEugDgM15yzXZunxXAedKqgHuBb7SXEWSLpVUJalq27ZtHWiumZm1pFgXRWcCt0VEKTAN+LmkPeqOiIURUR4R5SUlJUU6tJmZQWGBvgU4Lm+5NFuX7yLgDoCIeAzoA/QvRgPNzKwwhQT6k0CZpEGSDiR30XNpkzJ/BCYBSBpOLtA9pmJmthe1GegRsQuYDdwPPE/ubpbnJF0jqSIrdgVwiaRngErgixERXdVoMzPb0wGFFIqIe8ld7Mxfd2Xe+7XAJ4rbNDMzaw//UtTMLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRBQU6JKmSHpR0npJ81ooc46ktZKek/TL4jbTzMzackBbBST1Am4GJgM1wJOSlkbE2rwyZcA3gE9ExA5JR3ZVg83MrHmFnKFPANZHxMaIeBe4HZjepMwlwM0RsQMgIv5U3GaamVlbCgn0AcDmvOWabF2+E4ATJD0qaYWkKc1VJOlSSVWSqrZt29axFpuZWbOKdVH0AKAMOBWYCfyLpMOaFoqIhRFRHhHlJSUlRTq0mZlBYYG+BTgub7k0W5evBlgaEe9FxMvAOnIBb2Zme0khgf4kUCZpkKQDgRnA0iZllpA7O0dSf3JDMBuL2E4zM2tDm4EeEbuA2cD9wPPAHRHxnKRrJFVkxe4H6iStBZYDX4uIuq5qtJmZ7UkR0S0HLi8vj6qqqm45tpnZvkrSyogob26bfylqZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiSgo0CVNkfSipPWS5rVS7ixJIam8eE00M7NCtBnoknoBNwNTgRHATEkjminXF7gceLzYjTQzs7YVcoY+AVgfERsj4l3gdmB6M+WuBRYAO4vYPjMzK1AhgT4A2Jy3XJOtayBpLHBcRNzTWkWSLpVUJalq27Zt7W6smZm1rNMXRSV9CPgBcEVbZSNiYUSUR0R5SUlJZw9tZmZ5Cgn0LcBxecul2bp6fYFRwMOSqoGJwFJfGDUz27sKCfQngTJJgyQdCMwAltZvjIjXI6J/RAyMiIHACqAiIqq6pMVmZtasNgM9InYBs4H7geeBOyLiOUnXSKro6gaamVlhDiikUETcC9zbZN2VLZQ9tfPNMjOz9vIvRc3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLxAGFFJI0Bfgh0Av4aURc12T7V4GLgV3ANuDCiNhU5Laa2T7kvffeo6amhp07d3Z3U/ZJffr0obS0lN69exe8T5uBLqkXcDMwGagBnpS0NCLW5hVbBZRHxF8lXQZcD3y+Xa03s6TU1NTQt29fBg4ciKTubs4+JSKoq6ujpqaGQYMGFbxfIUMuE4D1EbExIt4FbgemNzn48oj4a7a4AigtuAVmlqSdO3fSr18/h3kHSKJfv37t/tdNIYE+ANict1yTrWvJRcB9zW2QdKmkKklV27ZtK7yVZrZPcph3XEc+u6JeFJV0LlAOfL+57RGxMCLKI6K8pKSkmIc2M9vvFRLoW4Dj8pZLs3WNSDoNmA9URMQ7xWmemVnnLFmyBEm88MILDeuqq6s5+OCDGTNmDMOHD2fChAncdtttLdaxatUqLrroIiA3vj1nzhyGDh3K6NGjeeqpp5rdZ+XKlZx00kkMHTqUOXPmEBEAzJ07l2XLlhWvg/kiotUXuQunG4FBwIHAM8DIJmXGABuAsrbqq3+NGzcuzCxda9eu7e4mRETEOeecE5/85CfjyiuvbFj38ssvx8iRIxuWN2zYECeffHLceuutzdZx9tlnx9NPPx0REffcc09MmTIldu/eHY899lhMmDCh2X3Gjx8fjz32WOzevTumTJkS9957b0REVFdXx+TJkwtqe3OfIVAVLeRqm3e5RMQuSbOB+8ndtnhrRDwn6Zqs4qXkhlg+Cvw6G/f5Y0RUFPlvj5nto67+zXOsfeWNotY54thD+PYZI1st89Zbb/GHP/yB5cuXc8YZZ3D11Vc3W27w4MH84Ac/4IorruCCCy5otO3NN99k9erVnHzyyQDcfffdnHfeeUhi4sSJvPbaa9TW1nLMMcc07FNbW8sbb7zBxIkTATjvvPNYsmQJU6dO5fjjj6euro6tW7dy9NFHd+Yj2ENBY+gRcW9EnBARQyLif2frrszCnIg4LSKOioiPZy+HuZl1u7vvvpspU6Zwwgkn0K9fP1auXNli2bFjxzYalqlXVVXFqFGjGpa3bNnCccd9MApdWlrKli2NR6G3bNlCaWlpi2XGjh3Lo48+2qE+taagHxaZmXVGW2fSXaWyspLLL78cgBkzZlBZWcm4ceOaLRvZGHdTtbW1FPsmjiOPPJJXXnmlqHWCA93MErV9+3aWLVvGs88+iyTef/99JPH97zd7Ex6rVq1i+PDhe6w/+OCDG90PPmDAADZv/uBO7pqaGgYMaHwn94ABA6ipqWmxzM6dOzn44IM73LeWeC4XM0vSnXfeyaxZs9i0aRPV1dVs3ryZQYMG8fvf/36PstXV1cydO5evfOUre2wbPnw469evb1iuqKhg8eLFRAQrVqzg0EMPbTR+DnDMMcdwyCGHsGLFCiKCxYsXM336B7/HXLduXaNhnGJxoJtZkiorKznzzDMbrTvrrLOorKwEYMOGDQ23LZ5zzjnMmTNnjwuiAMOGDeP111/nzTffBGDatGkMHjyYoUOHcskll3DLLbc0lP34xz/e8P6WW27h4osvZujQoQwZMoSpU6cCuTlu1q9fT3l5edH7rJbGjbpaeXl5VFVVdcuxzazrPf/8880OYeyLbrzxRvr27cvFF1/c6bruuusunnrqKa699to2yzb3GUpaGRHN/jXwGbqZWRsuu+wyDjrooKLUtWvXLq644oqi1NWUL4qambWhT58+zJo1qyh1fe5znytKPc3xGbqZWSIc6GZmiXCgm5klwoFuZpYIB7qZJWvr1q3MmDGDIUOGMG7cOKZNm8a6deuorq5GEj/60Y8ays6ePbvFKXRvuukmFi9eDOR+gTp58mTKysqYPHkyO3bsaHafRYsWUVZWRllZGYsWLWpYf9ppp7W4T2c50M0sSRHBmWeeyamnnsqGDRtYuXIl3/ve93j11VeB3HwqP/zhD3n33XdbrWfXrl3ceuutfOELXwDguuuuY9KkSbz00ktMmjSJ6667bo99tm/fztVXX83jjz/OE088wdVXX90Q4rNmzWr0Y6Ri8m2LZtb17psHW58tbp1HnwRT9wzTesuXL6d379586UtfalhXPwVudXU1JSUlfOITn2DRokVccsklLdazbNkyxo4dywEH5OLy7rvv5uGHHwbg/PPP59RTT2XBggWN9rn//vuZPHkyRxxxBACTJ0/mt7/9LTNnzqSiooJPfepTzJ8/v0Pdbo3P0M0sSWvWrGlxZsV6X//617nhhht4//33Wyzz6KOPNqrn1VdfbZi75eijj24448/X2hS7hx9+OO+88w51dXXt6k8hfIZuZl2vlTPp7jR48GBOOeUUfvnLX7ZYpra2tsUpDCR16GHO9dPn9uvXr937tsZn6GaWpJEjR7b6QIt63/zmN1mwYEGL86E3nT73qKOOora2FsiF/ZFHHrnHPm1Nsevpc83M2uEzn/kM77zzDgsXLmxYt3r16j2mzx02bBgjRozgN7/5TbP1NDd9bv1dK4sWLWo0LW69008/nQceeIAdO3awY8cOHnjgAU4//XQgd7F269atDBw4sLNd3IMD3cySJIm77rqLhx56iCFDhjBy5Ei+8Y1vNPscz/nz5zd6IEW+qVOn8sgjjzQsz5s3jwcffJCysjIeeugh5s2bB+QeVVc/G+MRRxzBt771LcaPH8/48eO58sorGy6Qrly5kokTJzZcZC0mT59rZl0ipelzzzzzTK6//nrKyso6Xdfll19ORUUFkyZNarOsp881Myuy6667rmHcvLNGjRpVUJh3hO9yMTNrw4knnsiJJ55YlLpau+e9s3yGbmaWCAe6mVkiHOhmZolwoJuZJcKBbmbJksS5557bsLxr1y5KSkr47Gc/27Duvvvuo7y8nBEjRjBmzJiGBzhfddVV3HDDDc3W21On03Wgm1myPvKRj7BmzRrefvttAB588MFGP8Ffs2YNs2fP5he/+AVr166lqqqKoUOHtlpnT55O17ctmlmXW/DEAl7Y/kJR6xx2xDC+PuHrbZabNm0a99xzD2effTaVlZXMnDmz4ef/119/PfPnz2fYsGEA9OrVi8suu6zV+nrydLo+QzezpM2YMYPbb7+dnTt3snr1ak455ZSGbYVMsdtUT55O12foZtblCjmT7iqjR4+murqayspKpk2b1un6evJ0ugWdoUuaIulFSeslzWtm+0GSfpVtf1zSwE61ysysiCoqKpg7dy4zZ85stL7QKXbz9eTpdNsMdEm9gJuBqcAIYKakEU2KXQTsiIihwI3AAszMeogLL7yQb3/725x00kmN1n/ta1/ju9/9LuvWrQNg9+7d/OQnP2m1rp48nW4hZ+gTgPURsTEi3gVuB5q2eDpQfx/OncAkdeTfHWZmXaC0tJQ5c+bssX706NHcdNNNzJw5k+HDhzNq1Cg2btzYal09eTrdNqfPlXQ2MCUiLs6WZwGnRMTsvDJrsjI12fKGrMyfm9R1KXApwMc+9rFxmzZt6nQHzKxnSmn63Kb21nS6PXr63IhYGBHlEVFeUlKyNw9tZlY0PXU63ULO8bcAx+Utl2brmitTI+kA4FCg+I+0NjPrAXrqdLqFnKE/CZRJGiTpQGAGsLRJmaXA+dn7s4Fl0V2PQjKzHsMx0HEd+ezaDPSI2AXMBu4HngfuiIjnJF0jqSIr9jOgn6T1wFeBPW5tNLP9S58+fairq3Ood0BEUFdXR58+fdq1n58pamZd4r333qOmpqbRPdtWuD59+lBaWkrv3r0brW/toqh/KWpmXaJ3794MGjSou5uxX/FcLmZmiXCgm5klwoFuZpaIbrsoKmkb0NGfivYH/txmqfTsj/12n/cP7nPhjo+IZn+Z2W2B3hmSqlq6ypuy/bHf7vP+wX0uDg+5mJklwoFuZpaIfTXQF3Z3A7rJ/thv93n/4D4XwT45hm5mZnvaV8/QzcysCQe6mVkielygd+aB1JK+ka1/UdLpe7PdndHRPksaKOltSU9nr9YfhtiDFNDnv5X0lKRd2VOz8redL+ml7HV+0317qk72+f2877np9NU9WgH9/qqktZJWS/oPScfnbUv1u26tzx3/riOix7yAXsAGYDBwIPAMMKJJmX8AfpK9nwH8Kns/Iit/EDAoq6dXd/epi/s8EFjT3X3ooj4PBEYDi4Gz89YfAWzM/nt49v7w7u5TV/Y52/ZWd/ehC/v9n4EPZ+8vy/v/O+Xvutk+d/a77mln6J15IPV04PaIeCciXgbWZ/X1dPvjQ7jb7HNEVEfEamB3k31PBx6MiO0RsQN4EJiyNxrdSZ3p876skH4vj4i/ZosryD0VDdL+rlvqc6f0tEAfAGzOW67J1jVbJnIP33gd6Ffgvj1RZ/oMMEjSKkm/k/Sprm5skXTmu0r5e25NH0lVklZI+q/FbVqXam+/LwLu6+C+PUVn+gyd+K49H/q+rRb4WETUSRoHLJE0MiLe6O6GWdEdHxFbJA0Glkl6NiI2dHejiknSuUA58Onubsve0kKfO/xd97Qz9PY8kJomD6QuZN+eqMN9zoaX6gAiYiW5cbsTurzFndeZ7yrl77lFEbEl++9G4GFgTDEb14UK6rek04D5QEVEvNOefXugzvS5c991d19AaHKh4AByFz4G8cHFhJFNynyZxhcI78jej6TxRdGN7BsXRTvT55L6PpK7ALMFOKK7+1SMPueVvY09L4q+TO4i2eHZ+9T7fDhwUPa+P/ASTS6y9dRXgf9/jyF3MlLWZH2y33Urfe7Ud93tnW/mw5gGrMs6Oz9bdw25v2IAfYBfk7vo+QQwOG/f+dl+LwJTu7svXd1n4CzgOeBp4CngjO7uSxH7PJ7c2ONfyP0L7Lm8fS/MPov1wAXd3Zeu7jPwn4Bns2B4Friou/tS5H4/BLya/X/8NLB0P/ium+1zZ79r//TfzCwRPW0M3czMOsiBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVki/j/x1BAf5YxTEwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ad_y = ad_tpr = [ x[\"recall\"] for x in adStatValues ]\n",
        "ad_x = ad_fpr = [ 1.0 - x[\"specificity\"] for x in adStatValues ]\n",
        "ad_x, ad_y = sortListsByX(ad_x, ad_y)\n",
        "\n",
        "decimals = 3\n",
        "ad_auc = round(torch.trapezoid(torch.tensor(ad_y), torch.tensor(ad_x)).item(), decimals)\n",
        "\n",
        "plt.title(experimentName + \" AD ROC\")\n",
        "\n",
        "plt.plot(ad_fpr, ad_tpr)\n",
        "\n",
        "plt.legend([\"AD (\"+str(ad_auc)+\")\"], loc =\"lower right\")\n",
        "plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_auc_roc_ad.png'))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "yUUyX_2fpMSX",
        "outputId": "fc7e4094-7365-4cfc-82c0-81ab7fde3aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "cn_y = cn_tpr = [ x[\"recall\"] for x in cnStatValues ]\n",
        "cn_x = cn_fpr = [ 1.0 - x[\"specificity\"] for x in cnStatValues ]\n",
        "cn_x, cn_y = sortListsByX(cn_x, cn_y)\n",
        "\n",
        "decimals = 3\n",
        "cn_auc = round(torch.trapezoid(torch.tensor(cn_y), torch.tensor(cn_x)).item(), decimals)\n",
        "\n",
        "plt.title(experimentName + \" CN ROC\")\n",
        "\n",
        "plt.plot(cn_fpr, cn_tpr)\n",
        "\n",
        "plt.legend([\"CN (\"+str(cn_auc)+\")\"], loc =\"lower right\")\n",
        "plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_auc_roc_cn.png'))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "8hxzslmopMju",
        "outputId": "7ceb9737-459c-4729-ffb2-59d4efc7b9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAY7ElEQVR4nO3dfZRV9X3v8fdHQNH6wIM8yaCjOFXB1CaOqDc3t1QYQdcVNDEtmmVIq7Fp67o2WbaixAeMqwFronmyLY1eJ7ZGU1sraVIVVPJ0U3XG2ETiAyOSMjyJMBrRAKLf+8fe4OF4hjlnzpk5jL/Pa6295uzf/u19vr8Z1v6cvX+bGUUEZmaWrv3qXYCZmdWXg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzPZC0lRJnQXrqyVNr2dNZrXmILCy5CfAHZIOL2r/maSQ1NiH773HybiK44SkNyRtzZdXa1Ffife5XtI/1uhYIenYHvqMk3S7pPWSXpf0nKQFkn6r4Bi/kLRfwT43Srqzm+NNlfRO/j16XdLzkv6oqI8k/aWklZJ+I+m/JX1R0gFF/aZI+r6kVyVtkfRE8bGs/hwEVomXgAt2rUj6AHBQ/cp5l6TBZXY9KSIOzpdhfVpUP5A0AvgpcCBwekQcArQAw4CJBV2PAOZUcOh1EXEwcCjwWeAfJB1XsP2rwKXAJ4FDgLOAacB3Cmo7HXgU+AFwLDAS+NO8r+1LIsKLlx4XYDXweeDJgrabgflAAI1523LgkoI+nwJ+XLB+PLAU2AI8D/xBwbazgV8CrwNrgSuA3wJ+A7wDbM2XI4DrgfuAfwR+DVwCTCE7Kb4KrAe+DuxfcPwAji0xtj3agTuBG/PXU4HOou/D9L18n2YCO4C38lr/K28/DLg9r2stcCMwKN92LNnJ8jXgFeDevP2HeW1v5Mf6wxLvdyPwC2C/vdQUwJXASmBwwX53dtN/jzHnbS8DH89fNwFvA1OK+kwAtgNn5Os/Br5R73+7XnpefEVglfhP4FBJJ0gaRPYJs+xbIPmtiqXA3cDofP/bJE3Ku9wO/Elkn2pPBB6NiDfIPkGui3c/ya/L+88mC4NhwD+RnZw+CxwOnE72CfXPqhlwpSLiQeCvyU7mB0fESfmmO4GdZCf9DwJnkoUXwBeAh4HhQAPwtfxY/yvfvusq5t4Sbzkd+NeIeKeH0v6VLDA/Vcl4JO0naRbZ97Qjb55GFhRPFPaNiDVk/0ZaJB1E9jO4r5L3s/pwEFil7iK7HdACPEv26bZc/xtYHRH/NyJ2RsTPgH8BPp5vfwuYJOnQiOiKiKd6ON5PI+LfIuKdiPhNRLRHxH/mx14N/D3we0X7PJXfr35V0lcrqL3XJI0hu9r5i4h4IyJeBm7h3Vs1bwFHAUdExLaI+HEFhx9JdpXRkwCuAa6RtH8Z/Y/I51B+A9wPfC7/eUEWCt295/p8+3Cy80s5tVmdOQisUncBF5J9svxWhfseBZxacCJ+FfgEMDbf/jGyE+avJP0gv8e8N2sKVyT9tqR/l7RB0q/JPpkfXrTPhyJiWL78nwrr762jgCHA+oJx/z3ZVRHAXwECnpC0QtIfV3DszcC4cjpGxPeBTuBPyui+LrI5lEPJ5gPOKNj2yl7ec1y+vYvsdl5ZtVl9OQisIhHxK7JJ47PJbjcUe4M9J5DHFrxeA/yg4EQ8LL/l8af5sZ+MiNlkJ8h/492Jx+5+V3px+98CzwFNEXEocDXZCbYnb+6l5t4ormsN2b3zwwvGfWhETAaIiA0R8emIOILsJH1bT08KFVgGnFf4RFAP5pN9X8qa5I+I7WTzCx+QdG7e/CgwQdKUwr6SJgCnAY9ExJtk8zUfK7MuqyMHgfXGxWQTgm+U2PY08FFJB+Uns4sLtv078NuSLpI0JF9Oyecc9pf0CUmHRcRbZPezd9333giMlHRYD3Udku+3VdLxZE+olONp4EJJgyTN5L23kyq1EWjcdXKOiPVkcwBfknRoft99oqTfA5D0cUkN+b5dZEFSOPZj9vJeXyb71N4q6aj8eOMlfVnS7xR3jojlwDPA3HIHExE7gC8B1+brLwB/B/yTpNPy79tkstt8yyJiWb7rXwGfyh8zHZnXdpKke8p9b+sfDgKrWES8GBFt3Wy+heypmY1AK9kk7q79XiebJJ0DrAM2AIuAXc+eXwSszm/rfIbsthER8RzwbWBVfmvliG7e+wqy21avA/8AlJpcLeVy4Byyp40+QXY1Uo1/zr9ulrRrnuOTwP5kT0V1kU2i7rptcgrwuKStwBLg8ohYlW+7nuwk/6qkPyh+o4jYAvwPsnmGxyW9DjxC9gRSR3H/3OeBERWO6Q7gSEnn5OuXAd8ke1hgK/Ag2RNju68AIuL/kd1SOoPsZ7cFWAx8v8L3tj6mCP+FMjOzlPmKwMwscQ4Cs16Q9B8Fv6qicLm63rWZVcq3hszMElfu72fZpxx++OHR2NhY7zLMzAaU9vb2VyJiVHH7gAyCxsZG2tq6e2jFzMxKkfSrUu2eIzAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS1xNgkDSTEnPS+qQNK/E9gMk3Ztvf1xSY9H2IyVtlXRFLeoxM7PyVR0EkgYB3wDOAiYBF0iaVNTtYqArIo4FbgEWFW3/MvAf1dZiZmaVq8UVwRSgIyJWRcQO4B5gdlGf2UBr/vo+YJokAUg6F3gJWFGDWszMrEK1CILxwJqC9c68rWSfiNgJvAaMlHQwcCWwoKc3kXSppDZJbZs2bapB2WZmBvWfLL4euCUitvbUMSIWR0RzRDSPGjWq7yszM0vE4BocYy0woWC9IW8r1adT0mDgMGAzcCpwvqSbgGHAO5K2RcTXa1CXmZmVoRZB8CTQJOloshP+HODCoj5LgLnAT4HzgUcjIoCP7Oog6Xpgq0PAzKx/VR0EEbFT0mXAQ8Ag4I6IWCHpBqAtIpYAtwN3SeoAtpCFhZmZ7QOUfTAfWJqbm6Otra3eZZiZDSiS2iOiubi93pPFZmZWZw4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PE1SQIJM2U9LykDknzSmw/QNK9+fbHJTXm7S2S2iX9Iv96Ri3qMTOz8lUdBJIGAd8AzgImARdImlTU7WKgKyKOBW4BFuXtrwDnRMQHgLnAXdXWY2ZmlanFFcEUoCMiVkXEDuAeYHZRn9lAa/76PmCaJEXEzyJiXd6+AjhQ0gE1qMnMzMpUiyAYD6wpWO/M20r2iYidwGvAyKI+HwOeiojtNajJzMzKNLjeBQBImkx2u+jMvfS5FLgU4Mgjj+ynyszM3v9qcUWwFphQsN6Qt5XsI2kwcBiwOV9vAO4HPhkRL3b3JhGxOCKaI6J51KhRNSjbzMygNkHwJNAk6WhJ+wNzgCVFfZaQTQYDnA88GhEhaRjwPWBeRPykBrWYmVmFqg6C/J7/ZcBDwLPAdyJihaQbJM3Ku90OjJTUAXwO2PWI6WXAscC1kp7Ol9HV1mRmZuVTRNS7hoo1NzdHW1tbvcswMxtQJLVHRHNxu/9nsZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSWuJkEgaaak5yV1SJpXYvsBku7Ntz8uqbFg21V5+/OSZtSiHjMzK1/VQSBpEPAN4CxgEnCBpElF3S4GuiLiWOAWYFG+7yRgDjAZmAnclh/PzMz6SS2uCKYAHRGxKiJ2APcAs4v6zAZa89f3AdMkKW+/JyK2R8RLQEd+PDMz6ye1CILxwJqC9c68rWSfiNgJvAaMLHNfACRdKqlNUtumTZtqULaZmcEAmiyOiMUR0RwRzaNGjap3OWZm7xu1CIK1wISC9Ya8rWQfSYOBw4DNZe5rZmZ9qBZB8CTQJOloSfuTTf4uKeqzBJibvz4feDQiIm+fkz9VdDTQBDxRg5rMzKxMg6s9QETslHQZ8BAwCLgjIlZIugFoi4glwO3AXZI6gC1kYUHe7zvAL4GdwJ9HxNvV1mRmZuVT9sF8YGlubo62trZ6l2FmNqBIao+I5uL2ATNZbGZmfcNBYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWuKqCQNIISUslrcy/Du+m39y8z0pJc/O2gyR9T9JzklZIWlhNLWZm1jvVXhHMAx6JiCbgkXx9D5JGANcBpwJTgOsKAuPmiDge+CDwYUlnVVmPmZlVqNogmA205q9bgXNL9JkBLI2ILRHRBSwFZkbEmxHxGEBE7ACeAhqqrMfMzCpUbRCMiYj1+esNwJgSfcYDawrWO/O23SQNA84hu6owM7N+NLinDpKWAWNLbJpfuBIRISkqLUDSYODbwFcjYtVe+l0KXApw5JFHVvo2ZmbWjR6DICKmd7dN0kZJ4yJivaRxwMsluq0FphasNwDLC9YXAysj4tYe6lic96W5ubniwDEzs9KqvTW0BJibv54LPFCiz0PAmZKG55PEZ+ZtSLoROAz4iyrrMDOzXqo2CBYCLZJWAtPzdSQ1S/omQERsAb4APJkvN0TEFkkNZLeXJgFPSXpa0iVV1mNmZhVSxMC7y9Lc3BxtbW31LsPMbECR1B4RzcXt/p/FZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmlriqgkDSCElLJa3Mvw7vpt/cvM9KSXNLbF8i6ZlqajEzs96p9opgHvBIRDQBj+Tre5A0ArgOOBWYAlxXGBiSPgpsrbIOMzPrpWqDYDbQmr9uBc4t0WcGsDQitkREF7AUmAkg6WDgc8CNVdZhZma9VG0QjImI9fnrDcCYEn3GA2sK1jvzNoAvAF8C3uzpjSRdKqlNUtumTZuqKNnMzAoN7qmDpGXA2BKb5heuRERIinLfWNLvAhMj4rOSGnvqHxGLgcUAzc3NZb+PmZntXY9BEBHTu9smaaOkcRGxXtI44OUS3dYCUwvWG4DlwOlAs6TVeR2jJS2PiKmYmVm/qfbW0BJg11NAc4EHSvR5CDhT0vB8kvhM4KGI+NuIOCIiGoH/CbzgEDAz63/VBsFCoEXSSmB6vo6kZknfBIiILWRzAU/myw15m5mZ7QMUMfButzc3N0dbW1u9yzAzG1AktUdEc3G7/2exmVniepwsNjOrt7feeovOzk62bdtW71IGhKFDh9LQ0MCQIUPK6u8gMLN9XmdnJ4cccgiNjY1Iqnc5+7SIYPPmzXR2dnL00UeXtY9vDZnZPm/btm2MHDnSIVAGSYwcObKiqycHgZkNCA6B8lX6vXIQmJklzkFgZlaGDRs2MGfOHCZOnMjJJ5/M2WefzQsvvMDq1auRxNe+9rXdfS+77DLuvPPOkse59dZb+da3vgXAli1baGlpoampiZaWFrq6ukru09raSlNTE01NTbS2tu5unz59erf7VMJBYGbWg4jgvPPOY+rUqbz44ou0t7fzxS9+kY0bNwIwevRovvKVr7Bjx469Hmfnzp3ccccdXHjhhQAsXLiQadOmsXLlSqZNm8bChQvfs8+WLVtYsGABjz/+OE888QQLFizYffK/6KKLuO2226oen58aMrMBZcF3V/DLdb+u6TEnHXEo150zudvtjz32GEOGDOEzn/nM7raTTjoJgNWrVzNq1Cg+/OEP09rayqc//eluj/Poo4/yoQ99iMGDs1PvAw88wPLlywGYO3cuU6dOZdGiRXvs89BDD9HS0sKIESMAaGlp4cEHH+SCCy5g1qxZfOQjH2H+/D1+B2jFfEVgZtaDZ555hpNPPnmvfa688kpuvvlm3n777W77/OQnP9njOBs3bmTcuHEAjB07dvcVRqG1a9cyYcKE3esNDQ2sXbsWgOHDh7N9+3Y2b95c0XiK+YrAzAaUvX1yr6djjjmGU089lbvvvrvbPuvXr+eEE04ouU1Sr56MGj16NOvWrWPkyJEV77uLrwjMzHowefJk2tvbe+x39dVXs2jRIrr7HW4HHnjgHs/3jxkzhvXrs7/ttX79ekaPHv2efcaPH8+aNe/+ba/Ozk7Gjx+/e33btm0ceOCBZY+lFAeBmVkPzjjjDLZv387ixYt3t/385z/nRz/60R79jj/+eCZNmsR3v/vdksc54YQT6Ojo2L0+a9as3U8Btba2Mnv27PfsM2PGDB5++GG6urro6uri4YcfZsaMGUA2ib1hwwYaGxurGp+DwMysB5K4//77WbZsGRMnTmTy5MlcddVVjB373j/eOH/+fDo7O0se56yzzuKHP/zh7vV58+axdOlSmpqaWLZsGfPmzQOgra2NSy65BIARI0ZwzTXXcMopp3DKKadw7bXX7p44bm9v57TTTts9+dzr8fnXUJvZvu7ZZ5/t9t76QHPeeedx00030dTUVPWxLr/8cmbNmsW0adPes63U98y/htrMbB+wcOHC3fMC1TrxxBNLhkCl/NSQmVk/Ou644zjuuONqcqy9/Z+FSviKwMwGhIF4G7teKv1eOQjMbJ83dOhQNm/e7DAow66/RzB06NCy9/GtITPb5zU0NNDZ2cmmTZvqXcqAsOsvlJXLQWBm+7whQ4aU/de2rHK+NWRmljgHgZlZ4hwEZmaJG5D/s1jSJuBX9a6jQocDr9S7iH7mMafBYx44joqIUcWNAzIIBiJJbaX+a/f7mcecBo954POtITOzxDkIzMwS5yDoP4t77vK+4zGnwWMe4DxHYGaWOF8RmJklzkFgZpY4B0ENSRohaamklfnX4d30m5v3WSlpbontSyQ90/cVV6+aMUs6SNL3JD0naYWkhf1bfWUkzZT0vKQOSfNKbD9A0r359sclNRZsuypvf17SjP6suxq9HbOkFkntkn6Rfz2jv2vvjWp+xvn2IyVtlXRFf9VcExHhpUYLcBMwL389D1hUos8IYFX+dXj+enjB9o8CdwPP1Hs8fT1m4CDg9/M++wM/As6q95i6Gecg4EXgmLzW/wImFfX5M+Dv8tdzgHvz15Py/gcAR+fHGVTvMfXxmD8IHJG/PhFYW+/x9OV4C7bfB/wzcEW9x1PJ4iuC2poNtOavW4FzS/SZASyNiC0R0QUsBWYCSDoY+BxwYz/UWiu9HnNEvBkRjwFExA7gKaD8353bv6YAHRGxKq/1HrKxFyr8XtwHTJOkvP2eiNgeES8BHfnx9nW9HnNE/Cwi1uXtK4ADJR3QL1X3XjU/YySdC7xENt4BxUFQW2MiYtcfI90AjCnRZzywpmC9M28D+ALwJeDNPquw9qodMwCShgHnAI/0RZE10OMYCvtExE7gNWBkmfvui6oZc6GPAU9FxPY+qrNWej3e/EPclcCCfqiz5vz3CCokaRkwtsSm+YUrERGSyn42V9LvAhMj4rPF9x3rra/GXHD8wcC3ga9GxKreVWn7IkmTgUXAmfWupY9dD9wSEVvzC4QBxUFQoYiY3t02SRsljYuI9ZLGAS+X6LYWmFqw3gAsB04HmiWtJvu5jJa0PCKmUmd9OOZdFgMrI+LWGpTbV9YCEwrWG/K2Un0683A7DNhc5r77omrGjKQG4H7gkxHxYt+XW7VqxnsqcL6km4BhwDuStkXE1/u+7Bqo9yTF+2kB/oY9J05vKtFnBNl9xOH58hIwoqhPIwNnsriqMZPNh/wLsF+9x9LDOAeTTXIfzbsTiZOL+vw5e04kfid/PZk9J4tXMTAmi6sZ87C8/0frPY7+GG9Rn+sZYJPFdS/g/bSQ3Rt9BFgJLCs42TUD3yzo98dkE4YdwB+VOM5ACoJej5nsE1cAzwJP58sl9R7TXsZ6NvAC2ZMl8/O2G4BZ+euhZE+MdABPAMcU7Ds/3+959tEno2o5ZuDzwBsFP9engdH1Hk9f/owLjjHggsC/YsLMLHF+asjMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS9/8B7AfnO8YbpO8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "mci_y = mci_tpr = [ x[\"recall\"] for x in mciStatValues ]\n",
        "mci_x = mci_fpr = [ 1.0 - x[\"specificity\"] for x in mciStatValues ]\n",
        "mci_x, mci_y = sortListsByX(mci_x, mci_y)\n",
        "\n",
        "decimals = 3\n",
        "mci_auc = round(torch.trapezoid(torch.tensor(mci_y), torch.tensor(mci_x)).item(), decimals)\n",
        "\n",
        "plt.title(experimentName + \" MCI ROC\")\n",
        "\n",
        "plt.plot(mci_fpr, mci_tpr)\n",
        "\n",
        "plt.legend([\"MCI (\"+str(mci_auc)+\")\"], loc =\"lower right\")\n",
        "plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_auc_roc_mci.png'))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "E9Z0TN2RpMzv",
        "outputId": "cce85a42-da16-4dc1-d5b9-3146f274d3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e58701268e414ee494812df35b750951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6259ea78745743d0a45ca7229584d68c",
              "IPY_MODEL_539a7687bdd04c20af58658a4ffa8033",
              "IPY_MODEL_180a408371204175a1cedc7102425283"
            ],
            "layout": "IPY_MODEL_349e6d4f4f3243b1aabc569383bb96b5"
          }
        },
        "6259ea78745743d0a45ca7229584d68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ac5b6fc6f540c8b882bdcb85827b67",
            "placeholder": "",
            "style": "IPY_MODEL_249a799f1e0442ea9828c6b96ea9ac12",
            "value": "100%"
          }
        },
        "539a7687bdd04c20af58658a4ffa8033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2b03fed95c4480ab44db4571d684ed",
            "max": 108949747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9005236086394b57ac7be7480bd6106d",
            "value": 108949747
          }
        },
        "180a408371204175a1cedc7102425283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e7e3926a4814c9b9e93afb967fe28c6",
            "placeholder": "",
            "style": "IPY_MODEL_aae9c7b1a5984bbd994229c617c19693",
            "value": " 104M/104M [00:00&lt;00:00, 238MB/s]"
          }
        },
        "349e6d4f4f3243b1aabc569383bb96b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00ac5b6fc6f540c8b882bdcb85827b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249a799f1e0442ea9828c6b96ea9ac12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d2b03fed95c4480ab44db4571d684ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9005236086394b57ac7be7480bd6106d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e7e3926a4814c9b9e93afb967fe28c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aae9c7b1a5984bbd994229c617c19693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}