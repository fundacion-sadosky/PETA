{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18107,"status":"ok","timestamp":1676227996943,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"},"user_tz":180},"id":"xhN8vz1PQ8Wv","outputId":"9079e6c9-3bd8-468d-ea2f-0084c8563a04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vpyelL4yXvC0","executionInfo":{"status":"ok","timestamp":1676227996943,"user_tz":180,"elapsed":4,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"ChL61Twesn0o"},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3300,"status":"ok","timestamp":1676228000241,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"},"user_tz":180},"id":"sRvvbIrxP5Hd","outputId":"d61fa4d3-1e36-48a0-8a9b-060273362c92"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch Version:  1.13.1+cu116\n","Torchvision Version:  0.14.1+cu116\n"]}],"source":["from __future__ import print_function, division\n","import os\n","import time\n","import copy\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchvision import transforms, utils, models, datasets\n","import torch.nn as nn\n","import torch.optim as optim\n","import nibabel as nib\n","import scipy.ndimage as ndi\n","from pathlib import Path\n","from PIL import Image\n","import io\n","import json\n","import random\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"HErqZ9GNCDq6","executionInfo":{"status":"ok","timestamp":1676228000241,"user_tz":180,"elapsed":13,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["imagesFolder = '/content/gdrive/MyDrive/Tesis/Imagenes/ADNI-MUESTRA-930'\n","trainDatasetCSV = imagesFolder + '/MUESTRA_train.csv'\n","valDatasetCSV =   imagesFolder + '/MUESTRA_val.csv'\n","experimentName = 'Muestra930_2_slicing_da'\n","experimentOutputFolder = '/content/gdrive/MyDrive/Tesis/Experimentos/muestra930_2'\n","experimentDescription = 'Muestra930 con slicing y DA'\n","executions = 1"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"VYNyT00wpzwU","executionInfo":{"status":"ok","timestamp":1676228000242,"user_tz":180,"elapsed":13,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n","model_name = \"inception\"\n","\n","# Number of classes in the dataset\n","num_classes = 3\n","\n","# Batch size for training (change depending on how much memory you have)\n","batch_size = 20\n","\n","# Number of epochs to train for\n","num_epochs = 25\n","\n","# Flag for feature extracting. When False, we finetune the whole model,\n","#   when True we only update the reshaped layer params\n","feature_extract = False\n","\n","usePretrained = True\n","\n","learningRate = 0.0001\n","\n","crossEntrophyWeigths = torch.tensor([1.0,1.0,1.0])\n","\n","slicesToCut = 32\n","\n","# Data augmentation\n","dataAugmentation = {\n","    \"angle\": 13.0,\n","    \"zoom\": 0.15,\n","    \"shiftX\": 10.0,\n","    \"shiftY\": 10.0,\n","    \"angleTransformChance\": 0.1,\n","    \"zoomTransformChance\": 0.1,\n","    \"shiftTransformChance\": 0.0\n","}\n","# dataAugmentation = {}\n","\n","validationCacheSize = 400\n","trainCacheSize = 700"]},{"cell_type":"code","source":["f = open(os.path.join(experimentOutputFolder, experimentName + \"_params.txt\"), \"w\")\n","f.write(\"batch_size: \" + str(batch_size) + \"\\n\")\n","f.write(\"epochs: \" + str(num_epochs) + \"\\n\")\n","f.write(\"feature_extract: \" + str(feature_extract) + \"\\n\")\n","f.write(\"usePretrained: \" + str(usePretrained) + \"\\n\")\n","f.write(\"learningRate: \" + str(learningRate) + \"\\n\")\n","f.write(\"cross entrophy weights: \" + str(crossEntrophyWeigths) + \"\\n\")\n","f.write(\"slicesToCut: \" + str(slicesToCut) + \"\\n\")\n","f.write(\"dataAugmentation: \" + str(json.dumps(dataAugmentation)) + \"\\n\")\n","f.write(\"executions: \" + str(executions) + \"\\n\")\n","f.write(\"validationCacheSize: \" + str(validationCacheSize) + \"\\n\")\n","f.write(\"trainCacheSize: \" + str(trainCacheSize) + \"\\n\")\n","f.close()"],"metadata":{"id":"a2ZFcEXjwezm","executionInfo":{"status":"ok","timestamp":1676228001147,"user_tz":180,"elapsed":917,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["f = open(os.path.join(experimentOutputFolder, experimentName + \"_descripcion.txt\"), \"w\")\n","f.write(experimentDescription)\n","f.close()"],"metadata":{"id":"zJYNgYD9AC4X","executionInfo":{"status":"ok","timestamp":1676228001147,"user_tz":180,"elapsed":11,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"VDba_NBLQOou","executionInfo":{"status":"ok","timestamp":1676228001148,"user_tz":180,"elapsed":11,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["# https://stackoverflow.com/questions/8598673/how-to-save-a-pylab-figure-into-in-memory-file-which-can-be-read-into-pil-image\n","def fig2img(fig):\n","    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n","    buf = io.BytesIO()\n","    fig.savefig(buf, facecolor='black', dpi = 64, transparent=False) # dpi Requerido para que la imagen sea 512x512\n","    buf.seek(0)\n","    img = Image.open(buf)\n","    return img"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"K-Z1h8wrQaiB","executionInfo":{"status":"ok","timestamp":1676228001148,"user_tz":180,"elapsed":10,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["def clipped_zoom(img, zoom_factor, **kwargs):\n","\n","    h, w = img.shape[:2]\n","\n","    # For multichannel images we don't want to apply the zoom factor to the RGB\n","    # dimension, so instead we create a tuple of zoom factors, one per array\n","    # dimension, with 1's for any trailing dimensions after the width and height.\n","    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n","\n","    # Zooming out\n","    if zoom_factor < 1:\n","\n","        # Bounding box of the zoomed-out image within the output array\n","        zh = int(np.round(h * zoom_factor))\n","        zw = int(np.round(w * zoom_factor))\n","        top = (h - zh) // 2\n","        left = (w - zw) // 2\n","\n","        # Zero-padding\n","        out = np.zeros_like(img)\n","        out[top:top+zh, left:left+zw] = ndi.zoom(img, zoom_tuple, **kwargs)\n","\n","    # Zooming in\n","    elif zoom_factor > 1:\n","\n","        # Bounding box of the zoomed-in region within the input array\n","        zh = int(np.round(h / zoom_factor))\n","        zw = int(np.round(w / zoom_factor))\n","        top = (h - zh) // 2\n","        left = (w - zw) // 2\n","\n","        out = ndi.zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n","\n","        # `out` might still be slightly larger than `img` due to rounding, so\n","        # trim off any extra pixels at the edges\n","        trim_top = ((out.shape[0] - h) // 2)\n","        trim_left = ((out.shape[1] - w) // 2)\n","        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n","\n","    # If zoom_factor == 1, just return the input array\n","    else:\n","        out = img\n","    return out"]},{"cell_type":"code","source":["def transformGridImage(sample, angle = None, zoom = None, shiftX = None, shiftY = None, \n","                        angleTransformChance = 0.1, zoomTransformChance = 0.1, shiftTransformChance = 0.1):\n","    brain_vol_data = sample.get_fdata()\n","    fig_rows = 4\n","    fig_cols = 4\n","    n_subplots = fig_rows * fig_cols\n","    n_slice = brain_vol_data.shape[2]\n","\n","    slices_to_eliminate = slicesToCut\n","\n","    n_slice_padding = slices_to_eliminate // 2 # quitamos los primeros y ultimos n slices\n","    n_slice = n_slice - slices_to_eliminate\n","\n","    step_size = n_slice / n_subplots\n","\n","    slice_indices = np.arange(n_slice_padding, n_slice_padding + n_slice, step = step_size)\n","\n","    fig, axs = plt.subplots(fig_rows, fig_cols, figsize=[10, 10], facecolor='black')\n","    \n","    if angle == None or angleTransformChance < random.uniform(0.0, 1.0):\n","        angle = 0.0 # Disable random angle\n","        \n","    if zoom != None and random.uniform(0.0, 1.0) > zoomTransformChance:\n","        zoom = None\n","        \n","    if shiftX != None and random.uniform(0.0, 1.0) > shiftTransformChance:\n","        shiftX = None\n","        \n","    if shiftY != None and random.uniform(0.0, 1.0) > shiftTransformChance:\n","        shiftY = None\n","\n","    idx = 0\n","    for img in slice_indices:\n","        processedImage = ndi.rotate(brain_vol_data[:, :, round(img)], 90.0 + angle)\n","        if zoom != None:\n","            processedImage = clipped_zoom(processedImage, zoom)\n","        if shiftX != None:\n","            processedImage = ndi.shift(processedImage, [0.0, shiftX, 0.0])\n","        if shiftY != None:\n","            processedImage = ndi.shift(processedImage, [shiftY, 0.0, 0.0])\n","        axs.flat[idx].imshow(np.squeeze(processedImage), cmap='gray')\n","        axs.flat[idx].axis('off')\n","        idx += 1\n","        \n","    plt.tight_layout()\n","\n","    image = fig2img(fig)\n","\n","    plt.close(fig) # Para que no muestre la imágen\n","    \n","    return image"],"metadata":{"id":"2w0W-yXe-GRA","executionInfo":{"status":"ok","timestamp":1676228001148,"user_tz":180,"elapsed":10,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"vODiu92PQdIL","executionInfo":{"status":"ok","timestamp":1676228001149,"user_tz":180,"elapsed":10,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["# CreateGrid transform\n","class CreateGrid(object):\n","    \"\"\"Creates a grid from the image\n","    \"\"\"\n","    def __init__(self, transformArgs = {}):\n","        self.transformArgs = transformArgs\n","\n","    def __call__(self, sample):\n","        return transformGridImage(sample, **self.transformArgs)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"TX-5K8GGG-zT","executionInfo":{"status":"ok","timestamp":1676228001149,"user_tz":180,"elapsed":8,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["class RemoveTransparency(object):\n","    def __call__(self, sample):\n","      # La imagen se guarda con transparencia, removemos la dimension de indice 3\n","      return sample[0:3, :, :]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"UmM3wjZ0Qfa4","executionInfo":{"status":"ok","timestamp":1676228001149,"user_tz":180,"elapsed":8,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["class ToLabelOutput(object):\n","    def __call__(self, label):\n","        if label == \"CN\":\n","            return 0\n","        elif label == \"AD\":\n","            return 1\n","        else:\n","            return 2 # MCI, LMCI, EMCI"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"wxq4R1JOQgyU","executionInfo":{"status":"ok","timestamp":1676228001149,"user_tz":180,"elapsed":8,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["class ADNIDataset(Dataset):\n","    \"\"\"ADNI dataset.\"\"\"\n","\n","    def __init__(self, csv_file, root_dir, transform=None, target_transform = None, cacheSize = 200):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file with annotations.\n","            root_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.csv = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","        # file cache almacena las rutas a cada item\n","        self.filename_cache = [None] * len(self)\n","        # item_cache directamente almacena los items procesados\n","        self.cacheSize = cacheSize\n","        self.item_cache = [None] * cacheSize\n","\n","    def __len__(self):\n","      return int(len(self.csv))\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        if self.cacheSize > 0 and self.item_cache[idx % self.cacheSize] != None:\n","            item = self.item_cache[idx % self.cacheSize]\n","            if item[\"id\"] == idx:\n","                # item in cache\n","                return item[\"image\"], item[\"label\"]\n","            \n","        studyID = self.csv.iloc[idx, 0]\n","        subjectID = self.csv.iloc[idx, 1]\n","        processFormat = self.csv.iloc[idx, 7]\n","        date = self.csv.iloc[idx, 9]\n","        diagnosis = self.csv.iloc[idx, 2]\n","        \n","        filename = self.filename_cache[idx]\n","        \n","        if filename == None:\n","            rglob = '*'+str(studyID)+'*.nii'\n","            samples = 0\n","\n","            for path in Path(self.root_dir).rglob(rglob):\n","                filename = str(path)\n","                samples =+ 1\n","            \n","            if samples > 1:\n","                raise \"Mas de un sample. Error\"\n","\n","            self.filename_cache[idx] = filename\n","\n","        if not filename:\n","            raise Exception(\"Not found filename for index \" + str(idx) + \" y studyID \" + studyID)\n","            \n","        brain_vol = nib.load(filename)\n","\n","        image = brain_vol\n","        label = diagnosis\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","            \n","        if self.target_transform:\n","            label = self.target_transform(label)\n","\n","        if self.cacheSize > 0 and self.item_cache[idx % self.cacheSize] == None:\n","            # Storing item in cache\n","            self.item_cache[idx % self.cacheSize] = {\n","                \"id\": idx,\n","                \"label\": label,\n","                \"image\": image\n","            }\n","\n","        return image, label"]},{"cell_type":"code","source":["def printFile(text, file):\n","  print(text)\n","  if file != None:\n","      file.write(text + \"\\n\")"],"metadata":{"id":"tMPKNDmqyALS","executionInfo":{"status":"ok","timestamp":1676228001150,"user_tz":180,"elapsed":8,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zW1D_vQnpzDk"},"source":["# Modelo"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"m44_ZbqJvsQ9","executionInfo":{"status":"ok","timestamp":1676228001150,"user_tz":180,"elapsed":8,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=True, logFile = None):\n","    f = None\n","    if logFile != None:\n","        f = open(logFile, \"w\")\n","\n","    since = time.time()\n","\n","    train_acc_history = []\n","    val_acc_history = []\n","    train_loss_history = []\n","    val_loss_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        printFile('Epoch {}/{}'.format(epoch, num_epochs - 1), f)\n","        printFile('-' * 10, f)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        # No usamos el aux\n","                        #outputs, aux_outputs = model(inputs)\n","                        #loss1 = criterion(outputs, labels)\n","                        #loss2 = criterion(aux_outputs, labels)\n","                        #loss = loss1 + 0.4*loss2\n","                        outputs, aux_outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            printFile('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), f)\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","                val_loss_history.append(epoch_loss)\n","            if phase == 'train':\n","                train_acc_history.append(epoch_acc)\n","                train_loss_history.append(epoch_loss)\n","            \n","\n","    time_elapsed = time.time() - since\n","    printFile('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60), f)\n","    printFile('Best val Acc: {:4f}'.format(best_acc), f)\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    if logFile != None:\n","        f.close()\n","    return model, val_acc_history, val_loss_history, train_acc_history, train_loss_history"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Vl-UuMFJv0_S","executionInfo":{"status":"ok","timestamp":1676228001150,"user_tz":180,"elapsed":8,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"id":"DuMUC0zqwFLw"},"source":["# Initialize and reshape inception"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["780200df651d498987212add20d0b8ea","fe02de39c0e54ba587485e80c3f72b0a","fb1ab613b28e4cdfa5ee6bac6cff37d5","221f2cf87c42457b99ac738dbf5158c8","220d65f0cfce4df2b6e8548b586011b1","a9f913cc63b4462c811a4527e17626cd","2993198669724018ac79a66a3c7e8573","05ccb532ec2f486db1a1d383db3ebfc1","c66eb7b2e7b942bfade67b72bfde9a2f","1e3cbe353c0e460094ce5540a5a036e3","87c4b950469140e499e7a17b16f8994b"]},"executionInfo":{"elapsed":1263,"status":"ok","timestamp":1676228002406,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"},"user_tz":180},"id":"GqZfuwYwwLw2","outputId":"e4dd94f9-4b20-43c0-c126-2ce7ce429eae"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/104M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"780200df651d498987212add20d0b8ea"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["num featurs2048\n"]}],"source":["def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"inception\":\n","        \"\"\" Inception v3\n","        Be careful, expects (299,299) sized images and has auxiliary output\n","        \"\"\"\n","        model_ft = models.inception_v3(pretrained=use_pretrained, \n","                                       aux_logits = True)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        # Handle the auxilary net\n","        # num_ftrs = model_ft.AuxLogits.fc.in_features\n","        # model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n","        # Handle the primary net\n","        num_ftrs = model_ft.fc.in_features\n","        print(\"num featurs\" + str(num_ftrs))\n","        # Fuente: https://github.com/bdrad/petdementiapub/blob/master/petdementia_source.py\n","        model_ft.fc = nn.Sequential(\n","          nn.Linear(num_ftrs,1024),\n","          nn.ReLU(),\n","          nn.Linear(1024,num_classes),\n","        )\n","          \n","        input_size = 512 \n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft, input_size\n","\n","# Initialize the model for this run\n","model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=usePretrained)\n","\n","# Print the model we just instantiated\n","# print(model_ft)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5787,"status":"ok","timestamp":1676228008191,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"},"user_tz":180},"id":"pfACeWNcwYqY","outputId":"0bcd6221-d81e-4ad7-97c9-fa28ae3aa421"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Datasets and Dataloaders...\n"]}],"source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms = {\n","    'train': transforms.Compose([\n","        CreateGrid(dataAugmentation),\n","        transforms.ToTensor(),\n","        RemoveTransparency(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        CreateGrid(),\n","        transforms.ToTensor(),\n","        RemoveTransparency(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create training and validation datasets\n","\n","image_datasets = {\n","    'train': ADNIDataset(trainDatasetCSV, imagesFolder, transform = data_transforms['train'], target_transform =ToLabelOutput(), cacheSize = trainCacheSize ),\n","    'val': ADNIDataset(valDatasetCSV, imagesFolder, transform = data_transforms['val'], target_transform =ToLabelOutput(), cacheSize = validationCacheSize )\n","}\n","\n","# Create training and validation dataloaders\n","dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4452,"status":"ok","timestamp":1676228012631,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"},"user_tz":180},"id":"XciJ190PwerB","outputId":"5f693af6-246e-434b-f50b-b49f2c59b25e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Params to learn:\n","\t Conv2d_1a_3x3.conv.weight\n","\t Conv2d_1a_3x3.bn.weight\n","\t Conv2d_1a_3x3.bn.bias\n","\t Conv2d_2a_3x3.conv.weight\n","\t Conv2d_2a_3x3.bn.weight\n","\t Conv2d_2a_3x3.bn.bias\n","\t Conv2d_2b_3x3.conv.weight\n","\t Conv2d_2b_3x3.bn.weight\n","\t Conv2d_2b_3x3.bn.bias\n","\t Conv2d_3b_1x1.conv.weight\n","\t Conv2d_3b_1x1.bn.weight\n","\t Conv2d_3b_1x1.bn.bias\n","\t Conv2d_4a_3x3.conv.weight\n","\t Conv2d_4a_3x3.bn.weight\n","\t Conv2d_4a_3x3.bn.bias\n","\t Mixed_5b.branch1x1.conv.weight\n","\t Mixed_5b.branch1x1.bn.weight\n","\t Mixed_5b.branch1x1.bn.bias\n","\t Mixed_5b.branch5x5_1.conv.weight\n","\t Mixed_5b.branch5x5_1.bn.weight\n","\t Mixed_5b.branch5x5_1.bn.bias\n","\t Mixed_5b.branch5x5_2.conv.weight\n","\t Mixed_5b.branch5x5_2.bn.weight\n","\t Mixed_5b.branch5x5_2.bn.bias\n","\t Mixed_5b.branch3x3dbl_1.conv.weight\n","\t Mixed_5b.branch3x3dbl_1.bn.weight\n","\t Mixed_5b.branch3x3dbl_1.bn.bias\n","\t Mixed_5b.branch3x3dbl_2.conv.weight\n","\t Mixed_5b.branch3x3dbl_2.bn.weight\n","\t Mixed_5b.branch3x3dbl_2.bn.bias\n","\t Mixed_5b.branch3x3dbl_3.conv.weight\n","\t Mixed_5b.branch3x3dbl_3.bn.weight\n","\t Mixed_5b.branch3x3dbl_3.bn.bias\n","\t Mixed_5b.branch_pool.conv.weight\n","\t Mixed_5b.branch_pool.bn.weight\n","\t Mixed_5b.branch_pool.bn.bias\n","\t Mixed_5c.branch1x1.conv.weight\n","\t Mixed_5c.branch1x1.bn.weight\n","\t Mixed_5c.branch1x1.bn.bias\n","\t Mixed_5c.branch5x5_1.conv.weight\n","\t Mixed_5c.branch5x5_1.bn.weight\n","\t Mixed_5c.branch5x5_1.bn.bias\n","\t Mixed_5c.branch5x5_2.conv.weight\n","\t Mixed_5c.branch5x5_2.bn.weight\n","\t Mixed_5c.branch5x5_2.bn.bias\n","\t Mixed_5c.branch3x3dbl_1.conv.weight\n","\t Mixed_5c.branch3x3dbl_1.bn.weight\n","\t Mixed_5c.branch3x3dbl_1.bn.bias\n","\t Mixed_5c.branch3x3dbl_2.conv.weight\n","\t Mixed_5c.branch3x3dbl_2.bn.weight\n","\t Mixed_5c.branch3x3dbl_2.bn.bias\n","\t Mixed_5c.branch3x3dbl_3.conv.weight\n","\t Mixed_5c.branch3x3dbl_3.bn.weight\n","\t Mixed_5c.branch3x3dbl_3.bn.bias\n","\t Mixed_5c.branch_pool.conv.weight\n","\t Mixed_5c.branch_pool.bn.weight\n","\t Mixed_5c.branch_pool.bn.bias\n","\t Mixed_5d.branch1x1.conv.weight\n","\t Mixed_5d.branch1x1.bn.weight\n","\t Mixed_5d.branch1x1.bn.bias\n","\t Mixed_5d.branch5x5_1.conv.weight\n","\t Mixed_5d.branch5x5_1.bn.weight\n","\t Mixed_5d.branch5x5_1.bn.bias\n","\t Mixed_5d.branch5x5_2.conv.weight\n","\t Mixed_5d.branch5x5_2.bn.weight\n","\t Mixed_5d.branch5x5_2.bn.bias\n","\t Mixed_5d.branch3x3dbl_1.conv.weight\n","\t Mixed_5d.branch3x3dbl_1.bn.weight\n","\t Mixed_5d.branch3x3dbl_1.bn.bias\n","\t Mixed_5d.branch3x3dbl_2.conv.weight\n","\t Mixed_5d.branch3x3dbl_2.bn.weight\n","\t Mixed_5d.branch3x3dbl_2.bn.bias\n","\t Mixed_5d.branch3x3dbl_3.conv.weight\n","\t Mixed_5d.branch3x3dbl_3.bn.weight\n","\t Mixed_5d.branch3x3dbl_3.bn.bias\n","\t Mixed_5d.branch_pool.conv.weight\n","\t Mixed_5d.branch_pool.bn.weight\n","\t Mixed_5d.branch_pool.bn.bias\n","\t Mixed_6a.branch3x3.conv.weight\n","\t Mixed_6a.branch3x3.bn.weight\n","\t Mixed_6a.branch3x3.bn.bias\n","\t Mixed_6a.branch3x3dbl_1.conv.weight\n","\t Mixed_6a.branch3x3dbl_1.bn.weight\n","\t Mixed_6a.branch3x3dbl_1.bn.bias\n","\t Mixed_6a.branch3x3dbl_2.conv.weight\n","\t Mixed_6a.branch3x3dbl_2.bn.weight\n","\t Mixed_6a.branch3x3dbl_2.bn.bias\n","\t Mixed_6a.branch3x3dbl_3.conv.weight\n","\t Mixed_6a.branch3x3dbl_3.bn.weight\n","\t Mixed_6a.branch3x3dbl_3.bn.bias\n","\t Mixed_6b.branch1x1.conv.weight\n","\t Mixed_6b.branch1x1.bn.weight\n","\t Mixed_6b.branch1x1.bn.bias\n","\t Mixed_6b.branch7x7_1.conv.weight\n","\t Mixed_6b.branch7x7_1.bn.weight\n","\t Mixed_6b.branch7x7_1.bn.bias\n","\t Mixed_6b.branch7x7_2.conv.weight\n","\t Mixed_6b.branch7x7_2.bn.weight\n","\t Mixed_6b.branch7x7_2.bn.bias\n","\t Mixed_6b.branch7x7_3.conv.weight\n","\t Mixed_6b.branch7x7_3.bn.weight\n","\t Mixed_6b.branch7x7_3.bn.bias\n","\t Mixed_6b.branch7x7dbl_1.conv.weight\n","\t Mixed_6b.branch7x7dbl_1.bn.weight\n","\t Mixed_6b.branch7x7dbl_1.bn.bias\n","\t Mixed_6b.branch7x7dbl_2.conv.weight\n","\t Mixed_6b.branch7x7dbl_2.bn.weight\n","\t Mixed_6b.branch7x7dbl_2.bn.bias\n","\t Mixed_6b.branch7x7dbl_3.conv.weight\n","\t Mixed_6b.branch7x7dbl_3.bn.weight\n","\t Mixed_6b.branch7x7dbl_3.bn.bias\n","\t Mixed_6b.branch7x7dbl_4.conv.weight\n","\t Mixed_6b.branch7x7dbl_4.bn.weight\n","\t Mixed_6b.branch7x7dbl_4.bn.bias\n","\t Mixed_6b.branch7x7dbl_5.conv.weight\n","\t Mixed_6b.branch7x7dbl_5.bn.weight\n","\t Mixed_6b.branch7x7dbl_5.bn.bias\n","\t Mixed_6b.branch_pool.conv.weight\n","\t Mixed_6b.branch_pool.bn.weight\n","\t Mixed_6b.branch_pool.bn.bias\n","\t Mixed_6c.branch1x1.conv.weight\n","\t Mixed_6c.branch1x1.bn.weight\n","\t Mixed_6c.branch1x1.bn.bias\n","\t Mixed_6c.branch7x7_1.conv.weight\n","\t Mixed_6c.branch7x7_1.bn.weight\n","\t Mixed_6c.branch7x7_1.bn.bias\n","\t Mixed_6c.branch7x7_2.conv.weight\n","\t Mixed_6c.branch7x7_2.bn.weight\n","\t Mixed_6c.branch7x7_2.bn.bias\n","\t Mixed_6c.branch7x7_3.conv.weight\n","\t Mixed_6c.branch7x7_3.bn.weight\n","\t Mixed_6c.branch7x7_3.bn.bias\n","\t Mixed_6c.branch7x7dbl_1.conv.weight\n","\t Mixed_6c.branch7x7dbl_1.bn.weight\n","\t Mixed_6c.branch7x7dbl_1.bn.bias\n","\t Mixed_6c.branch7x7dbl_2.conv.weight\n","\t Mixed_6c.branch7x7dbl_2.bn.weight\n","\t Mixed_6c.branch7x7dbl_2.bn.bias\n","\t Mixed_6c.branch7x7dbl_3.conv.weight\n","\t Mixed_6c.branch7x7dbl_3.bn.weight\n","\t Mixed_6c.branch7x7dbl_3.bn.bias\n","\t Mixed_6c.branch7x7dbl_4.conv.weight\n","\t Mixed_6c.branch7x7dbl_4.bn.weight\n","\t Mixed_6c.branch7x7dbl_4.bn.bias\n","\t Mixed_6c.branch7x7dbl_5.conv.weight\n","\t Mixed_6c.branch7x7dbl_5.bn.weight\n","\t Mixed_6c.branch7x7dbl_5.bn.bias\n","\t Mixed_6c.branch_pool.conv.weight\n","\t Mixed_6c.branch_pool.bn.weight\n","\t Mixed_6c.branch_pool.bn.bias\n","\t Mixed_6d.branch1x1.conv.weight\n","\t Mixed_6d.branch1x1.bn.weight\n","\t Mixed_6d.branch1x1.bn.bias\n","\t Mixed_6d.branch7x7_1.conv.weight\n","\t Mixed_6d.branch7x7_1.bn.weight\n","\t Mixed_6d.branch7x7_1.bn.bias\n","\t Mixed_6d.branch7x7_2.conv.weight\n","\t Mixed_6d.branch7x7_2.bn.weight\n","\t Mixed_6d.branch7x7_2.bn.bias\n","\t Mixed_6d.branch7x7_3.conv.weight\n","\t Mixed_6d.branch7x7_3.bn.weight\n","\t Mixed_6d.branch7x7_3.bn.bias\n","\t Mixed_6d.branch7x7dbl_1.conv.weight\n","\t Mixed_6d.branch7x7dbl_1.bn.weight\n","\t Mixed_6d.branch7x7dbl_1.bn.bias\n","\t Mixed_6d.branch7x7dbl_2.conv.weight\n","\t Mixed_6d.branch7x7dbl_2.bn.weight\n","\t Mixed_6d.branch7x7dbl_2.bn.bias\n","\t Mixed_6d.branch7x7dbl_3.conv.weight\n","\t Mixed_6d.branch7x7dbl_3.bn.weight\n","\t Mixed_6d.branch7x7dbl_3.bn.bias\n","\t Mixed_6d.branch7x7dbl_4.conv.weight\n","\t Mixed_6d.branch7x7dbl_4.bn.weight\n","\t Mixed_6d.branch7x7dbl_4.bn.bias\n","\t Mixed_6d.branch7x7dbl_5.conv.weight\n","\t Mixed_6d.branch7x7dbl_5.bn.weight\n","\t Mixed_6d.branch7x7dbl_5.bn.bias\n","\t Mixed_6d.branch_pool.conv.weight\n","\t Mixed_6d.branch_pool.bn.weight\n","\t Mixed_6d.branch_pool.bn.bias\n","\t Mixed_6e.branch1x1.conv.weight\n","\t Mixed_6e.branch1x1.bn.weight\n","\t Mixed_6e.branch1x1.bn.bias\n","\t Mixed_6e.branch7x7_1.conv.weight\n","\t Mixed_6e.branch7x7_1.bn.weight\n","\t Mixed_6e.branch7x7_1.bn.bias\n","\t Mixed_6e.branch7x7_2.conv.weight\n","\t Mixed_6e.branch7x7_2.bn.weight\n","\t Mixed_6e.branch7x7_2.bn.bias\n","\t Mixed_6e.branch7x7_3.conv.weight\n","\t Mixed_6e.branch7x7_3.bn.weight\n","\t Mixed_6e.branch7x7_3.bn.bias\n","\t Mixed_6e.branch7x7dbl_1.conv.weight\n","\t Mixed_6e.branch7x7dbl_1.bn.weight\n","\t Mixed_6e.branch7x7dbl_1.bn.bias\n","\t Mixed_6e.branch7x7dbl_2.conv.weight\n","\t Mixed_6e.branch7x7dbl_2.bn.weight\n","\t Mixed_6e.branch7x7dbl_2.bn.bias\n","\t Mixed_6e.branch7x7dbl_3.conv.weight\n","\t Mixed_6e.branch7x7dbl_3.bn.weight\n","\t Mixed_6e.branch7x7dbl_3.bn.bias\n","\t Mixed_6e.branch7x7dbl_4.conv.weight\n","\t Mixed_6e.branch7x7dbl_4.bn.weight\n","\t Mixed_6e.branch7x7dbl_4.bn.bias\n","\t Mixed_6e.branch7x7dbl_5.conv.weight\n","\t Mixed_6e.branch7x7dbl_5.bn.weight\n","\t Mixed_6e.branch7x7dbl_5.bn.bias\n","\t Mixed_6e.branch_pool.conv.weight\n","\t Mixed_6e.branch_pool.bn.weight\n","\t Mixed_6e.branch_pool.bn.bias\n","\t AuxLogits.conv0.conv.weight\n","\t AuxLogits.conv0.bn.weight\n","\t AuxLogits.conv0.bn.bias\n","\t AuxLogits.conv1.conv.weight\n","\t AuxLogits.conv1.bn.weight\n","\t AuxLogits.conv1.bn.bias\n","\t AuxLogits.fc.weight\n","\t AuxLogits.fc.bias\n","\t Mixed_7a.branch3x3_1.conv.weight\n","\t Mixed_7a.branch3x3_1.bn.weight\n","\t Mixed_7a.branch3x3_1.bn.bias\n","\t Mixed_7a.branch3x3_2.conv.weight\n","\t Mixed_7a.branch3x3_2.bn.weight\n","\t Mixed_7a.branch3x3_2.bn.bias\n","\t Mixed_7a.branch7x7x3_1.conv.weight\n","\t Mixed_7a.branch7x7x3_1.bn.weight\n","\t Mixed_7a.branch7x7x3_1.bn.bias\n","\t Mixed_7a.branch7x7x3_2.conv.weight\n","\t Mixed_7a.branch7x7x3_2.bn.weight\n","\t Mixed_7a.branch7x7x3_2.bn.bias\n","\t Mixed_7a.branch7x7x3_3.conv.weight\n","\t Mixed_7a.branch7x7x3_3.bn.weight\n","\t Mixed_7a.branch7x7x3_3.bn.bias\n","\t Mixed_7a.branch7x7x3_4.conv.weight\n","\t Mixed_7a.branch7x7x3_4.bn.weight\n","\t Mixed_7a.branch7x7x3_4.bn.bias\n","\t Mixed_7b.branch1x1.conv.weight\n","\t Mixed_7b.branch1x1.bn.weight\n","\t Mixed_7b.branch1x1.bn.bias\n","\t Mixed_7b.branch3x3_1.conv.weight\n","\t Mixed_7b.branch3x3_1.bn.weight\n","\t Mixed_7b.branch3x3_1.bn.bias\n","\t Mixed_7b.branch3x3_2a.conv.weight\n","\t Mixed_7b.branch3x3_2a.bn.weight\n","\t Mixed_7b.branch3x3_2a.bn.bias\n","\t Mixed_7b.branch3x3_2b.conv.weight\n","\t Mixed_7b.branch3x3_2b.bn.weight\n","\t Mixed_7b.branch3x3_2b.bn.bias\n","\t Mixed_7b.branch3x3dbl_1.conv.weight\n","\t Mixed_7b.branch3x3dbl_1.bn.weight\n","\t Mixed_7b.branch3x3dbl_1.bn.bias\n","\t Mixed_7b.branch3x3dbl_2.conv.weight\n","\t Mixed_7b.branch3x3dbl_2.bn.weight\n","\t Mixed_7b.branch3x3dbl_2.bn.bias\n","\t Mixed_7b.branch3x3dbl_3a.conv.weight\n","\t Mixed_7b.branch3x3dbl_3a.bn.weight\n","\t Mixed_7b.branch3x3dbl_3a.bn.bias\n","\t Mixed_7b.branch3x3dbl_3b.conv.weight\n","\t Mixed_7b.branch3x3dbl_3b.bn.weight\n","\t Mixed_7b.branch3x3dbl_3b.bn.bias\n","\t Mixed_7b.branch_pool.conv.weight\n","\t Mixed_7b.branch_pool.bn.weight\n","\t Mixed_7b.branch_pool.bn.bias\n","\t Mixed_7c.branch1x1.conv.weight\n","\t Mixed_7c.branch1x1.bn.weight\n","\t Mixed_7c.branch1x1.bn.bias\n","\t Mixed_7c.branch3x3_1.conv.weight\n","\t Mixed_7c.branch3x3_1.bn.weight\n","\t Mixed_7c.branch3x3_1.bn.bias\n","\t Mixed_7c.branch3x3_2a.conv.weight\n","\t Mixed_7c.branch3x3_2a.bn.weight\n","\t Mixed_7c.branch3x3_2a.bn.bias\n","\t Mixed_7c.branch3x3_2b.conv.weight\n","\t Mixed_7c.branch3x3_2b.bn.weight\n","\t Mixed_7c.branch3x3_2b.bn.bias\n","\t Mixed_7c.branch3x3dbl_1.conv.weight\n","\t Mixed_7c.branch3x3dbl_1.bn.weight\n","\t Mixed_7c.branch3x3dbl_1.bn.bias\n","\t Mixed_7c.branch3x3dbl_2.conv.weight\n","\t Mixed_7c.branch3x3dbl_2.bn.weight\n","\t Mixed_7c.branch3x3dbl_2.bn.bias\n","\t Mixed_7c.branch3x3dbl_3a.conv.weight\n","\t Mixed_7c.branch3x3dbl_3a.bn.weight\n","\t Mixed_7c.branch3x3dbl_3a.bn.bias\n","\t Mixed_7c.branch3x3dbl_3b.conv.weight\n","\t Mixed_7c.branch3x3dbl_3b.bn.weight\n","\t Mixed_7c.branch3x3dbl_3b.bn.bias\n","\t Mixed_7c.branch_pool.conv.weight\n","\t Mixed_7c.branch_pool.bn.weight\n","\t Mixed_7c.branch_pool.bn.bias\n","\t fc.0.weight\n","\t fc.0.bias\n","\t fc.2.weight\n","\t fc.2.bias\n"]}],"source":["# Send the model to GPU\n","model_ft = model_ft.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_ft.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.Adam(params_to_update, lr=learningRate)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"CVJl5AvUqK13","executionInfo":{"status":"ok","timestamp":1676228012632,"user_tz":180,"elapsed":17,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"outputs":[],"source":["def test_model(model,dataloaders,device):\n","    classStats = [{\n","        'fn': 0,\n","        'tn': 0,\n","        'tp': 0,\n","        'fp': 0,\n","        'n': 0,\n","    } for i in range(num_classes)]\n","    correctlyPredicted = 0\n","    n = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for inputs, labels in dataloaders['val']:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            \n","            # Iteramos para chequear estadisticas\n","            for i, correctClass in enumerate(labels.data):\n","              n += 1\n","              predictedClass = int(preds[i].item())\n","              correctClass = int(correctClass.item())\n","              classStats[correctClass]['n'] += 1\n","              if correctClass == predictedClass:\n","                  correctlyPredicted += 1\n","                  classStats[correctClass]['tp'] += 1\n","                  for i in range(num_classes):\n","                      if i != correctClass:\n","                          classStats[correctClass]['tn'] += 1\n","              else:\n","                  classStats[correctClass]['fn'] += 1\n","                  classStats[predictedClass]['fp'] += 1\n","                  for i in range(num_classes):\n","                      if i != correctClass and i != predictedClass:\n","                          classStats[correctClass]['tn'] += 1\n","    accuracy = correctlyPredicted * 1.0 / n\n","    return classStats, accuracy"]},{"cell_type":"code","source":["def printClassStats(stats):\n","  recall = sensitivity = stats['tp'] / (stats['tp'] + stats['fn']) # prob positive test result\n","  specificity = stats['tn'] / (stats['tn'] + stats['fp'])          # prob negative test result\n","  if stats['tp'] + stats['fp'] > 0:\n","    precision = stats['tp'] / (stats['tp'] + stats['fp'])          # prob of recognized positive actually correct\n","  else:\n","    precision = 1\n","    printFile(\"Setting precision as 1 but no positive value has been reported, so this is placeholder\", f)\n","  if precision + recall == 0:\n","    printFile(\"Setting f1 as 0 because precision + recall is ZERO\", f)\n","    f1 = 0.0\n","  else:\n","    f1 = 2 * (precision * recall) / ( precision + recall )\n","  printFile(\"Sensitivity (%): \" + str(round(sensitivity * 100)), f)\n","  printFile(\"Specificity (%): \" + str(round(specificity * 100)), f)\n","  printFile(\"Precision  (%): \" + str(round(precision * 100)), f)\n","  printFile(\"F1 Score  (%): \" + str(round(f1 * 100)), f)\n","  printFile(\"Number of images: \" + str(stats['n']), f)\n","  return recall, specificity, precision, f1"],"metadata":{"id":"aK3auwSS05Le","executionInfo":{"status":"ok","timestamp":1676228012632,"user_tz":180,"elapsed":16,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"D84am68jwlX6","executionInfo":{"status":"ok","timestamp":1676232858220,"user_tz":180,"elapsed":4845604,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}},"outputId":"7d77aa00-039e-4a2c-baa5-a56238d342da"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Execution 0 begin ---\n","Epoch 0/24\n","----------\n","train Loss: 1.0792 Acc: 0.4048\n","val Loss: 1.0728 Acc: 0.4300\n","Epoch 1/24\n","----------\n","train Loss: 0.8839 Acc: 0.5921\n","val Loss: 1.3334 Acc: 0.3833\n","Epoch 2/24\n","----------\n","train Loss: 0.6943 Acc: 0.7111\n","val Loss: 1.3290 Acc: 0.4700\n","Epoch 3/24\n","----------\n","train Loss: 0.5575 Acc: 0.7651\n","val Loss: 2.7718 Acc: 0.3600\n","Epoch 4/24\n","----------\n","train Loss: 0.4028 Acc: 0.8333\n","val Loss: 1.7443 Acc: 0.5233\n","Epoch 5/24\n","----------\n","train Loss: 0.3533 Acc: 0.8381\n","val Loss: 2.4446 Acc: 0.3800\n","Epoch 6/24\n","----------\n","train Loss: 0.3257 Acc: 0.8444\n","val Loss: 2.2222 Acc: 0.4667\n","Epoch 7/24\n","----------\n","train Loss: 0.3123 Acc: 0.8556\n","val Loss: 1.9200 Acc: 0.5367\n","Epoch 8/24\n","----------\n","train Loss: 0.3146 Acc: 0.8587\n","val Loss: 1.6421 Acc: 0.5167\n","Epoch 9/24\n","----------\n","train Loss: 0.2037 Acc: 0.9032\n","val Loss: 2.6205 Acc: 0.4700\n","Epoch 10/24\n","----------\n","train Loss: 0.2374 Acc: 0.8841\n","val Loss: 2.7136 Acc: 0.4233\n","Epoch 11/24\n","----------\n","train Loss: 0.2768 Acc: 0.8651\n","val Loss: 1.6247 Acc: 0.5000\n","Epoch 12/24\n","----------\n","train Loss: 0.1828 Acc: 0.9270\n","val Loss: 1.8675 Acc: 0.5700\n","Epoch 13/24\n","----------\n","train Loss: 0.1577 Acc: 0.9381\n","val Loss: 2.0673 Acc: 0.5167\n","Epoch 14/24\n","----------\n","train Loss: 0.1745 Acc: 0.9079\n","val Loss: 2.1733 Acc: 0.5467\n","Epoch 15/24\n","----------\n","train Loss: 0.1952 Acc: 0.8984\n","val Loss: 2.4033 Acc: 0.5100\n","Epoch 16/24\n","----------\n","train Loss: 0.1332 Acc: 0.9413\n","val Loss: 2.1289 Acc: 0.5900\n","Epoch 17/24\n","----------\n","train Loss: 0.1893 Acc: 0.9063\n","val Loss: 3.1351 Acc: 0.4200\n","Epoch 18/24\n","----------\n","train Loss: 0.2352 Acc: 0.9032\n","val Loss: 2.7324 Acc: 0.4567\n","Epoch 19/24\n","----------\n","train Loss: 0.2515 Acc: 0.8841\n","val Loss: 3.4753 Acc: 0.4067\n","Epoch 20/24\n","----------\n","train Loss: 0.2238 Acc: 0.8984\n","val Loss: 1.7481 Acc: 0.5033\n","Epoch 21/24\n","----------\n","train Loss: 0.1851 Acc: 0.9079\n","val Loss: 2.4105 Acc: 0.5000\n","Epoch 22/24\n","----------\n","train Loss: 0.1389 Acc: 0.9238\n","val Loss: 2.5645 Acc: 0.4700\n","Epoch 23/24\n","----------\n","train Loss: 0.1602 Acc: 0.9159\n","val Loss: 2.5456 Acc: 0.4867\n","Epoch 24/24\n","----------\n","train Loss: 0.1337 Acc: 0.9333\n","val Loss: 2.6318 Acc: 0.5367\n","Training complete in 79m 40s\n","Best val Acc: 0.590000\n","accuracy: 0.59\n","CN stats: \n","Sensitivity (%): 82\n","Specificity (%): 73\n","Precision  (%): 55\n","F1 Score  (%): 66\n","Number of images: 100\n","\n","AD stats: \n","Sensitivity (%): 82\n","Specificity (%): 81\n","Precision  (%): 66\n","F1 Score  (%): 73\n","Number of images: 100\n","\n","MCI stats: \n","Sensitivity (%): 13\n","Specificity (%): 89\n","Precision  (%): 48\n","F1 Score  (%): 20\n","Number of images: 100\n","--- Execution End ---\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}],"source":["accuracyValues = []\n","adStatValues = []\n","cnStatValues = []\n","mciStatValues = []\n","for i in range(0, executions):\n","    experimentExecutionName = experimentName + '_' + str(i)\n","    print(\"--- Execution \" + str(i) + \" begin ---\")\n","    # Setup the loss fxn\n","    crossEntrophyWeigths = crossEntrophyWeigths.to(device)\n","    criterion = nn.CrossEntropyLoss(crossEntrophyWeigths)\n","\n","    logFile = os.path.join(experimentOutputFolder, experimentExecutionName + '_train.log')\n","\n","    # Train and evaluate\n","    model_ft, val_acc_hist, val_loss_hist, train_acc_hist, train_loss_hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"), logFile = logFile)\n","\n","    torch.save(model_ft.state_dict(), os.path.join(experimentOutputFolder, experimentExecutionName + '.pth'))\n","\n","    # validation accuracy\n","    fig = plt.figure()\n","    lst = [ x.cpu().item() for x in val_acc_hist ]\n","    plt.plot(lst)\n","    ax = plt.gca()\n","    plt.text(0.05, 0.9, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n","    plt.text(0.05, 0.8, 'LR = ' + str(learningRate), transform=ax.transAxes)\n","    plt.text(0.05, 0.7, 'batch = ' + str(batch_size), transform=ax.transAxes)\n","    plt.suptitle(experimentExecutionName + ' (acc set de validacion)')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_val_acc.png'))\n","    plt.clf()\n","\n","    # validation loss\n","    fig = plt.figure()\n","    plt.plot(val_loss_hist)\n","    ax = plt.gca()\n","    plt.text(0.05, 0.3, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n","    plt.text(0.05, 0.2, 'LR = ' + str(learningRate), transform=ax.transAxes)\n","    plt.text(0.05, 0.1, 'batch = ' + str(batch_size), transform=ax.transAxes)\n","    plt.suptitle(experimentExecutionName + ' (loss set de validacion)')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epochs')\n","    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_val_loss.png'))\n","    plt.clf()\n","\n","    # train accuracy\n","    fig = plt.figure()\n","    lst = [ x.cpu().item() for x in train_acc_hist ]\n","    ax = plt.gca()\n","    plt.text(0.05, 0.9, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n","    plt.text(0.05, 0.8, 'LR = ' + str(learningRate), transform=ax.transAxes)\n","    plt.text(0.05, 0.7, 'batch = ' + str(batch_size), transform=ax.transAxes)\n","    plt.plot(lst)\n","    plt.suptitle(experimentExecutionName + ' (accuracy set de train)')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_train_acc.png'))\n","    plt.clf()\n","\n","    # train loss\n","    fig = plt.figure()\n","    ax = plt.gca()\n","    plt.text(0.05, 0.3, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n","    plt.text(0.05, 0.2, 'LR = ' + str(learningRate), transform=ax.transAxes)\n","    plt.text(0.05, 0.1, 'batch = ' + str(batch_size), transform=ax.transAxes)\n","    plt.plot(train_loss_hist)\n","    plt.suptitle(experimentExecutionName + ' (Loss set de train)')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epochs')\n","    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_train_loss.png'))\n","    plt.clf()\n","\n","    stats, accuracy = test_model(model_ft, dataloaders_dict, device)\n","\n","    print(\"accuracy: \" + str(accuracy))\n","    accuracyValues.append(accuracy)\n","\n","    f = open(os.path.join(experimentOutputFolder, experimentExecutionName + \"_stats.txt\"), \"w\")\n","    printFile(\"CN stats: \", f)\n","    recall, specificity, precision, f1 = printClassStats(stats[0])\n","    cnStatValues.append({\n","        \"recall\": recall,\n","        \"specificity\": specificity,\n","        \"precision\": precision,\n","        \"f1\": f1\n","    })\n","    # AD\n","    printFile(\"\\nAD stats: \", f)\n","    recall, specificity, precision, f1 = printClassStats(stats[1])\n","    adStatValues.append({\n","        \"recall\": recall,\n","        \"specificity\": specificity,\n","        \"precision\": precision,\n","        \"f1\": f1\n","    })\n","    # MCI\n","    printFile(\"\\nMCI stats: \", f)\n","    recall, specificity, precision, f1 = printClassStats(stats[2])\n","    mciStatValues.append({\n","        \"recall\": recall,\n","        \"specificity\": specificity,\n","        \"precision\": precision,\n","        \"f1\": f1\n","    })\n","    f.close()\n","\n","    print(\"--- Execution End ---\")"]},{"cell_type":"code","source":["accuracyValues = torch.tensor(accuracyValues)\n","std, mean = torch.std_mean(accuracyValues)\n","f = open(os.path.join(\n","    os.path.join(experimentOutputFolder, experimentName + '_results.txt')), \"w\")\n","printFile(\"Final stats: \", f)\n","printFile(\"Executions: \" + str(executions), f)\n","printFile(\"Accuracy mean: \" + str(mean.item()), f)\n","printFile(\"Accuracy std: \" + str(std.item()), f)\n","printFile(\"Best accuracy: \" + str(accuracyValues.max().item()), f)\n","printFile(\"Worst accuracy: \" + str(accuracyValues.min().item()), f)\n","f.close()"],"metadata":{"id":"WuiTfuCMd8j4","executionInfo":{"status":"ok","timestamp":1676232858221,"user_tz":180,"elapsed":9,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"00581324-e672-48b6-f449-3b146bf8ae8c"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Final stats: \n","Executions: 1\n","Accuracy mean: 0.5899999737739563\n","Accuracy std: nan\n","Best accuracy: 0.5899999737739563\n","Worst accuracy: 0.5899999737739563\n"]}]},{"cell_type":"markdown","source":["# ROC - AUC"],"metadata":{"id":"xA-ShjPRUYxP"}},{"cell_type":"code","source":["def sortByX(point):\n","  return point[0]\n","\n","# Se necesita ordenar los puntos para llamar a torch.trapezoid con los puntos ordenados por la coordenada X\n","def sortListsByX(x, y):\n","    points = zip(x, y)\n","    points = list(points)\n","    points.sort(key=sortByX)\n","    x, y = ([ a for a,b in points ], [ b for a,b in points ])\n","    return x, y\n","\n","fig = plt.figure()\n","ad_y = ad_tpr = [ x[\"recall\"] for x in adStatValues ]\n","ad_x = ad_fpr = [ 1.0 - x[\"specificity\"] for x in adStatValues ]\n","ad_x, ad_y = sortListsByX(ad_x, ad_y)\n","\n","cn_y = cn_tpr = [ x[\"recall\"] for x in cnStatValues ]\n","cn_x = cn_fpr = [ 1.0 - x[\"specificity\"] for x in cnStatValues ]\n","cn_x, cn_y = sortListsByX(cn_x, cn_y)\n","\n","mci_y = mci_tpr = [ x[\"recall\"] for x in mciStatValues ]\n","mci_x = mci_fpr = [ 1.0 - x[\"specificity\"] for x in mciStatValues ]\n","mci_x, mci_y = sortListsByX(mci_x, mci_y)\n","\n","decimals = 3\n","ad_auc = round(torch.trapezoid(torch.tensor(ad_y), torch.tensor(ad_x)).item(), decimals)\n","cn_auc = round(torch.trapezoid(torch.tensor(cn_y), torch.tensor(cn_x)).item(), decimals)\n","mci_auc = round(torch.trapezoid(torch.tensor(mci_y), torch.tensor(mci_x)).item(), decimals)\n","\n","plt.title(experimentName + \" ROC\")\n","\n","plt.plot(ad_fpr, ad_tpr)\n","plt.plot(cn_fpr, cn_tpr)\n","plt.plot(mci_fpr, mci_tpr)\n","\n","plt.legend([\"AD (\"+str(ad_auc)+\")\", \"CN (\"+str(cn_auc)+\")\", \"MCI (\"+str(mci_auc)+\")\"], loc =\"lower right\")\n","\n","plt.show()"],"metadata":{"id":"mmKtfcWNUOIR","executionInfo":{"status":"ok","timestamp":1676232858221,"user_tz":180,"elapsed":7,"user":{"displayName":"Hugo Massaroli","userId":"15440061811672054235"}},"colab":{"base_uri":"https://localhost:8080/","height":281},"outputId":"2e913794-54a3-4067-e233-80ed3a12f001"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"16o1Cwhe7WZLogDA0DbP9dhD2dpuH7hTj","timestamp":1676227832830},{"file_id":"1wBDyx6qBbMVKhBkalmDDh8fHPGizULqY","timestamp":1675975075129},{"file_id":"15DQCaEowifBeL7LrHIhH27T1wLMqux-Q","timestamp":1675862573434},{"file_id":"1yGoLeZe4i8JaHXU1IfjR2UPRsLtU23F9","timestamp":1675797870814},{"file_id":"120K10bTpyu0fdEdMVM__L0qERi9n-jAS","timestamp":1675439211225},{"file_id":"13WvbakefqyInUNu3IQON4PMLfeqtRAfy","timestamp":1674663309852},{"file_id":"1iT4xx9DO_8Lc0tKgVBhlpCz5eWSt06ey","timestamp":1674653538354},{"file_id":"1ZK41MNgZDEE9pw_LuWBGh9zFE2lC1Nc9","timestamp":1674333964346},{"file_id":"1pM4FyjV72HeYXVll7Q9TokiVunh0UijY","timestamp":1674152895718}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"780200df651d498987212add20d0b8ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe02de39c0e54ba587485e80c3f72b0a","IPY_MODEL_fb1ab613b28e4cdfa5ee6bac6cff37d5","IPY_MODEL_221f2cf87c42457b99ac738dbf5158c8"],"layout":"IPY_MODEL_220d65f0cfce4df2b6e8548b586011b1"}},"fe02de39c0e54ba587485e80c3f72b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9f913cc63b4462c811a4527e17626cd","placeholder":"​","style":"IPY_MODEL_2993198669724018ac79a66a3c7e8573","value":"100%"}},"fb1ab613b28e4cdfa5ee6bac6cff37d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05ccb532ec2f486db1a1d383db3ebfc1","max":108949747,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c66eb7b2e7b942bfade67b72bfde9a2f","value":108949747}},"221f2cf87c42457b99ac738dbf5158c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e3cbe353c0e460094ce5540a5a036e3","placeholder":"​","style":"IPY_MODEL_87c4b950469140e499e7a17b16f8994b","value":" 104M/104M [00:00&lt;00:00, 189MB/s]"}},"220d65f0cfce4df2b6e8548b586011b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9f913cc63b4462c811a4527e17626cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2993198669724018ac79a66a3c7e8573":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05ccb532ec2f486db1a1d383db3ebfc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c66eb7b2e7b942bfade67b72bfde9a2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e3cbe353c0e460094ce5540a5a036e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87c4b950469140e499e7a17b16f8994b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}