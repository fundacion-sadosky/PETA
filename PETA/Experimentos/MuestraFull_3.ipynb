{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhN8vz1PQ8Wv",
        "outputId": "87dad64a-4a89-48c7-91eb-68fc0bb2990e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "except ModuleNotFoundError:\n",
        "    print('Not running on Google')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vpyelL4yXvC0"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChL61Twesn0o"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRvvbIrxP5Hd",
        "outputId": "9b6a833b-f5ed-4d5e-cb61-4ed3184013d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.13.1+cu116\n",
            "Torchvision Version:  0.14.1+cu116\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, utils, models, datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nibabel as nib\n",
        "import scipy.ndimage as ndi\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import io\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuración"
      ],
      "metadata": {
        "id": "INZ-JH53dh-Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HErqZ9GNCDq6"
      },
      "outputs": [],
      "source": [
        "imagesFolder = '/content/gdrive/MyDrive/Tesis/Imagenes/ADNI-MUESTRA-FULL-stripped-preprocessed'\n",
        "trainDatasetCSV = '/content/gdrive/MyDrive/Tesis/Imagenes/ADNI-MUESTRA-FULL/MUESTRA_train.csv'\n",
        "valDatasetCSV =   '/content/gdrive/MyDrive/Tesis/Imagenes/ADNI-MUESTRA-FULL/MUESTRA_val.csv'\n",
        "experimentName = 'MuestraFull3_performance_aux'\n",
        "experimentOutputFolder = '/content/gdrive/MyDrive/Tesis/Experimentos/muestraFull_3'\n",
        "experimentDescription = 'Testeo de  stripping y removiendo las superfícies menores a 90x90. Nuevo código, carga imágenes. Salida auxiliar habilitada. auxEnabled = true'\n",
        "executions = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VYNyT00wpzwU"
      },
      "outputs": [],
      "source": [
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 3\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 10\n",
        "\n",
        "dl_num_workers = 4\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 1\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "usePretrained = True\n",
        "\n",
        "# Habilita la salida auxiliar\n",
        "auxEnabled = True\n",
        "\n",
        "learningRate = 0.0001\n",
        "dropoutRate = 0.6\n",
        "crossEntrophyWeigths = torch.tensor([485.0,283.0,1167.0])\n",
        "\n",
        "# Data augmentation\n",
        "dataAugmentation = {\n",
        "    \"angleTransformChance\": 0.1,\n",
        "    \"zoomTransformChance\": 0.1,\n",
        "    \"shiftTransformChance\": 0.0\n",
        "}\n",
        "# dataAugmentation = {}\n",
        "\n",
        "validationCacheSize = 300\n",
        "trainCacheSize = 0\n",
        "\n",
        "debug = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a2ZFcEXjwezm"
      },
      "outputs": [],
      "source": [
        "f = open(os.path.join(experimentOutputFolder, experimentName + \"_params.txt\"), \"w\")\n",
        "f.write(\"batch_size: \" + str(batch_size) + \"\\n\")\n",
        "f.write(\"dl_num_workers: \" + str(dl_num_workers) + \"\\n\")\n",
        "f.write(\"epochs: \" + str(num_epochs) + \"\\n\")\n",
        "f.write(\"feature_extract: \" + str(feature_extract) + \"\\n\")\n",
        "f.write(\"usePretrained: \" + str(usePretrained) + \"\\n\")\n",
        "f.write(\"auxEnabled: \" + str(auxEnabled) + \"\\n\")\n",
        "f.write(\"learningRate: \" + str(learningRate) + \"\\n\")\n",
        "f.write(\"dropoutRate: \" + str(dropoutRate) + \"\\n\")\n",
        "f.write(\"cross entrophy weights: \" + str(crossEntrophyWeigths) + \"\\n\")\n",
        "f.write(\"dataAugmentation: \" + str(json.dumps(dataAugmentation)) + \"\\n\")\n",
        "f.write(\"executions: \" + str(executions) + \"\\n\")\n",
        "f.write(\"validationCacheSize: \" + str(validationCacheSize) + \"\\n\")\n",
        "f.write(\"trainCacheSize: \" + str(trainCacheSize) + \"\\n\")\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zJYNgYD9AC4X"
      },
      "outputs": [],
      "source": [
        "f = open(os.path.join(experimentOutputFolder, experimentName + \"_descripcion.txt\"), \"w\")\n",
        "f.write(experimentDescription)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilidades"
      ],
      "metadata": {
        "id": "ICvsarqhdkaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logDebug(str):\n",
        "    if debug:\n",
        "        print(str)"
      ],
      "metadata": {
        "id": "kbR_0LKedYLw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VDba_NBLQOou"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/8598673/how-to-save-a-pylab-figure-into-in-memory-file-which-can-be-read-into-pil-image\n",
        "def fig2img(fig):\n",
        "    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, facecolor='black', dpi = 64, transparent=False) # dpi Requerido para que la imagen sea 512x512\n",
        "    buf.seek(0)\n",
        "    img = Image.open(buf)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K-Z1h8wrQaiB"
      },
      "outputs": [],
      "source": [
        "def clipped_zoom(img, zoom_factor, **kwargs):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
        "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
        "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
        "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
        "\n",
        "    # Zooming out\n",
        "    if zoom_factor < 1:\n",
        "\n",
        "        # Bounding box of the zoomed-out image within the output array\n",
        "        zh = int(np.round(h * zoom_factor))\n",
        "        zw = int(np.round(w * zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        # Zero-padding\n",
        "        out = np.zeros_like(img)\n",
        "        out[top:top+zh, left:left+zw] = ndi.zoom(img, zoom_tuple, **kwargs)\n",
        "\n",
        "    # Zooming in\n",
        "    elif zoom_factor > 1:\n",
        "\n",
        "        # Bounding box of the zoomed-in region within the input array\n",
        "        zh = int(np.round(h / zoom_factor))\n",
        "        zw = int(np.round(w / zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        out = ndi.zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
        "\n",
        "        # `out` might still be slightly larger than `img` due to rounding, so\n",
        "        # trim off any extra pixels at the edges\n",
        "        trim_top = ((out.shape[0] - h) // 2)\n",
        "        trim_left = ((out.shape[1] - w) // 2)\n",
        "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
        "\n",
        "    # If zoom_factor == 1, just return the input array\n",
        "    else:\n",
        "        out = img\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelectGridImage(object):\n",
        "    \"\"\"Selects a grid from the image\n",
        "    \"\"\"\n",
        "    def __init__(self, angleTransformChance = 0.0, zoomTransformChance = 0.0, shiftTransformChance = 0.0):\n",
        "        self.angleTransformChance = angleTransformChance\n",
        "        self.zoomTransformChance = zoomTransformChance\n",
        "        self.shiftTransformChance = shiftTransformChance\n",
        "\n",
        "    def __call__(self, studyID):\n",
        "        # angleTransformChance = 0.1, zoomTransformChance = 0.1, shiftTransformChance = 0.1,\n",
        "        filename = \"normal.png\"\n",
        "        if self.angleTransformChance > random.uniform(0.0, 1.0):\n",
        "            filename = random.choice([\"angle15Left.png\", \"angle15Right.png\"])\n",
        "        if random.uniform(0.0, 1.0) < self.zoomTransformChance:\n",
        "            filename = random.choice([\"zoomIn.png\", \"zoomOut.png\"])\n",
        "        if random.uniform(0.0, 1.0) < self.shiftTransformChance:\n",
        "            filename = random.choice([\"shiftXLeft.png\", \"shiftXRight.png\", \"shiftYTop.png\", \"shiftYBottom.png\"])\n",
        "        \n",
        "        return os.path.join(studyID, filename)"
      ],
      "metadata": {
        "id": "eVgG7KAS5zyq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoadGridImage(object):\n",
        "    \"\"\"Loads an image\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, filePath):\n",
        "      fullPath = os.path.join(imagesFolder, filePath)\n",
        "\n",
        "      return Image.open(fullPath)"
      ],
      "metadata": {
        "id": "nAA2bysa6kdx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TX-5K8GGG-zT"
      },
      "outputs": [],
      "source": [
        "class RemoveTransparency(object):\n",
        "    def __call__(self, sample):\n",
        "      # La imagen se guarda con transparencia, removemos la dimension de indice 3\n",
        "      return sample[0:3, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UmM3wjZ0Qfa4"
      },
      "outputs": [],
      "source": [
        "class ToLabelOutput(object):\n",
        "    def __call__(self, label):\n",
        "        if label == \"CN\":\n",
        "            return 0\n",
        "        elif label == \"AD\":\n",
        "            return 1\n",
        "        else:\n",
        "            return 2 # MCI, LMCI, EMCI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ADNIDataset(Dataset):\n",
        "    \"\"\"ADNI dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, name, csv_file, root_dir, transform=None, target_transform = None, \n",
        "                 cacheSize = 200):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.csv = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        # item_cache directamente almacena los items procesados\n",
        "        self.cacheSize = cacheSize\n",
        "        self.item_cache = [None] * cacheSize\n",
        "        self.cachedItems = 0\n",
        "\n",
        "    def __len__(self):\n",
        "      return int(len(self.csv))\n",
        "\n",
        "    def storeInCache(self, idx, image, label):\n",
        "        if self.cacheSize > 0 and self.item_cache[idx % self.cacheSize] == None:  \n",
        "            logDebug(self.name + \"] Storing item in cache: \" + str(idx))\n",
        "            self.cachedItems += 1\n",
        "            # Storing item in cache\n",
        "            self.item_cache[idx % self.cacheSize] = {\n",
        "                \"id\": idx,\n",
        "                \"label\": label,\n",
        "                \"image\": image\n",
        "            }\n",
        "            logDebug(self.name + \"] Cached items: \" + str(self.cachedItems))\n",
        "\n",
        "    def itemInCache(self, idx):\n",
        "        if self.cacheSize > 0 and self.item_cache[idx % self.cacheSize] != None and self.item_cache[idx % self.cacheSize][\"id\"] == idx:\n",
        "            return self.item_cache[idx % self.cacheSize]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        if self.itemInCache(idx):\n",
        "            item = self.itemInCache(idx)\n",
        "            return item[\"image\"], item[\"label\"], \n",
        "\n",
        "        studyID = self.csv.iloc[idx, 0]\n",
        "        subjectID = self.csv.iloc[idx, 1]\n",
        "        processFormat = self.csv.iloc[idx, 7]\n",
        "        date = self.csv.iloc[idx, 9]\n",
        "        label = self.csv.iloc[idx, 2]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(studyID)\n",
        "            \n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        self.storeInCache(idx, image, label)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "JmEN7Kfc31ge"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tMPKNDmqyALS"
      },
      "outputs": [],
      "source": [
        "def printFile(text, file):\n",
        "  print(text)\n",
        "  if file != None:\n",
        "      file.write(text + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW1D_vQnpzDk"
      },
      "source": [
        "# Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m44_ZbqJvsQ9"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=True, logFile = None):\n",
        "    f = None\n",
        "    if logFile != None:\n",
        "        f = open(logFile, \"w\")\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        printFile('Epoch {}/{}'.format(epoch, num_epochs - 1), f)\n",
        "        printFile('-' * 10, f)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            it = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        if auxEnabled: \n",
        "                          loss1 = criterion(outputs, labels)\n",
        "                          loss2 = criterion(aux_outputs, labels)\n",
        "                          loss = loss1 + 0.4*loss2                          \n",
        "                        else:\n",
        "                          loss = criterion(outputs, labels)\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                logDebug(\"Iteration \" + str(it))\n",
        "                it += 1\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            printFile('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), f)\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                val_loss_history.append(epoch_loss)\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                train_loss_history.append(epoch_loss)\n",
        "            \n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    printFile('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60), f)\n",
        "    printFile('Best val Acc: {:4f}'.format(best_acc), f)\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    if logFile != None:\n",
        "        f.close()\n",
        "    return model, val_acc_history, val_loss_history, train_acc_history, train_loss_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Vl-UuMFJv0_S"
      },
      "outputs": [],
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuMUC0zqwFLw"
      },
      "source": [
        "# Initialize and reshape inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "735216a5647b49b9b37dcea0a4702039",
            "99943af575b44732a00ee5c261b7e2ab",
            "8dfc6b118d664cc098b89275b05821e9",
            "5a697b99d51a423f8cdb3deeabbbf77c",
            "4536bde21b034a38b4936d246411c468",
            "37591d36ca4c41bd96bafab2af9fb1f2",
            "6ef2e826ce794eac83469e1bff4178cc",
            "19fb26a2f8034c54bd5d183a44e37b60",
            "d70692e98bb64874b621efff67223642",
            "d1e6c78aa0714799977d7441b029fd32",
            "b4fbc6cdb6fe4a6189bbc50a86bd93af"
          ]
        },
        "id": "GqZfuwYwwLw2",
        "outputId": "794d902f-f0bb-43f8-de88-cc620691c94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/104M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "735216a5647b49b9b37dcea0a4702039"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num featurs2048\n",
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=768, out_features=3, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.6, inplace=False)\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained, \n",
        "                                       aux_logits = True)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        # num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        # model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        print(\"num featurs\" + str(num_ftrs))\n",
        "        # Fuente: https://github.com/bdrad/petdementiapub/blob/master/petdementia_source.py\n",
        "        model_ft.dropout = nn.Dropout(dropoutRate)\n",
        "        model_ft.fc = nn.Sequential(\n",
        "          nn.Linear(num_ftrs,1024),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(1024,num_classes),\n",
        "        )\n",
        "\n",
        "        if auxEnabled :\n",
        "          model_ft.AuxLogits.fc = nn.Sequential(\n",
        "            nn.Linear(768,num_classes), # elegido arbitrariamentoe\n",
        "          )\n",
        "          \n",
        "        input_size = 512 \n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=usePretrained)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfACeWNcwYqY",
        "outputId": "5c452dc3-e41c-4fae-a0b9-5690730c1426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ]
        }
      ],
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "trainGridArgs = dataAugmentation.copy()\n",
        "\n",
        "valGridArgs = {}\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        SelectGridImage(**trainGridArgs),\n",
        "        LoadGridImage(),\n",
        "        transforms.ToTensor(),\n",
        "        RemoveTransparency(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        SelectGridImage(),\n",
        "        LoadGridImage(),\n",
        "        transforms.ToTensor(),\n",
        "        RemoveTransparency(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "\n",
        "image_datasets = {\n",
        "    'train': ADNIDataset('trainDL', trainDatasetCSV, imagesFolder, transform = data_transforms['train'], target_transform =ToLabelOutput(), cacheSize = trainCacheSize),\n",
        "    'val': ADNIDataset('valDL', valDatasetCSV, imagesFolder, transform = data_transforms['val'], target_transform =ToLabelOutput(), cacheSize = validationCacheSize )\n",
        "}\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=dl_num_workers) for x in ['train', 'val']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XciJ190PwerB",
        "outputId": "de247f3d-959e-4599-ff3d-ac36b0627974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.0.weight\n",
            "\t AuxLogits.fc.0.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.0.weight\n",
            "\t fc.0.bias\n",
            "\t fc.2.weight\n",
            "\t fc.2.bias\n"
          ]
        }
      ],
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(params_to_update, lr=learningRate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CVJl5AvUqK13"
      },
      "outputs": [],
      "source": [
        "def test_model(model,dataloaders,device):\n",
        "    classStats = [{\n",
        "        'fn': 0,\n",
        "        'tn': 0,\n",
        "        'tp': 0,\n",
        "        'fp': 0,\n",
        "        'n': 0,\n",
        "    } for i in range(num_classes)]\n",
        "    correctlyPredicted = 0\n",
        "    n = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            # Iteramos para chequear estadisticas\n",
        "            for i, correctClass in enumerate(labels.data):\n",
        "              n += 1\n",
        "              predictedClass = int(preds[i].item())\n",
        "              correctClass = int(correctClass.item())\n",
        "              classStats[correctClass]['n'] += 1\n",
        "              if correctClass == predictedClass:\n",
        "                  correctlyPredicted += 1\n",
        "                  classStats[correctClass]['tp'] += 1\n",
        "                  for i in range(num_classes):\n",
        "                      if i != correctClass:\n",
        "                          classStats[correctClass]['tn'] += 1\n",
        "              else:\n",
        "                  classStats[correctClass]['fn'] += 1\n",
        "                  classStats[predictedClass]['fp'] += 1\n",
        "                  for i in range(num_classes):\n",
        "                      if i != correctClass and i != predictedClass:\n",
        "                          classStats[correctClass]['tn'] += 1\n",
        "    accuracy = correctlyPredicted * 1.0 / n\n",
        "    return classStats, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aK3auwSS05Le"
      },
      "outputs": [],
      "source": [
        "def printClassStats(stats):\n",
        "  recall = sensitivity = stats['tp'] / (stats['tp'] + stats['fn']) # prob positive test result\n",
        "  specificity = stats['tn'] / (stats['tn'] + stats['fp'])          # prob negative test result\n",
        "  if stats['tp'] + stats['fp'] > 0:\n",
        "    precision = stats['tp'] / (stats['tp'] + stats['fp'])          # prob of recognized positive actually correct\n",
        "  else:\n",
        "    precision = 1\n",
        "    printFile(\"Setting precision as 1 but no positive value has been reported, so this is placeholder\", f)\n",
        "  if precision + recall == 0:\n",
        "    printFile(\"Setting f1 as 0 because precision + recall is ZERO\", f)\n",
        "    f1 = 0.0\n",
        "  else:\n",
        "    f1 = 2 * (precision * recall) / ( precision + recall )\n",
        "  printFile(\"Sensitivity (%): \" + str(round(sensitivity * 100)), f)\n",
        "  printFile(\"Specificity (%): \" + str(round(specificity * 100)), f)\n",
        "  printFile(\"Precision  (%): \" + str(round(precision * 100)), f)\n",
        "  printFile(\"F1 Score  (%): \" + str(round(f1 * 100)), f)\n",
        "  printFile(\"Number of images: \" + str(stats['n']), f)\n",
        "  return recall, specificity, precision, f1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading cache\n",
        "#dataloaders_dict['train'].num_workers = 0\n",
        "#dataloaders_dict['val'].num_workers = 0\n",
        "\n",
        "#for idx, (x, y) in enumerate(dataloaders_dict['train']):\n",
        "#    print(f\"Loading Cache {idx*batch_size}.\\r\", end='')\n",
        "\n",
        "#for idx, (x, y) in enumerate(dataloaders_dict['val']):\n",
        "#    print(f\"Loading Cache {idx*batch_size}.\\r\", end='')\n",
        "\n",
        "#dataloaders_dict['train'].num_workers = dl_num_workers\n",
        "#dataloaders_dict['val'].num_workers = dl_num_workers"
      ],
      "metadata": {
        "id": "Bp5X2oNCki65"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "D84am68jwlX6",
        "outputId": "c3b92283-9009-4814-fff2-3bd98f2aa8b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Execution 0 begin ---\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.8612 Acc: 0.6000\n",
            "val Loss: 0.5859 Acc: 0.6019\n",
            "Training complete in 11m 40s\n",
            "Best val Acc: 0.601852\n",
            "accuracy: 0.6018518518518519\n",
            "CN stats: \n",
            "Setting precision as 1 but no positive value has been reported, so this is placeholder\n",
            "Sensitivity (%): 0\n",
            "Specificity (%): 100\n",
            "Precision  (%): 100\n",
            "F1 Score  (%): 0\n",
            "Number of images: 54\n",
            "\n",
            "AD stats: \n",
            "Setting precision as 1 but no positive value has been reported, so this is placeholder\n",
            "Sensitivity (%): 0\n",
            "Specificity (%): 100\n",
            "Precision  (%): 100\n",
            "F1 Score  (%): 0\n",
            "Number of images: 32\n",
            "\n",
            "MCI stats: \n",
            "Sensitivity (%): 100\n",
            "Specificity (%): 75\n",
            "Precision  (%): 60\n",
            "F1 Score  (%): 75\n",
            "Number of images: 130\n",
            "--- Execution End ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "accuracyValues = []\n",
        "adStatValues = []\n",
        "cnStatValues = []\n",
        "mciStatValues = []\n",
        "for i in range(0, executions):\n",
        "    experimentExecutionName = experimentName + '_' + str(i)\n",
        "    print(\"--- Execution \" + str(i) + \" begin ---\")\n",
        "    # Setup the loss fxn\n",
        "    crossEntrophyWeigths = crossEntrophyWeigths.to(device)\n",
        "    criterion = nn.CrossEntropyLoss(crossEntrophyWeigths)\n",
        "\n",
        "    logFile = os.path.join(experimentOutputFolder, experimentExecutionName + '_train.log')\n",
        "\n",
        "    # Train and evaluate\n",
        "    model_ft, val_acc_hist, val_loss_hist, train_acc_hist, train_loss_hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"), logFile = logFile)\n",
        "\n",
        "    torch.save(model_ft.state_dict(), os.path.join(experimentOutputFolder, experimentExecutionName + '.pth'))\n",
        "\n",
        "    # validation accuracy\n",
        "    fig = plt.figure()\n",
        "    lst = [ x.cpu().item() for x in val_acc_hist ]\n",
        "    plt.plot(lst)\n",
        "    ax = plt.gca()\n",
        "    plt.text(0.05, 0.9, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.8, 'LR = ' + str(learningRate), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.7, 'batch = ' + str(batch_size), transform=ax.transAxes)\n",
        "    plt.suptitle(experimentExecutionName + ' (acc set de validacion)')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_val_acc.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # validation loss\n",
        "    fig = plt.figure()\n",
        "    plt.plot(val_loss_hist)\n",
        "    ax = plt.gca()\n",
        "    plt.text(0.05, 0.3, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.2, 'LR = ' + str(learningRate), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.1, 'batch = ' + str(batch_size), transform=ax.transAxes)\n",
        "    plt.suptitle(experimentExecutionName + ' (loss set de validacion)')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_val_loss.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # train accuracy\n",
        "    fig = plt.figure()\n",
        "    lst = [ x.cpu().item() for x in train_acc_hist ]\n",
        "    ax = plt.gca()\n",
        "    plt.text(0.05, 0.9, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.8, 'LR = ' + str(learningRate), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.7, 'batch = ' + str(batch_size), transform=ax.transAxes)\n",
        "    plt.plot(lst)\n",
        "    plt.suptitle(experimentExecutionName + ' (accuracy set de train)')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_train_acc.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # train loss\n",
        "    fig = plt.figure()\n",
        "    ax = plt.gca()\n",
        "    plt.text(0.05, 0.3, 'FE = ' + str(feature_extract), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.2, 'LR = ' + str(learningRate), transform=ax.transAxes)\n",
        "    plt.text(0.05, 0.1, 'batch = ' + str(batch_size), transform=ax.transAxes)\n",
        "    plt.plot(train_loss_hist)\n",
        "    plt.suptitle(experimentExecutionName + ' (Loss set de train)')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_train_loss.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    stats, accuracy = test_model(model_ft, dataloaders_dict, device)\n",
        "\n",
        "    print(\"accuracy: \" + str(accuracy))\n",
        "    accuracyValues.append(accuracy)\n",
        "\n",
        "    f = open(os.path.join(experimentOutputFolder, experimentExecutionName + \"_stats.txt\"), \"w\")\n",
        "    printFile(\"CN stats: \", f)\n",
        "    recall, specificity, precision, f1 = printClassStats(stats[0])\n",
        "    cnStatValues.append({\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"precision\": precision,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "    # AD\n",
        "    printFile(\"\\nAD stats: \", f)\n",
        "    recall, specificity, precision, f1 = printClassStats(stats[1])\n",
        "    adStatValues.append({\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"precision\": precision,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "    # MCI\n",
        "    printFile(\"\\nMCI stats: \", f)\n",
        "    recall, specificity, precision, f1 = printClassStats(stats[2])\n",
        "    mciStatValues.append({\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"precision\": precision,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "    f.close()\n",
        "\n",
        "    print(\"--- Execution End ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WuiTfuCMd8j4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba9c602-a208-4040-8a7b-afe7c72381da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final stats: \n",
            "Executions: 1\n",
            "Accuracy mean: 0.6018518805503845\n",
            "Accuracy std: nan\n",
            "Best accuracy: 0.6018518805503845\n",
            "Worst accuracy: 0.6018518805503845\n"
          ]
        }
      ],
      "source": [
        "accuracyValues = torch.tensor(accuracyValues)\n",
        "std, mean = torch.std_mean(accuracyValues)\n",
        "f = open(os.path.join(\n",
        "    os.path.join(experimentOutputFolder, experimentName + '_results.txt')), \"w\")\n",
        "printFile(\"Final stats: \", f)\n",
        "printFile(\"Executions: \" + str(executions), f)\n",
        "printFile(\"Accuracy mean: \" + str(mean.item()), f)\n",
        "printFile(\"Accuracy std: \" + str(std.item()), f)\n",
        "printFile(\"Best accuracy: \" + str(accuracyValues.max().item()), f)\n",
        "printFile(\"Worst accuracy: \" + str(accuracyValues.min().item()), f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA-ShjPRUYxP"
      },
      "source": [
        "# ROC - AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mmKtfcWNUOIR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f1360183-a025-46f2-d79b-f151c53c4448"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def sortByX(point):\n",
        "  return point[0]\n",
        "\n",
        "# Se necesita ordenar los puntos para llamar a torch.trapezoid con los puntos ordenados por la coordenada X\n",
        "def sortListsByX(x, y):\n",
        "    points = zip(x, y)\n",
        "    points = list(points)\n",
        "    points.sort(key=sortByX)\n",
        "    x, y = ([ a for a,b in points ], [ b for a,b in points ])\n",
        "    return x, y\n",
        "\n",
        "fig = plt.figure()\n",
        "ad_y = ad_tpr = [ x[\"recall\"] for x in adStatValues ]\n",
        "ad_x = ad_fpr = [ 1.0 - x[\"specificity\"] for x in adStatValues ]\n",
        "ad_x, ad_y = sortListsByX(ad_x, ad_y)\n",
        "\n",
        "cn_y = cn_tpr = [ x[\"recall\"] for x in cnStatValues ]\n",
        "cn_x = cn_fpr = [ 1.0 - x[\"specificity\"] for x in cnStatValues ]\n",
        "cn_x, cn_y = sortListsByX(cn_x, cn_y)\n",
        "\n",
        "mci_y = mci_tpr = [ x[\"recall\"] for x in mciStatValues ]\n",
        "mci_x = mci_fpr = [ 1.0 - x[\"specificity\"] for x in mciStatValues ]\n",
        "mci_x, mci_y = sortListsByX(mci_x, mci_y)\n",
        "\n",
        "decimals = 3\n",
        "ad_auc = round(torch.trapezoid(torch.tensor(ad_y), torch.tensor(ad_x)).item(), decimals)\n",
        "cn_auc = round(torch.trapezoid(torch.tensor(cn_y), torch.tensor(cn_x)).item(), decimals)\n",
        "mci_auc = round(torch.trapezoid(torch.tensor(mci_y), torch.tensor(mci_x)).item(), decimals)\n",
        "\n",
        "plt.title(experimentName + \" ROC\")\n",
        "\n",
        "plt.plot(ad_fpr, ad_tpr)\n",
        "plt.plot(cn_fpr, cn_tpr)\n",
        "plt.plot(mci_fpr, mci_tpr)\n",
        "\n",
        "plt.legend([\"AD (\"+str(ad_auc)+\")\", \"CN (\"+str(cn_auc)+\")\", \"MCI (\"+str(mci_auc)+\")\"], loc =\"lower right\")\n",
        "plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_auc_roc.png'))\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yUUyX_2fpMSX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "891d0f89-cb4a-41d0-8c22-4cb78b8c0877"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig = plt.figure()\n",
        "ad_y = ad_tpr = [ x[\"recall\"] for x in adStatValues ]\n",
        "ad_x = ad_fpr = [ 1.0 - x[\"specificity\"] for x in adStatValues ]\n",
        "ad_x, ad_y = sortListsByX(ad_x, ad_y)\n",
        "\n",
        "decimals = 3\n",
        "ad_auc = round(torch.trapezoid(torch.tensor(ad_y), torch.tensor(ad_x)).item(), decimals)\n",
        "\n",
        "plt.title(experimentName + \" AD ROC\")\n",
        "\n",
        "plt.plot(ad_fpr, ad_tpr)\n",
        "\n",
        "plt.legend([\"AD (\"+str(ad_auc)+\")\"], loc =\"lower right\")\n",
        "plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_auc_roc_ad.png'))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8hxzslmopMju",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "31cb5c5a-816f-4f53-dc98-43ff4272c866"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "cn_y = cn_tpr = [ x[\"recall\"] for x in cnStatValues ]\n",
        "cn_x = cn_fpr = [ 1.0 - x[\"specificity\"] for x in cnStatValues ]\n",
        "cn_x, cn_y = sortListsByX(cn_x, cn_y)\n",
        "\n",
        "decimals = 3\n",
        "cn_auc = round(torch.trapezoid(torch.tensor(cn_y), torch.tensor(cn_x)).item(), decimals)\n",
        "\n",
        "plt.title(experimentName + \" CN ROC\")\n",
        "\n",
        "plt.plot(cn_fpr, cn_tpr)\n",
        "\n",
        "plt.legend([\"CN (\"+str(cn_auc)+\")\"], loc =\"lower right\")\n",
        "plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_auc_roc_cn.png'))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "E9Z0TN2RpMzv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "5fae1601-83ff-4bf0-cc39-180424a7a8a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbXElEQVR4nO3dfZxU1Z3n8c83PIhRCAqtAs2IWTsGVKLYoM7GlRWJwjiQOE5GEp+jToxOMjvRDAnr44wJGmdinCS6ziwR4o4mMYmajUZRQ8xmRW2iIuqoiEQaEDs8JBJFRX/zxz2NRdsP1d3V1c3h+3696kXdc+49dc6tqm/dOvd2oYjAzMzy9b7e7oCZmfUsB72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9FZxkiZLaixZXinp2Cr3QZK+K2mjpEeq+dhmfY2DvgelgHtT0vAW5Y9JCkljevCxtwvbbrQTkv4oaXO6bapA96rho8BUoDYiJvV2Z3Ik6Yz0+vhGi/KZqfymkrKBki6T9Hx6Pa2UNK/5PSBpkaSz23mct9Pr7w+SnpB0Qot1dpH0NUkvSXo9Pc5FktRiveMkPSjpVUlNkn4paUal9klf5aDveS8Cs5oXJB0MvL/3uvMuSf3LXPUjEbF7ug3tyT5VQhrXvsDKiPhjF7e38rwAfLLFPjsdeK7FercBM4BPAR8APgIsAaaU+TgPRcTuwFDgO8CtkoaW1P8wtTUdGAycCpwLfLN5BUknpfUWALXA3sAlwJ+X2YcdV0T41kM3YCXwP4FHS8quAeYAAYxJZYuAs0vWOQP4fyXLHwYWAhuAZ4FPltRNB54GXgVWAxcCuwGvA+8Am9NtJHAZxRvuZuAPwNnAJOAhYBOwFvgWMLCk/QD2b2Vs25UDNwH/mO5PBhpb7IdjO9hXzX37fhrLbyg+YJrrRwI/ApooPjw/38q2zeP6a2AL8HYa++VpvXOA5Wk/3gmMbDGe84HnU/uTgUbgS8Arad98PO3v51IbXynZvpz9+NnU/ibg24BK6s8BnkljfxqY0NG429mXbfYFGJP60r9k/UWk1x9wPfCjkrqrgPtL+9rydQr8HPizVLYn8DLwdeCmVHYsxetxdDt93taHth6nZPn9aQwT0/KU9HyPbrHd4ek1sD8g4CXgot7Ohd64+Yi+5y0GhkgaK6kfcDJFIJVF0m4UIf/vwF5p++9IGpdW+d/AX0fEYOAg4IEojmKnAWvi3SPxNWn9mRShOBT4PxRvhP8BDAeOpHjTfK4b4+2OmRRHXHtSjPd2SQMkvQ/4KfAEMCr18W8lHddi2+ZxLaAI1YfS2C+VdAzwNeCTwAjgt8CtLR7/4xTh0Lxv9wEGpce8BPhX4BTgMOAo4GJJ+6V1y9mPJwATgfGpH8cBSPpLig+r04AhFEe+68scd2u685x+ETg4TZccBXwGOD1ScrZhQeo7FK/PO4A3SuqPBR6JiFVl9qFN6T10JvAWxXMIxRTdwy3bj4iHKT6spwAHAKMpXiM7HQd9dXyP4o0wleKobXUntj2BYgriuxGxNSIeozjC+8tU/xYwTtKQiNgYEb/poL2HIuL2iHgnIl6PiCURsTi1vRL4X8DRLbb5jaRN6XZdJ/reWUsi4raIeAv4Z4qQPYIiHGsi4oqIeDMiVlCE7sltjauVtj8NzIuI30TEG8CXgSNbnCf5WkRsKNn+LeDK1J9bKYLzmxHxakQ8RXHk/RGAMvfj3IjYFBEvAb8ADknlZwNXR8SjUVgeEb8tc9zvUWZf2tr2NYppj3+mOCD5m4jo6FzPT4DJkj5A8Tpf0KJ+GMU3i+44Ip0f2kLxrfiUiHgl1Q1vp/21qX5YyfJOx3OR1fE94EFgP977JujIvsDhLU6C9k9tAvwFxfTQXElLgdkR8VA77W131CPpQxRv6nqKr8T9KeZOS02IiOWd7HdXbOtbRLyTTiaPpPiaPrLFPugH/Kq1bdswkmI6qLn9zZLWUxwpr2yjjfUR8Xa63xz+60rqXwd2h7L348sl919r3pbiSPOFVvq8Lx2P+z3K7EubIuJhSSsovkH+oIz1X5f0M4rX4bCI+LWkaSWrrAc+VO7jt2FxRHxU0u4U32KPKunb74C6NrYbkerXlyy/2M2+7HB8RF8F6ejsRYr53R+3ssof2f4E7T4l91cBv4yIoSW33SPivNT2oxExk+JNeTvvvvjb+qrdsvx64D+AuogYAnyFYj6zI6+10+euGt18J01b1AJrKPbBiy32weCImF6ybUc/w7qGIjib29+N4iiv9NtVd37Ktav7EYrx/Zc2yjsad2f70nxyus3nTtL5wC4U++xLZY5hAcW0T2vTkvcBkyTVltlWmyJiM3AecKqkQ0vaP1zS6NJ1JR1O8Zp6gOLc1iqKA6OdjoO+ej4DHBOtXwXyOHCipPdL2j+t2+z/Ah+SdGqarx4gaWKa8x8o6dOSPpCmF/5AcQIWiiPPYenrdHsGp+02S/owxZuoHI8Dn5LUT9LxlDk10IHDJJ2YruD4W4p53sXAI8Crkv5e0q7pMQ+SNLETbd8CnCnpEEm7AF+lmNddWYF+Q9f3I8C/ARdKOkyF/SXtS9fH3WZfIqKJ4sPtlNTeWZR8yKRvA/9IcS7iVOBLkg4pYwy/pJia/JeWFRFxH8V5pp+kMfaXNFjSZ9Pjd0pEbKDYZ5eUtH8/8CNJB6ZxHUHxoXN9RDyfzjH8HcV5lTMlDZH0PkkflXRjZ/uwo3HQV0lEvBARDW1UfwN4kyKc51OcJG3e7lXgYxTzsmsovv5fRXHEBcWbcaWkP1CcgPx02u4/KMJtRZpbH9nGY19IccnbqxTzv98vc0hfoLgsbVN6zNvL3K49dwB/BWykGNeJEfFWmj45gWJO+0WKr+L/RnGZXllSGFxMcX5jLUW4tTvX3Uld3Y9ExA+BKylOQL9KsS/37Ma4O+rLOcBFFNMZBwL/H7ZdVnozcFVEPBERz1N8G/he+nBsbwwREfenEG7NScBdqS+/B5ZRTC3d18FY2nItMF3S+LT8FxTnPX5OcaXVzRRTPH9T0sfbKF5fZ1G8l9ZRfKjd0cU+7DDU/sl0s+qQdBnF5Zqn9HZfzHLjI3ozs8w56K1qJN2td39KofT2ld7u247G+9I6w1M3ZmaZ8xG9mVnm+twfTA0fPjzGjBnT290wM9uhLFmy5HcRUdNaXZ8L+jFjxtDQ0NZViGZm1hpJv22rzlM3ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZ6zDoJc2T9IqkZW3US9J1kpZLWippQov6IZIaJX2rUp02M7PylXNEfxNwfDv104C6dDsXuL5F/T8AD3alc2Zm1n0dBn1EPAhsaGeVmcCCKCwGhkoaASDpMGBv4N5KdNbMzDqvEnP0o4BVJcuNwChJ7wP+CbiwowYknSupQVJDU1NTBbpkZmbNevJk7OeAuyKisaMVI+LGiKiPiPqampoe7JKZ2c6nfwXaWA2MLlmuTWVHAkdJ+hywOzBQ0uaImF2BxzQzszJVIujvBC6QdCtwOPD7iFgLfLp5BUlnAPUOeTOz6usw6CXdAkwGhktqBC4FBgBExA3AXcB0YDnwGnBmT3XWzMw6r8Ogj4hZHdQHcH4H69xEcZmmmZlVmf8y1swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMdRj0kuZJekXSsjbqJek6ScslLZU0IZUfIukhSU+l8r+qdOfNzKxj5RzR3wQc3079NKAu3c4Frk/lrwGnRcSBaftrJQ3tck/NzKxL+ne0QkQ8KGlMO6vMBBZERACLJQ2VNCIinitpY42kV4AaYFM3+2xmZp1QiTn6UcCqkuXGVLaNpEnAQOCFCjyemZl1Qo+fjJU0AvgecGZEvNPGOudKapDU0NTU1NNdMjPbqVQi6FcDo0uWa1MZkoYAPwPmRMTithqIiBsjoj4i6mtqairQJTMza1aJoL8TOC1dfXME8PuIWCtpIPATivn72yrwOGZm1gUdnoyVdAswGRguqRG4FBgAEBE3AHcB04HlFFfanJk2/STw34Bhks5IZWdExOOV676ZmXWknKtuZnVQH8D5rZTfDNzc9a6ZmVkl+C9jzcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMdBr2keZJekbSsjXpJuk7ScklLJU0oqTtd0vPpdnolO25mZuUp54j+JuD4duqnAXXpdi5wPYCkPYFLgcOBScClkvboTmfNzKzzOgz6iHgQ2NDOKjOBBVFYDAyVNAI4DlgYERsiYiOwkPY/MMzMrAdUYo5+FLCqZLkxlbVV/h6SzpXUIKmhqampAl0yM7NmfeJkbETcGBH1EVFfU1PT290xM8tKJYJ+NTC6ZLk2lbVVbmZmVVSJoL8TOC1dfXME8PuIWAvcA3xM0h7pJOzHUpmZmVVR/45WkHQLMBkYLqmR4kqaAQARcQNwFzAdWA68BpyZ6jZI+gfg0dTUFRHR3kldMzPrAR0GfUTM6qA+gPPbqJsHzOta18zMrBL6xMlYMzPrOQ56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMlRX0ko6X9Kyk5ZJmt1K/r6T7JS2VtEhSbUnd1ZKekvSMpOskqZIDMDOz9nUY9JL6Ad8GpgHjgFmSxrVY7RpgQUSMB64Avpa2/VPgvwLjgYOAicDRFeu9mZl1qJwj+knA8ohYERFvArcCM1usMw54IN3/RUl9AIOAgcAuwABgXXc7bWZm5Ssn6EcBq0qWG1NZqSeAE9P9TwCDJQ2LiIcogn9tut0TEc90r8tmZtYZlToZeyFwtKTHKKZmVgNvS9ofGAvUUnw4HCPpqJYbSzpXUoOkhqampgp1yczMoLygXw2MLlmuTWXbRMSaiDgxIg4F5qSyTRRH94sjYnNEbAbuBo5s+QARcWNE1EdEfU1NTddGYmZmrSon6B8F6iTtJ2kgcDJwZ+kKkoZLam7ry8C8dP8liiP9/pIGUBzte+rGzKyKOgz6iNgKXADcQxHSP4iIpyRdIWlGWm0y8Kyk54C9gStT+W3AC8CTFPP4T0TETys7BDMza48iorf7sJ36+vpoaGjo7W6Yme1QJC2JiPrW6vyXsWZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpa5soJe0vGSnpW0XNLsVur3lXS/pKWSFkmqLan7E0n3SnpG0tOSxlSw/2Zm1oEOg15SP+DbwDRgHDBL0rgWq10DLIiI8cAVwNdK6hYAX4+IscAk4JVKdNzMzMpTzhH9JGB5RKyIiDeBW4GZLdYZBzyQ7v+iuT59IPSPiIUAEbE5Il6rSM/NzKws5QT9KGBVyXJjKiv1BHBiuv8JYLCkYcCHgE2SfizpMUlfT98QtiPpXEkNkhqampo6PwozM2tTpU7GXggcLekx4GhgNfA20B84KtVPBD4InNFy44i4MSLqI6K+pqamQl0yMzMoL+hXA6NLlmtT2TYRsSYiToyIQ4E5qWwTxdH/42naZytwOzChAv02M7MylRP0jwJ1kvaTNBA4GbizdAVJwyU1t/VlYF7JtkMlNR+mHwM83f1um5lZuToM+nQkfgFwD/AM8IOIeErSFZJmpNUmA89Keg7YG7gybfs2xbTN/ZKeBAT8a8VHYWZmbVJE9HYftlNfXx8NDQ293Q0zsx2KpCURUd9anf8y1swsc/17uwNmtnN56623aGxsZMuWLb3dlR3SoEGDqK2tZcCAAWVv46A3s6pqbGxk8ODBjBkzBkm93Z0dSkSwfv16Ghsb2W+//crezlM3ZlZVW7ZsYdiwYQ75LpDEsGHDOv1tyEFvZlXnkO+6ruw7B72ZWeYc9Ga205HEKaecsm1569at1NTUcMIJJ2wru/vuu6mvr2fcuHEceuihfPGLXwTgsssu45prrmm13WuvvZYFCxYAsGHDBqZOnUpdXR1Tp05l48aNrW4zf/586urqqKurY/78+dvKjz322Da36SwHvZntdHbbbTeWLVvG66+/DsDChQsZNerd32pctmwZF1xwATfffDNPP/00DQ0N7L///u22uXXrVubNm8enPvUpAObOncuUKVN4/vnnmTJlCnPnzn3PNhs2bODyyy/n4Ycf5pFHHuHyyy/fFu6nnnoq3/nOdyoyXl91Y2a95vKfPsXTa/5Q0TbHjRzCpX9+YIfrTZ8+nZ/97GecdNJJ3HLLLcyaNYtf/epXAFx99dXMmTOHD3/4wwD069eP8847r932HnjgASZMmED//kWs3nHHHSxatAiA008/ncmTJ3PVVVdtt80999zD1KlT2XPPPQGYOnUqP//5z5k1axYzZszgqKOOYs6cOZ0af2t8RG9mO6WTTz6ZW2+9lS1btrB06VIOP/zwbXXLli3jsMMO61R7v/71r7fbZt26dYwYMQKAffbZh3Xr1r1nm9WrVzN69Lu/GVlbW8vq1cVvRu6xxx688cYbrF+/vlP9aI2P6M2s15Rz5N1Txo8fz8qVK7nllluYPn16t9tbu3YtY8eObbVOUpeultlrr71Ys2YNw4YN61bffERvZjutGTNmcOGFFzJr1qztyg888ECWLFnSqbZ23XXX7a5v33vvvVm7di1QfAjstdde79lm1KhRrFr17v/r1NjYuN25gi1btrDrrrt2qh+tcdCb2U7rrLPO4tJLL+Xggw/ervyiiy7iq1/9Ks899xwA77zzDjfccEO7bY0dO5bly5dvW54xY8a2q2jmz5/PzJkt/wdWOO6447j33nvZuHEjGzdu5N577+W4444Dir+CffnllxkzZkx3hgg46M1sJ1ZbW8vnP//595SPHz+ea6+9llmzZjF27FgOOuggVqxY0W5b06ZN48EHH9y2PHv2bBYuXEhdXR333Xcfs2fPBqChoYGzzz4bgD333JOLL76YiRMnMnHiRC655JJtJ2aXLFnCEUccse3kbnf4Z4rNrKqeeeaZNueyd3Sf+MQnuPrqq6mrq+t2W1/4wheYMWMGU6ZMeU9da/vQP1NsZlYFc+fO3TYv310HHXRQqyHfFb7qxsysQg444AAOOOCAirR1zjnnVKQd8BG9mfWCvjZlvCPpyr5z0JtZVQ0aNIj169c77Lug+ffoBw0a1KntPHVjZlVVW1tLY2MjTU1Nvd2VHVLz/zDVGQ56M6uqAQMGdOp/R7Lu89SNmVnmHPRmZplz0JuZZa7P/WWspCbgt8Bw4He93J1q85h3HjvjuD3mnrVvRNS0VtHngr6ZpIa2/pw3Vx7zzmNnHLfH3Hs8dWNmljkHvZlZ5vpy0N/Y2x3oBR7zzmNnHLfH3Ev67By9mZlVRl8+ojczswpw0JuZZa4qQS/peEnPSlouaXYr9X8n6WlJSyXdL2nfVL6vpN9IelzSU5I+W7LNotTm4+n23v95t5d1ddwl9UMkNUr6VknZYZKeTG1ep6781/I9qIfG3Kef6+6MWdLbJeO6s6R8P0kPpza/L2lgtcZTjh4a802SXiypO6RKwylLN8f8J5LulfRMWmdMKq/O8xwRPXoD+gEvAB8EBgJPAONarPPfgfen++cB30/3BwK7pPu7AyuBkWl5EVDf0/3vjXGX1H8T+HfgWyVljwBHAALuBqb19lirMOY++1x3d8zA5jba/QFwcrp/A3Beb4+1CmO+CTipt8fXQ2NeBExN93cvWa8qz3M1jugnAcsjYkVEvAncCmz336FHxC8i4rW0uBioTeVvRsQbqXwXdqyppi6PG4ojd2Bv4N6SshHAkIhYHMUrYwHw8R4dRedUfMw7gG6NuTXpW9oxwG2paD4ZPc87qC6PWdI4oH9ELEzrbY6I16r5PFcjOEcBq0qWG1NZWz5DcaQKgKTRkpamNq6KiDUl6343fcW7uK9NYdCNcUt6H/BPwIWttNnYiTarrSfG3KyvPtfden0DgyQ1SFos6eOpbBiwKSK2ltlmtfXEmJtdmaY+viFpl8p0tyK6M+YPAZsk/VjSY5K+LqkfVXye+9Tv0Us6BagHjm4ui4hVwHhJI4HbJd0WEeuAT0fEakmDgR8Bp1Ic4e5wWhn354C7IqKxb2Va5XRyzFk81629vil+n2S1pA8CD0h6Evh9r3SwB5Q75oh4Afgy8DLF1MiNwN8DV1S7z93Vypj7A0cBhwIvAd8HzgDuqFafqnFEvxoYXbJcm8q2I+lYYA4wo2S6Zpt0JL+MYocREavTv69SzOlOqnjPu6c74z4SuEDSSuAa4DRJc9P2pV+BW22zF/XEmPv6c92t13fJ2FZQzOMeCqwHhkpqPhDL6Xlua8xExNoovAF8l3ye50bg8TTtsxW4HZhANZ/nnjyBkU4w9AdWAPvx7kmMA1uscyjFiY66FuW1wK7p/h7Ac8DBqc3hqXwAxRzXZ3t6LNUad4t1zqD9k7HTe3usPTnmvv5cd/P1vQfvXmwwHHiedIIP+CHbn6T7XG+PtQpjHpH+FXAtMLe3x1qhMfdL69ek5e8C51fzea7WTpqeQvoFYE4qu4LiUw/gPmAd8Hi63ZnKpwJL005aCpybyncDlqSypyiu1OjX2y+GSo27RRtnsH3Q11N8s3kB+Bbpr5v7yq3SY94RnutuvL7/FHgyvb6fBD5T0uYHKT7Ul6cw2KW3x1mFMT+QypYBNwO79/Y4K/Xa5t0se5Li6qKB1Xye/RMIZmaZ25EuVzQzsy5w0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWuf8EInGMY4GjshcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "mci_y = mci_tpr = [ x[\"recall\"] for x in mciStatValues ]\n",
        "mci_x = mci_fpr = [ 1.0 - x[\"specificity\"] for x in mciStatValues ]\n",
        "mci_x, mci_y = sortListsByX(mci_x, mci_y)\n",
        "\n",
        "decimals = 3\n",
        "mci_auc = round(torch.trapezoid(torch.tensor(mci_y), torch.tensor(mci_x)).item(), decimals)\n",
        "\n",
        "plt.title(experimentName + \" MCI ROC\")\n",
        "\n",
        "plt.plot(mci_fpr, mci_tpr)\n",
        "\n",
        "plt.legend([\"MCI (\"+str(mci_auc)+\")\"], loc =\"lower right\")\n",
        "plt.savefig(os.path.join(experimentOutputFolder, experimentExecutionName + '_auc_roc_mci.png'))\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "735216a5647b49b9b37dcea0a4702039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99943af575b44732a00ee5c261b7e2ab",
              "IPY_MODEL_8dfc6b118d664cc098b89275b05821e9",
              "IPY_MODEL_5a697b99d51a423f8cdb3deeabbbf77c"
            ],
            "layout": "IPY_MODEL_4536bde21b034a38b4936d246411c468"
          }
        },
        "99943af575b44732a00ee5c261b7e2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37591d36ca4c41bd96bafab2af9fb1f2",
            "placeholder": "​",
            "style": "IPY_MODEL_6ef2e826ce794eac83469e1bff4178cc",
            "value": "100%"
          }
        },
        "8dfc6b118d664cc098b89275b05821e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19fb26a2f8034c54bd5d183a44e37b60",
            "max": 108949747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d70692e98bb64874b621efff67223642",
            "value": 108949747
          }
        },
        "5a697b99d51a423f8cdb3deeabbbf77c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1e6c78aa0714799977d7441b029fd32",
            "placeholder": "​",
            "style": "IPY_MODEL_b4fbc6cdb6fe4a6189bbc50a86bd93af",
            "value": " 104M/104M [00:00&lt;00:00, 189MB/s]"
          }
        },
        "4536bde21b034a38b4936d246411c468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37591d36ca4c41bd96bafab2af9fb1f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef2e826ce794eac83469e1bff4178cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19fb26a2f8034c54bd5d183a44e37b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70692e98bb64874b621efff67223642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1e6c78aa0714799977d7441b029fd32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4fbc6cdb6fe4a6189bbc50a86bd93af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}