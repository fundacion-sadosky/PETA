{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99dee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom2nifti\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import SimpleITK as sitk # para calcular rangos\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4abd525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/hugom/PET-IA/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff277e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ADNIDataset, FleniMyriamDataset, BaseDataset\n",
    "from transforms import TransformGridImage, ToLabelOutputEBRAINS\n",
    "from train_lib import train_model, set_parameter_requires_grad, initialize_model\n",
    "from util import collectAllData\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils, models, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0012fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"last_3_classes\": {\n",
    "    \"weights\": \"/Users/hugom/Tesis/ExperimentosServer/muestraFull3700_9/muestraFull3700_9_dxlast_3classes_0_epoch21.pth\",\n",
    "    \"num_classes\": 3\n",
    "  },\n",
    "  \"sev_3_classes\": {\n",
    "    \"weights\": \"/Users/hugom/Tesis/ExperimentosServer/muestraFull3700_9/muestraFull3700_9_dxmost_severe_3classes_0_epoch31.pth\",\n",
    "    \"num_classes\": 3\n",
    "  },\n",
    "  \"visit_3_classes\": {\n",
    "    \"weights\": \"/Users/hugom/Tesis/ExperimentosServer/muestraFull3700_9/muestraFull3700_9_dxvisit_3classes_0_epoch10.pth\",\n",
    "    \"num_classes\": 3\n",
    "  },\n",
    "  \"last_2classes\": {\n",
    "    \"weights\": \"/Users/hugom/Tesis/ExperimentosServer/muestraFull3700_9/muestraFull3700_9_dxlast_2classes_0_epoch18.pth\",\n",
    "    \"num_classes\": 2\n",
    "  },\n",
    "  \"sev_2classes\": {\n",
    "    \"weights\": \"/Users/hugom/Tesis/ExperimentosServer/muestraFull3700_9/muestraFull3700_9_dxmost_severe_2classes_0_epoch16.pth\",\n",
    "    \"num_classes\": 2\n",
    "  },\n",
    "  \"visit_2classes\": {\n",
    "    \"weights\": \"/Users/hugom/Tesis/ExperimentosServer/muestraFull3700_9/muestraFull3700_9_dxvisit_2classes_0_epoch5.pth\",\n",
    "    \"num_classes\": 2\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe73657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeModel(dataloader, weights, num_classes):\n",
    "    featureExtract = False\n",
    "    dropoutRate = 0.6\n",
    "    auxEnabled = True\n",
    "    usePretrained = False\n",
    "    model_ft, input_size = initialize_model('inception', num_classes, featureExtract, dropoutRate, auxEnabled, use_pretrained=usePretrained)\n",
    "    device = torch.device(deviceName if torch.cuda.is_available() else \"cpu\")\n",
    "    model_state_dict = torch.load(weights, map_location=device)\n",
    "    model_ft.load_state_dict(model_state_dict)\n",
    "\n",
    "    model_ft.to(device)\n",
    "    \n",
    "    testY, predY = collectAllData(dataloader, model_ft, device, num_classes)\n",
    "    \n",
    "    _, preds = torch.max(torch.from_numpy(predY), 1)\n",
    "    preds = preds.cpu().numpy()\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(testY, preds)\n",
    "    bacc = sklearn.metrics.balanced_accuracy_score(testY, preds)\n",
    "    \n",
    "    print(testY)\n",
    "    print(preds)\n",
    "    \n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"B acc: {bacc}\")\n",
    "    matrix = sklearn.metrics.confusion_matrix(testY, preds)\n",
    "    \n",
    "    print(\"Confusion matrix:\")\n",
    "    print(matrix)\n",
    "    \n",
    "    if (num_classes == 2):\n",
    "        #lr_auc = roc_auc_score(testY, torch.from_numpy(predY[:, 1]), average = None)\n",
    "        #print(f\"AUC ROC: {lr_auc}\")\n",
    "        return\n",
    "    \n",
    "    print(\"------------\")\n",
    "    print(\"Merging 2 with 0\")\n",
    "    \n",
    "    predY[:, 0] = predY[:, 0] + predY[:, 2] #sumo MCI con CN\n",
    "    predY = predY[:, 0:2] # Borro MCI\n",
    "    \n",
    "    _, preds = torch.max(torch.from_numpy(predY), 1)\n",
    "    preds = preds.cpu().numpy()\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(testY, preds)\n",
    "    bacc = sklearn.metrics.balanced_accuracy_score(testY, preds)\n",
    "    \n",
    "    print(f\"Accuracy merged: {acc}\")\n",
    "    print(f\"B acc merged: {bacc}\")\n",
    "    \n",
    "    print(\"Confusion matrix merged:\")\n",
    "    matrix = sklearn.metrics.confusion_matrix(testY, preds)\n",
    "    print(matrix)\n",
    "    \n",
    "    #lr_auc = roc_auc_score(testY, torch.from_numpy(predY[:, 1]), average = None)\n",
    "    #print(f\"AUC ROC: {lr_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e405d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = '/Users/hugom/PET-IA/Sets/ebrains.csv'\n",
    "imagesFolder = '/Users/hugom/PET-IA/Full-DBs/ebrains/data_nifti_stripped/hc_images_preprocessed'\n",
    "mean = 4959.78173828125\n",
    "std = 9861.69518896219\n",
    "means = [mean, mean, mean]\n",
    "stds = [std, std, std]\n",
    "ebrainsTransforms = torchvision.transforms.Compose([\n",
    "    TransformGridImage(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(means, stds)\n",
    "])\n",
    "dataset = BaseDataset('ebrains', csvFile, imagesFolder, studyIDLabel = 'ID', transform = ebrainsTransforms, target_transform = ToLabelOutputEBRAINS(), truthLabel = 'Group')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5c4893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando last_3_classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugom/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/hugom/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/Users/hugom/Library/Python/3.9/lib/python/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num featurs2048\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/hugom/PET-IA/Full-DBs/ebrains/data_nifti_stripped/hc_images_preprocessed/s0042855A-207260-00001-000001/metadata.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEjecutando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mexecuteModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mexecuteModel\u001b[0;34m(dataloader, weights, num_classes)\u001b[0m\n\u001b[1;32m      9\u001b[0m model_ft\u001b[38;5;241m.\u001b[39mload_state_dict(model_state_dict)\n\u001b[1;32m     11\u001b[0m model_ft\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m testY, predY \u001b[38;5;241m=\u001b[39m \u001b[43mcollectAllData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(predY), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/PET-IA/src/util.py:149\u001b[0m, in \u001b[0;36mcollectAllData\u001b[0;34m(dataloader, model, device, num_classes)\u001b[0m\n\u001b[1;32m    147\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 149\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    150\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/PET-IA/src/datasets.py:87\u001b[0m, in \u001b[0;36mBaseDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     84\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruthLabel]\n\u001b[1;32m     85\u001b[0m     studyID \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudyIDLabel]\n\u001b[0;32m---> 87\u001b[0m     image, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudyID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstoreInCache(idx, image, label, metadata)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[0;32m~/PET-IA/src/datasets.py:68\u001b[0m, in \u001b[0;36mBaseDataset.loadImage\u001b[0;34m(self, studyID)\u001b[0m\n\u001b[1;32m     66\u001b[0m imageFile \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, studyID, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresampled-normalized.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimageExtension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m metadataFile \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, studyID, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmetadataFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     70\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/hugom/PET-IA/Full-DBs/ebrains/data_nifti_stripped/hc_images_preprocessed/s0042855A-207260-00001-000001/metadata.json'"
     ]
    }
   ],
   "source": [
    "for key in config:\n",
    "    print(f\"Ejecutando {key}\")\n",
    "    executeModel(dataloader, **config[key])\n",
    "    print(\"#################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36430501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cde9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
