# -*- coding: utf-8 -*-
from __future__ import print_function, division
"""MuestraFull3700_5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dR7ZG17_Mmr3y3JV0mLf12Bp8U8J27Aa
"""

try:
    from google.colab import drive
    drive.mount('/content/gdrive')
except ModuleNotFoundError:
    print('Not running on Google')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import os
import time
import copy
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
import torchvision
from torchvision import transforms, utils, models, datasets
import torch.nn as nn
import torch.optim as optim
import nibabel as nib
import scipy.ndimage as ndi
from pathlib import Path
from PIL import Image
import io
import json
import random
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
import sys
import json

# Own
from util import clipped_zoom, printFile
from transforms import TransformGridImage, ToLabelOutput, ToLabelOutputFleni, ToLabelOutputConfigurable
from datasets import FleniMyriamDataset, ADNIDataset, BaseDataset
from select_criterias import select_criteria_accuracy_aggregate, select_criteria_accuracy_epoch_result, select_criteria_f1AD_aggregate, select_criteria_f1AD_epoch_result
from eval_lib import collectAllData, processStatsThreeClases, processStatsTwoClases
from config import loadConfig
from train_lib import train_model, set_parameter_requires_grad, initialize_model
from util import test_model, printClassStats
from cross_validation import getKFoldTrainAndValDatasets

# Ignore warnings
import warnings
warnings.filterwarnings("ignore")
print("PyTorch Version: ",torch.__version__)
print("Torchvision Version: ",torchvision.__version__)

"""# Configuración"""
configFile = sys.argv[1]


config = loadConfig(configFile)

imagesFolder = config['imagesFolder']
fleni100ImagesFolder = config['fleni100ImagesFolder']
fleni600ImagesFolder = config['fleni600ImagesFolder']
trainDatasetCSV = config['trainDatasetCSV']
valDatasetCSV = config['valDatasetCSV']
testDatasetCSV = config['testDatasetCSV']
fleni100ValDatasetCSV = config['fleni100ValDatasetCSV']
fleni60ValDatasetCSV = config['fleni60ValDatasetCSV']
fleni600ValDatasetCSV = config['fleni600ValDatasetCSV']
experimentName = config['experimentName']
experimentOutputFolder = config['experimentOutputFolder']
experimentDescription = config['experimentDescription']
executions = config['executions']
model_name = config['model_name'] # Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]
num_classes = config['num_classes'] # Number of classes in the dataset
batch_size = config['batch_size'] # Batch size for training (change depending on how much memory you have)
dl_num_workers = config['dl_num_workers'] # TODO: set as 0 if running on my local machine
num_epochs = config['num_epochs'] # Number of epochs to train for
# Flag for feature extracting. When False, we finetune the whole model,
#   when True we only update the reshaped layer params
feature_extract = config['feature_extract']
usePretrained = config['usePretrained']
auxEnabled = config['auxEnabled'] # Habilita la salida auxiliar
learningRate = config['learningRate']
dropoutRate = config['dropoutRate']
normalization = config['normalization']
trainMean = config['trainMean']
trainStd = config['trainStd']
fleni100Mean = config['fleni100Mean']
fleni100Std = config['fleni100Std']
fleni60Mean = config['fleni60Mean']
fleni60Std = config['fleni60Std']
fleni600Mean = config['fleni600Mean']
fleni600Std = config['fleni600Std']
deviceName = config['deviceName']
dataAugmentation = config['dataAugmentation']
selectCriteria = config['selectCriteria']
validationCacheSize = config['validationCacheSize']
trainCacheSize = config['trainCacheSize']
calculateAUCROC = config['calculateAUCROC']
debug = config['debug']
doTrain = config['doTrain']
selectCriteriaAbbrv = config['selectCriteriaAbbrv']
trainElements = config['trainElements']
truthLabel = config['truthLabel']
crossValidationK = config['crossValidationK']

# Útil para procesar solo un subconjunto de epochs
printStats = True
startEpoch = 0
endEpoch = num_epochs
if "eval" in config and "startEpoch" in config["eval"]:
    startEpoch = config["eval"]["startEpoch"]
    printStats = False
if "eval" in config and "endEpoch" in config["eval"]:
    endEpoch = config["eval"]["endEpoch"]
    printStats = False
# Seteamos printStats = False porque dejan de ser representativas si no procesamos todas las epochs

# Pisar valores para eval:
processStatsADNI = True
processStatsFleni = True
processStatsADNITest = True
if "eval" in config:
    evalConfig = config["eval"]
    if "processStatsADNI" in evalConfig:
        processStatsADNI = evalConfig["processStatsADNI"]
    if "processStatsADNITest" in evalConfig:
        processStatsADNI = evalConfig["processStatsADNITest"]
    if "processStatsFleni" in evalConfig:
        processStatsFleni = evalConfig["processStatsFleni"]
    if "deviceName" in evalConfig:
        deviceName = evalConfig['deviceName']
    if "dl_num_workers" in evalConfig:
        dl_num_workers = evalConfig['dl_num_workers']

print(f"Using device {deviceName}")


if num_classes == 3:
  crossEntrophyWeigths = torch.tensor(trainElements) # Órden: CN, AD, MCI
else:
    if len(trainElements) == 3: # backward compatibility
        crossEntrophyWeigths = torch.tensor([trainElements[0] + trainElements[2], trainElements[1]]) # Órden: CN/MCI, AD
    else:
        crossEntrophyWeigths = torch.tensor([trainElements[0], trainElements[1]])

#trainMean = 0.1716601789041244 #preproc3, < 0s eliminados
#trainStd = 0.3936839672084841 #preproc3
#trainMean = 0.1534203209139499  #preproc4, sin eliminar < 0s
#trainStd =  0.4048895150096513   #preproc4


if normalization == "z-score":
    zScoreNormalization = {
        "trainMeans": [trainMean, trainMean, trainMean],
        "trainStds": [trainStd, trainStd, trainStd]
    }

    normalizationTransform = transforms.Normalize(zScoreNormalization["trainMeans"], zScoreNormalization["trainStds"])

    fleni100Normalization = {
        "trainMeans": [fleni100Mean, fleni100Mean, fleni100Mean],
        "trainStds": [fleni100Std, fleni100Std, fleni100Std]
    }

    fleni100NormalizationTransform = transforms.Normalize(fleni100Normalization["trainMeans"], fleni100Normalization["trainStds"])

    fleni60Normalization = {
        "trainMeans": [fleni60Mean, fleni60Mean, fleni60Mean],
        "trainStds": [fleni60Std, fleni60Std, fleni60Std]
    }

    fleni60NormalizationTransform = transforms.Normalize(fleni60Normalization["trainMeans"], fleni60Normalization["trainStds"])

    fleni600Normalization = {
        "trainMeans": [fleni600Mean, fleni600Mean, fleni600Mean],
        "trainStds": [fleni600Std, fleni600Std, fleni600Std]
    }

    fleni600NormalizationTransform = transforms.Normalize(fleni600Normalization["trainMeans"], fleni600Normalization["trainStds"])
    
elif normalization == "min-max":

    normalizationTransform = MinMaxNormalization(-1, 1)

    fleniNormalizationTransform = MinMaxNormalization(-1, 1)
else:
    raise Exception(f"Unknown normalization ${normalization}")

     
# Data augmentation
# dataAugmentation = {
#     "angle": 8,
#     "shiftX": 10,
#     "shiftY": 10,
#     "zoom": 0.1,
#     "shear": np.pi / 16,
# }
# dataAugmentation = {}

# End Config

"""# Utilidades"""

selectCriteriaAbbrv = selectCriteriaAbbrv[selectCriteria]


# Evals an experiment. It requires some data for it, including the experiment output folder
# It works with multiple weight files. The evaluation is done for every weight file.
def evalExperiment(experimentName, valDatasetCSV, k, crossValidationK = None):
    if crossValidationK != None:
        experimentName = experimentName + "_kFold" + str(k)

    print(f"Evaluando experimento {experimentName}")

    print(f"Con k = {k}")
    print(f"Y valDatasetCSV de {len(valDatasetCSV)} muestras")
    
    # Init model

    # Initialize the model for this run
    model_ft, _ = initialize_model(model_name, num_classes, feature_extract, dropoutRate, auxEnabled, use_pretrained=usePretrained)

    # Print the model we just instantiated
    print(model_ft)

    # Data augmentation and normalization for training
    # Just normalization for validation

    # Data augmentation and normalization for training
    # Just normalization for validation

    data_transforms = {
        'train': transforms.Compose([
            TransformGridImage(**dataAugmentation),
            transforms.ToTensor(),
            normalizationTransform
        ]),
        'val': transforms.Compose([
            TransformGridImage(),
            transforms.ToTensor(),
            normalizationTransform
        ]),
        'test': transforms.Compose([
            TransformGridImage(),
            transforms.ToTensor(),
            normalizationTransform
        ]),
        'valFleni100': transforms.Compose([
            TransformGridImage(),
            transforms.ToTensor(),
            fleni100NormalizationTransform
        ]),
        'valFleni60': transforms.Compose([
            TransformGridImage(),
            transforms.ToTensor(),
            fleni60NormalizationTransform
        ]),
        'valFleni600': transforms.Compose([
            TransformGridImage(),
            transforms.ToTensor(),
            fleni600NormalizationTransform
        ]),
    }

    print("Initializing Datasets and Dataloaders...")

    # Create training and validation datasets

    dictiFleni60 = {
        "AD": 1,
        "non-AD": 0
    }

    dictiFleni600 = {
        "AD": 1,
        "non-AD": 0
    }
    
    image_datasets = {
        'train': ADNIDataset('trainDL', trainDatasetCSV, imagesFolder, transform = data_transforms['train'], target_transform =ToLabelOutput(num_classes), cacheSize = trainCacheSize, truthLabel = truthLabel),
        'val': ADNIDataset('valDL', valDatasetCSV, imagesFolder, transform = data_transforms['val'], target_transform =ToLabelOutput(num_classes), cacheSize = validationCacheSize, truthLabel = truthLabel ),
        'test': ADNIDataset('valDL', testDatasetCSV, imagesFolder, transform = data_transforms['test'], target_transform =ToLabelOutput(num_classes), cacheSize = validationCacheSize, truthLabel = truthLabel ),
        'valFleni100': FleniMyriamDataset('valFleni100DL', fleni100ValDatasetCSV, fleni100ImagesFolder, transform = data_transforms['valFleni100'], target_transform =ToLabelOutputFleni(num_classes), cacheSize = validationCacheSize ),
        'valFleni60': BaseDataset('fleni60', fleni60ValDatasetCSV, fleni600ImagesFolder, studyIDLabel = 'anon_id', transform = data_transforms['valFleni60'], target_transform = ToLabelOutputConfigurable(dictiFleni60), truthLabel = 'Conclusion PET'),
        'valFleni600': BaseDataset('fleni600', fleni600ValDatasetCSV, fleni600ImagesFolder, studyIDLabel = 'anon_id', transform = data_transforms['valFleni600'], target_transform = ToLabelOutputConfigurable(dictiFleni600), truthLabel = 'Diagnóstico'),
    }

    # Create training and validation dataloaders
    # , 'valFleni'
    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=dl_num_workers) for x in ['train', 'val', 'test', 'valFleni100', 'valFleni60', 'valFleni600']}

    # Detect if we have a GPU available
    device = torch.device(deviceName if torch.cuda.is_available() else "cpu")
    
    # Eval
    executionNumber = 0

    if processStatsADNI:
        print("########################")
        print("## Stats ADNI Validation")
        if num_classes == 3:
          processStatsThreeClases(model_ft, device, dataloaders_dict['val'], num_epochs, experimentOutputFolder, experimentName, executionNumber, "val", startEpoch = startEpoch, endEpoch = endEpoch, printStats = printStats)
        else:
          processStatsTwoClases(model_ft, device, dataloaders_dict['val'], num_epochs, experimentOutputFolder, experimentName, executionNumber, num_classes, "val", labels = [0,1], labelDict = { 0: "noAD", 1: "AD" }, startEpoch = startEpoch, endEpoch = endEpoch, printStats = printStats)
    else:
        print("Skipping Stats ADNI")

    if processStatsADNITest:
        print("########################")
        print("## Stats ADNI Testidation")
        if num_classes == 3:
          processStatsThreeClases(model_ft, device, dataloaders_dict['test'], num_epochs, experimentOutputFolder, experimentName, executionNumber, "test", startEpoch = startEpoch, endEpoch = endEpoch, printStats = printStats)
        else:
          processStatsTwoClases(model_ft, device, dataloaders_dict['test'], num_epochs, experimentOutputFolder, experimentName, executionNumber, num_classes, "test", labels = [0,1], labelDict = { 0: "noAD", 1: "AD" }, startEpoch = startEpoch, endEpoch = endEpoch, printStats = printStats)
    else:
        print("Skipping Stats ADNI")

    # TODO: tirar los stats a diferentes archivos
    if processStatsFleni:
        print("########################")
        print("## Stats Fleni100")
        if num_classes == 3: # borrar
          labels = [0, 1, 2]
          labelDict = {
            0: "CN",
            1: "AD",
            2: "MCI"
          }
        else: # borrar /end
          labels = [0,1]
          labelDict = { 0: "noAD", 1: "AD" }

        processStatsTwoClases(model_ft, device, dataloaders_dict['valFleni100'], num_epochs, experimentOutputFolder, experimentName, executionNumber, num_classes,  "valFleni100", labels = labels, labelDict = labelDict, startEpoch = startEpoch, endEpoch = endEpoch, printStats = printStats)

        print("########################")
        print("## Stats Fleni60")
        if num_classes == 3: # borrar
          labels = [0, 1, 2]
          labelDict = {
            0: "CN",
            1: "AD",
            2: "MCI"
          }
        else: # borrar /end
          labels = [0,1]
          labelDict = { 0: "noAD", 1: "AD" }

        processStatsTwoClases(model_ft, device, dataloaders_dict['valFleni60'], num_epochs, experimentOutputFolder, experimentName, executionNumber, num_classes,  "valFleni60", labels = labels, labelDict = labelDict, startEpoch = startEpoch, endEpoch = endEpoch, printStats = printStats)

        print("########################")
        print("## Stats Fleni600")
        if num_classes == 3: # borrar
          labels = [0, 1, 2]
          labelDict = {
            0: "CN",
            1: "AD",
            2: "MCI"
          }
        else: # borrar /end
          labels = [0,1]
          labelDict = { 0: "noAD", 1: "AD" }

        processStatsTwoClases(model_ft, device, dataloaders_dict['valFleni600'], num_epochs, experimentOutputFolder, experimentName, executionNumber, num_classes,  "valFleni600", labels = labels, labelDict = labelDict, startEpoch = startEpoch, endEpoch = endEpoch, printStats = printStats)
    else:
        print("Skipping Stats Fleni")


if crossValidationK == None:
    crossValidationK = 1

train_sets, val_sets = getKFoldTrainAndValDatasets(trainDatasetCSV, valDatasetCSV, crossValidationK)

for k in range(0, crossValidationK):
    evalExperiment(experimentName, val_sets[k], k, crossValidationK)

    print("=========================")
    print("=========================")
    print("=========================")
